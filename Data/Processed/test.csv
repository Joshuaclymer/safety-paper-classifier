text,label
One for All Simultaneous Metric and Preference Learning over Multiple Users This paper investigates simultaneous preference and metric learning from acrowd of respondents. A set of items represented by ddimensional featurevectors and paired comparisons of the form item i is preferable to itemj made by each user is given. Our model jointly learns a distance metricthat characterizes the crowds general measure of item similarities along witha latent ideal point for each user reflecting their individual preferences.This model has the flexibility to capture individual preferences whileenjoying a metric learning sample cost that is amortized over the crowd. Wefirst study this problem in a noiseless continuous response setting i.e.responses equal to differences of item distances to understand the fundamentallimits of learning. Next we establish prediction error guarantees for noisybinary measurements such as may be collected from human respondents and showhow the sample complexity improves when the underlying metric is lowrank.Finally we establish recovery guarantees under assumptions on the responsedistribution. We demonstrate the performance of our model on both simulateddata and on a dataset of color preference judgements across a large number ofusers.,0
Active Exploration for Inverse Reinforcement Learning Inverse Reinforcement Learning IRL is a powerful paradigm for inferring areward function from expert demonstrations. Many IRL algorithms require a knowntransition model and sometimes even a known expert policy or they at leastrequire access to a generative model. However these assumptions are too strongfor many realworld applications where the environment can be accessed onlythrough sequential interaction. We propose a novel IRL algorithm Activeexploration for Inverse Reinforcement Learning AceIRL which activelyexplores an unknown environment and expert policy to quickly learn the expertsreward function and identify a good policy. AceIRL uses previous observationsto construct confidence intervals that capture plausible reward functions andfind exploration policies that focus on the most informative regions of theenvironment. AceIRL is the first approach to active IRL with samplecomplexitybounds that does not require a generative model of the environment. AceIRLmatches the sample complexity of active IRL with a generative model in theworst case. Additionally we establish a problemdependent bound that relatesthe sample complexity of AceIRL to the suboptimality gap of a given IRLproblem. We empirically evaluate AceIRL in simulations and find that itsignificantly outperforms more naive exploration strategies.,0
Aligning AI With Shared Human Values We show how to assess a language models knowledge of basic concepts ofmorality. We introduce the ETHICS dataset a new benchmark that spans conceptsin justice wellbeing duties virtues and commonsense morality. Modelspredict widespread moral judgments about diverse text scenarios. This requiresconnecting physical and social world knowledge to value judgements acapability that may enable us to steer chatbot outputs or eventually regularizeopenended reinforcement learning agents. With the ETHICS dataset we find thatcurrent language models have a promising but incomplete ability to predictbasic human ethical judgements. Our work shows that progress can be made onmachine ethics today and it provides a steppingstone toward AI that is alignedwith human values.,0
TruthfulQA Measuring How Models Mimic Human Falsehoods We propose a benchmark to measure whether a language model is truthful ingenerating answers to questions. The benchmark comprises  questions thatspan  categories including health law finance and politics. We craftedquestions that some humans would answer falsely due to a false belief ormisconception. To perform well models must avoid generating false answerslearned from imitating human texts. We tested GPT GPTNeoJ GPT and aTbased model. The best model was truthful on  of questions while humanperformance was . Models generated many false answers that mimic popularmisconceptions and have the potential to deceive humans. The largest modelswere generally the least truthful. This contrasts with other NLP tasks whereperformance improves with model size. However this result is expected if falseanswers are learned from the training distribution. We suggest that scaling upmodels alone is less promising for improving truthfulness than finetuningusing training objectives other than imitation of text from the web.,0
DiscriminatorActorCritic Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning We identify two issues with the family of algorithms based on the AdversarialImitation Learning framework. The first problem is implicit bias present in thereward functions used in these algorithms. While these biases might work wellfor some environments they can also lead to suboptimal behavior in others.Secondly even though these algorithms can learn from few expertdemonstrations they require a prohibitively large number of interactions withthe environment in order to imitate the expert for many realworldapplications. In order to address these issues we propose a new algorithmcalled DiscriminatorActorCritic that uses offpolicy Reinforcement Learningto reduce policyenvironment interaction sample complexity by an average factorof . Furthermore since our reward function is designed to be unbiased wecan apply our algorithm to many problems without making any taskspecificadjustments.,0
Unsolved Problems in ML Safety Machine learning ML systems are rapidly increasing in size are acquiringnew capabilities and are increasingly deployed in highstakes settings. Aswith other powerful technologies safety for ML should be a leading researchpriority. In response to emerging safety challenges in ML such as thoseintroduced by recent largescale models we provide a new roadmap for ML Safetyand refine the technical problems that the field needs to address. We presentfour problems ready for research namely withstanding hazards Robustnessidentifying hazards Monitoring reducing inherent model hazardsAlignment and reducing systemic hazards Systemic Safety. Throughoutwe clarify each problems motivation and provide concrete research directions.,0
AI safety via debate To make AI systems broadly useful for challenging realworld tasks we needthem to learn complex human goals and preferences. One approach to specifyingcomplex goals asks humans to judge during training which agent behaviors aresafe and useful but this approach can fail if the task is too complicated fora human to directly judge. To help address this concern we propose trainingagents via self play on a zero sum debate game. Given a question or proposedaction two agents take turns making short statements up to a limit then ahuman judges which of the agents gave the most true useful information. In ananalogy to complexity theory debate with optimal play can answer any questionin PSPACE given polynomial time judges direct judging answers only NPquestions. In practice whether debate works involves empirical questionsabout humans and the tasks we want AIs to perform plus theoretical questionsabout the meaning of AI alignment. We report results on an initial MNISTexperiment where agents compete to convince a sparse classifier boosting theclassifiers accuracy from . to . given  pixels and from . to. given  pixels. Finally we discuss theoretical and practical aspects ofthe debate model focusing on potential weaknesses as the model scales up andwe propose future human and computer experiments to test these properties.,0
Actionable Guidance for HighConsequence AI Risk Management Towards Standards Addressing AI Catastrophic Risks Artificial intelligence AI systems can provide many beneficial capabilitiesbut also risks of adverse events. Some AI systems could present risks of eventswith very high or catastrophic consequences at societal scale. The US NationalInstitute of Standards and Technology NIST is developing the NIST ArtificialIntelligence Risk Management Framework AI RMF as voluntary guidance on AIrisk assessment and management for AI developers and others. For addressingrisks of events with catastrophic consequences NIST indicated a need totranslate from high level principles to actionable risk management guidance.,0
Imperceptible Backdoor Attack From Input Space to Feature Representation Backdoor attacks are rapidly emerging threats to deep neural networks DNNs.In the backdoor attack scenario attackers usually implant the backdoor intothe target model by manipulating the training dataset or training process.Then the compromised model behaves normally for benign input yet makesmistakes when the predefined trigger appears. In this paper we analyze thedrawbacks of existing attack approaches and propose a novel imperceptiblebackdoor attack. We treat the trigger pattern as a special kind of noisefollowing a multinomial distribution. A Unetbased network is employed togenerate concrete parameters of multinomial distribution for each benign input.This elaborated trigger ensures that our approach is invisible to both humansand statistical detection. Besides the design of the trigger we also considerthe robustness of our approach against model diagnosebased defences. We forcethe feature representation of malicious input stamped with the trigger to beentangled with the benign one. We demonstrate the effectiveness and robustnessagainst multiple stateoftheart defences through extensive datasets andnetworks. Our trigger only modifies less than  pixels of a benign imagewhile the modification magnitude is . Our source code is available at,1
Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles Deep neural networks NNs are powerful black box predictors that haverecently achieved impressive performance on a wide spectrum of tasks.Quantifying predictive uncertainty in NNs is a challenging and yet unsolvedproblem. Bayesian NNs which learn a distribution over weights are currentlythe stateoftheart for estimating predictive uncertainty however theserequire significant modifications to the training procedure and arecomputationally expensive compared to standard nonBayesian NNs. We proposean alternative to Bayesian NNs that is simple to implement readilyparallelizable requires very little hyperparameter tuning and yields highquality predictive uncertainty estimates. Through a series of experiments onclassification and regression benchmarks we demonstrate that our methodproduces wellcalibrated uncertainty estimates which are as good or better thanapproximate Bayesian NNs. To assess robustness to dataset shift we evaluatethe predictive uncertainty on test examples from known and unknowndistributions and show that our method is able to express higher uncertaintyon outofdistribution examples. We demonstrate the scalability of our methodby evaluating predictive uncertainty estimates on ImageNet.,1
WeShort Outofdistribution Detection With Weak Shortcut structure Neural networks have achieved impressive performance for data in thedistribution which is the same as the training set but can produce anoverconfident incorrect result for the data these networks have never seen.Therefore it is essential to detect whether inputs come fromoutofdistributionOOD in order to guarantee the safety of neural networksdeployed in the real world. In this paper we propose a simple and effectiveposthoc technique WeShort to reduce the overconfidence of neural networks onOOD data. Our method is inspired by the observation of the internal residualstructure which shows the separation of the OOD and indistribution ID datain the shortcut layer. Our method is compatible with different OOD detectionscores and can generalize well to different architectures of networks. Wedemonstrate our method on various OOD datasets to show its competitiveperformances and provide reasonable hypotheses to explain why our method works.On the ImageNet benchmark Weshort achieves stateoftheart performance on thefalse positive rate FPR and the area under the receiver operatingcharacteristic AUROC on the family of posthoc methods.,1
BadNets Identifying Vulnerabilities in the Machine Learning Model Supply Chain Deep learningbased techniques have achieved stateoftheart performance ona wide variety of recognition and classification tasks. However these networksare typically computationally expensive to train requiring weeks ofcomputation on many GPUs as a result many users outsource the trainingprocedure to the cloud or rely on pretrained models that are then finetunedfor a specific task. In this paper we show that outsourced training introducesnew security risks an adversary can create a maliciously trained network abackdoored neural network or a emphBadNet that has stateoftheartperformance on the users training and validation samples but behaves badly onspecific attackerchosen inputs. We first explore the properties of BadNets ina toy example by creating a backdoored handwritten digit classifier. Next wedemonstrate backdoors in a more realistic scenario by creating a U.S. streetsign classifier that identifies stop signs as speed limits when a specialsticker is added to the stop sign we then show in addition that the backdoorin our US street sign detector can persist even if the network is laterretrained for another task and cause a drop in accuracy of  on averagewhen the backdoor trigger is present. These results demonstrate that backdoorsin neural networks are both powerful andbecause the behavior of neuralnetworks is difficult to explicatestealthy. This work provides motivationfor further research into techniques for verifying and inspecting neuralnetworks just as we have developed tools for verifying and debugging software.,1
Locating and Editing Factual Associations in GPT We analyze the storage and recall of factual associations in autoregressivetransformer language models finding evidence that these associationscorrespond to localized directlyeditable computations. We first develop acausal intervention for identifying neuron activations that are decisive in amodels factual predictions. This reveals a distinct set of steps inmiddlelayer feedforward modules that mediate factual predictions whileprocessing subject tokens. To test our hypothesis that these computationscorrespond to factual association recall we modify feedforward weights toupdate specific factual associations using RankOne Model Editing ROME. Wefind that ROME is effective on a standard zeroshot relation extraction zsREmodelediting task comparable to existing methods. To perform a more sensitiveevaluation we also evaluate ROME on a new dataset of counterfactualassertions on which it simultaneously maintains both specificity andgeneralization whereas other methods sacrifice one or another. Our resultsconfirm an important role for midlayer feedforward modules in storing factualassociations and suggest that direct manipulation of computational mechanismsmay be a feasible approach for model editing. The code datasetvisualizations and an interactive demo notebook are available at,1
Scaling OutofDistribution Detection for RealWorld Settings Detecting outofdistribution examples is important for safetycriticalmachine learning applications such as detecting novel biological phenomena andselfdriving cars. However existing research mainly focuses on simplesmallscale settings. To set the stage for more realistic outofdistributiondetection we depart from smallscale settings and explore largescalemulticlass and multilabel settings with highresolution images and thousandsof classes. To make future work in realworld settings possible we create newbenchmarks for three largescale settings. To test ImageNet multiclass anomalydetectors we introduce the Species dataset containing over  images andover a thousand anomalous species. We leverage ImageNetK to evaluate PASCALVOC and COCO multilabel anomaly detectors. Third we introduce a new benchmarkfor anomaly segmentation by introducing a segmentation benchmark with roadanomalies. We conduct extensive experiments in these more realistic settingsfor outofdistribution detection and find that a surprisingly simple detectorbased on the maximum logit outperforms prior methods in all the largescalemulticlass multilabel and segmentation tasks establishing a simple newbaseline for future work.,1
Detecting AI Trojans Using Meta Neural Analysis In machine learning Trojan attacks an adversary trains a corrupted modelthat obtains good performance on normal data but behaves maliciously on datasamples with certain trigger patterns. Several approaches have been proposed todetect such attacks but they make undesirable assumptions about the attackstrategies or require direct access to the trained models which restrictstheir utility in practice.,1
Grokking Generalization Beyond Overfitting on Small Algorithmic Datasets In this paper we propose to study generalization of neural networks on smallalgorithmically generated datasets. In this setting questions about dataefficiency memorization generalization and speed of learning can be studiedin great detail. In some situations we show that neural networks learn througha process of grokking a pattern in the data improving generalizationperformance from random chance level to perfect generalization and that thisimprovement in generalization can happen well past the point of overfitting. Wealso study generalization as a function of dataset size and find that smallerdatasets require increasing amounts of optimization for generalization. Weargue that these datasets provide a fertile ground for studying a poorlyunderstood aspect of deep learning generalization of overparametrized neuralnetworks beyond memorization of the finite training dataset.,1
Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead Black box machine learning models are currently being used for high stakesdecisionmaking throughout society causing problems throughout healthcarecriminal justice and in other domains. People have hoped that creating methodsfor explaining these black box models will alleviate some of these problemsbut trying to textitexplain black box models rather than creating modelsthat are textitinterpretable in the first place is likely to perpetuate badpractices and can potentially cause catastrophic harm to society. There is away forward  it is to design models that are inherently interpretable. Thismanuscript clarifies the chasm between explaining black boxes and usinginherently interpretable models outlines several key reasons why explainableblack boxes should be avoided in highstakes decisions identifies challengesto interpretable machine learning and provides several example applicationswhere interpretable models could potentially replace black box models incriminal justice healthcare and computer vision.,1
Network Dissection Quantifying Interpretability of Deep Visual Representations We propose a general framework called Network Dissection for quantifying theinterpretability of latent representations of CNNs by evaluating the alignmentbetween individual hidden units and a set of semantic concepts. Given any CNNmodel the proposed method draws on a broad data set of visual concepts toscore the semantics of hidden units at each intermediate convolutional layer.The units with semantics are given labels across a range of objects partsscenes textures materials and colors. We use the proposed method to test thehypothesis that interpretability of units is equivalent to random linearcombinations of units then we apply our method to compare the latentrepresentations of various networks when trained to solve different supervisedand selfsupervised training tasks. We further analyze the effect of trainingiterations compare networks trained with different initializations examinethe impact of network depth and width and measure the effect of dropout andbatch normalization on the interpretability of deep visual representations. Wedemonstrate that the proposed method can shed light on characteristics of CNNmodels and training methods that go beyond measurements of their discriminativepower.,1
Deep Anomaly Detection with Outlier Exposure It is important to detect anomalous inputs when deploying machine learningsystems. The use of larger and more complex inputs in deep learning magnifiesthe difficulty of distinguishing between anomalous and indistributionexamples. At the same time diverse image and text data are available inenormous quantities. We propose leveraging these data to improve deep anomalydetection by training anomaly detectors against an auxiliary dataset ofoutliers an approach we call Outlier Exposure OE. This enables anomalydetectors to generalize and detect unseen anomalies. In extensive experimentson natural language processing and small and largescale vision tasks we findthat Outlier Exposure significantly improves detection performance. We alsoobserve that cuttingedge generative models trained on CIFAR may assignhigher likelihoods to SVHN images than to CIFAR images we use OE tomitigate this issue. We also analyze the flexibility and robustness of OutlierExposure and identify characteristics of the auxiliary dataset that improveperformance.,1
Defense Against Multitarget Trojan Attacks Adversarial attacks on deep learningbased models pose a significant threatto the current AI infrastructure. Among them Trojan attacks are the hardest todefend against. In this paper we first introduce a variation of the Badnetkind of attacks that introduces Trojan backdoors to multiple target classes andallows triggers to be placed anywhere in the image. The former makes it morepotent and the latter makes it extremely easy to carry out the attack in thephysical space. The stateoftheart Trojan detection methods fail with thisthreat model. To defend against this attack we first introduce a triggerreverseengineering mechanism that uses multiple images to recover a variety ofpotential triggers. We then propose a detection mechanism by measuring thetransferability of such recovered triggers. A Trojan trigger will have veryhigh transferability i.e. they make other images also go to the same class. Westudy many practical advantages of our attack method and then demonstrate thedetection performance using a variety of image datasets. The experimentalresults show the superior detection performance of our method over thestateofthearts.,1
Adversarial NLI A New Benchmark for Natural Language Understanding We introduce a new largescale NLI benchmark dataset collected via aniterative adversarial humanandmodelintheloop procedure. We show thattraining models on this new dataset leads to stateoftheart performance on avariety of popular NLI benchmarks while posing a more difficult challenge withits new test set. Our analysis sheds light on the shortcomings of currentstateoftheart models and shows that nonexpert annotators are successful atfinding their weaknesses. The data collection method can be applied in aneverending learning scenario becoming a moving target for NLU rather than astatic benchmark that will quickly saturate.,2
Fast AdvProp Adversarial Propagation AdvProp is an effective way to improve recognitionmodels leveraging adversarial examples. Nonetheless AdvProp suffers from theextremely slow training speed mainly because a extra forward and backwardpasses are required for generating adversarial examples b both originalsamples and their adversarial counterparts are used for training i.e.times data. In this paper we introduce Fast AdvProp which aggressivelyrevamps AdvProps costly training components rendering the method nearly ascheap as the vanilla training. Specifically our modifications in Fast AdvPropare guided by the hypothesis that disentangled learning with adversarialexamples is the key for performance improvements while other training recipese.g. paired clean and adversarial training samples multistep adversarialattackers could be largely simplified.,2
Certified Defenses against Adversarial Examples While neural networks have achieved high accuracy on standard imageclassification benchmarks their accuracy drops to nearly zero in the presenceof small adversarial perturbations to test inputs. Defenses based onregularization and adversarial training have been proposed but often followedby new stronger attacks that defeat these defenses. Can we somehow end thisarms race In this work we study this problem for neural networks with onehidden layer. We first propose a method based on a semidefinite relaxation thatoutputs a certificate that for a given network and test input no attack canforce the error to exceed a certain value. Second as this certificate isdifferentiable we jointly optimize it with the network parameters providingan adaptive regularizer that encourages robustness against all attacks. OnMNIST our approach produces a network and a certificate that no attack thatperturbs each pixel by at most epsilon  . can cause more than  testerror.,2
Can Rationalization Improve Robustness A growing line of work has investigated the development of neural NLP modelsthat can produce rationalessubsets of input that can explain their modelpredictions. In this paper we ask whether such rationale models can alsoprovide robustness to adversarial attacks in addition to their interpretablenature. Since these models need to first generate rationales rationalizerbefore making predictions predictor they have the potential to ignorenoise or adversarially added text by simply masking it out of the generatedrationale. To this end we systematically generate various types of AddTextattacks for both token and sentencelevel rationalization tasks and perform anextensive empirical evaluation of stateoftheart rationale models across fivedifferent tasks. Our experiments reveal that the rationale models show thepromise to improve robustness while they struggle in certain scenarioswhenthe rationalizer is sensitive to positional bias or lexical choices of attacktext. Further leveraging human rationale as supervision does not alwaystranslate to better performance. Our study is a first step towards exploringthe interplay between interpretability and robustness in therationalizethenpredict framework.,2
Smooth Adversarial Training It is commonly believed that networks cannot be both accurate and robustthat gaining robustness means losing accuracy. It is also generally believedthat unless making networks larger network architectural elements wouldotherwise matter little in improving adversarial robustness. Here we presentevidence to challenge these common beliefs by a careful study about adversarialtraining. Our key observation is that the widelyused ReLU activation functionsignificantly weakens adversarial training due to its nonsmooth nature. Hencewe propose smooth adversarial training SAT in which we replace ReLU with itssmooth approximations to strengthen adversarial training. The purpose of smoothactivation functions in SAT is to allow it to find harder adversarial examplesand compute better gradient updates during adversarial training.,2
Adversarial Examples for Evaluating Reading Comprehension Systems Standard accuracy metrics indicate that reading comprehension systems aremaking rapid progress but the extent to which these systems truly understandlanguage remains unclear. To reward systems with real language understandingabilities we propose an adversarial evaluation scheme for the StanfordQuestion Answering Dataset SQuAD. Our method tests whether systems can answerquestions about paragraphs that contain adversarially inserted sentences whichare automatically generated to distract computer systems without changing thecorrect answer or misleading humans. In this adversarial setting the accuracyof sixteen published models drops from an average of  F score to when the adversary is allowed to add ungrammatical sequences of words averageaccuracy on four models decreases further to . We hope our insights willmotivate the development of new models that understand language more precisely.,2
PixMix Dreamlike Pictures Comprehensively Improve Safety Measures In realworld applications of machine learning reliable and safe systemsmust consider measures of performance beyond standard test set accuracy. Theseother goals include outofdistribution OOD robustness predictionconsistency resilience to adversaries calibrated uncertainty estimates andthe ability to detect anomalous inputs. However improving performance towardsthese goals is often a balancing act that todays methods cannot achievewithout sacrificing performance on other safety axes. For instance adversarialtraining improves adversarial robustness but sharply degrades other classifierperformance metrics. Similarly strong data augmentation and regularizationtechniques often improve OOD robustness but harm anomaly detection raising thequestion of whether a Pareto improvement on all existing safety measures ispossible. To meet this challenge we design a new data augmentation strategyutilizing the natural structural complexity of pictures such as fractals whichoutperforms numerous baselines is near Paretooptimal and roundly improvessafety measures.,2
Using PreTraining Can Improve Model Robustness and Uncertainty He et al.  have called into question the utility of pretraining byshowing that training from scratch can often yield similar performance topretraining. We show that although pretraining may not improve performance ontraditional classification metrics it improves model robustness anduncertainty estimates. Through extensive experiments on adversarial exampleslabel corruption class imbalance outofdistribution detection andconfidence calibration we demonstrate large gains from pretraining andcomplementary effects with taskspecific methods. We introduce adversarialpretraining and show approximately a  absolute improvement over theprevious stateoftheart in adversarial robustness. In some cases usingpretraining without taskspecific methods also surpasses the stateofthearthighlighting the need for pretraining when evaluating future methods onrobustness and uncertainty tasks.,2
Towards Evaluating the Robustness of Neural Networks Neural networks provide stateoftheart results for most machine learningtasks. Unfortunately neural networks are vulnerable to adversarial examplesgiven an input x and any target classification t it is possible to find anew input x that is similar to x but classified as t. This makes itdifficult to apply neural networks in securitycritical areas. Defensivedistillation is a recently proposed approach that can take an arbitrary neuralnetwork and increase its robustness reducing the success rate of currentattacks ability to find adversarial examples from  to ..,2
Reliable evaluation of adversarial robustness with an ensemble of diverse parameterfree attacks The field of defense strategies against adversarial attacks has significantlygrown over the last years but progress is hampered as the evaluation ofadversarial defenses is often insufficient and thus gives a wrong impression ofrobustness. Many promising defenses could be broken later on making itdifficult to identify the stateoftheart. Frequent pitfalls in the evaluationare improper tuning of hyperparameters of the attacks gradient obfuscation ormasking. In this paper we first propose two extensions of the PGDattackovercoming failures due to suboptimal step size and problems of the objectivefunction. We then combine our novel attacks with two complementary existingones to form a parameterfree computationally affordable and userindependentensemble of attacks to test adversarial robustness. We apply our ensemble toover  models from papers published at recent top machine learning andcomputer vision venues. In all except one of the cases we achieve lower robusttest accuracy than reported in these papers often by more than identifying several broken defenses.,2
The Many Faces of Robustness A Critical Analysis of OutofDistribution Generalization We introduce four new realworld distribution shift datasets consisting ofchanges in image style image blurriness geographic location cameraoperation and more. With our new datasets we take stock of previouslyproposed methods for improving outofdistribution robustness and put them tothe test. We find that using larger models and artificial data augmentationscan improve robustness on realworld distribution shifts contrary to claims inprior work. We find improvements in artificial robustness benchmarks cantransfer to realworld distribution shifts contrary to claims in prior work.Motivated by our observation that data augmentations can help with realworlddistribution shifts we also introduce a new data augmentation method whichadvances the stateoftheart and outperforms models pretrained with  timesmore labeled data. Overall we find that some methods consistently help withdistribution shifts in texture and local image statistics but these methods donot help with some other distribution shifts like geographic changes. Ourresults show that future research must study multiple distribution shiftssimultaneously as we demonstrate that no evaluated method consistentlyimproves robustness.,2
Can CNNs Be More Robust Than Transformers The recent success of Vision Transformers is shaking the long dominance ofConvolutional Neural Networks CNNs in image recognition for a decade.Specifically in terms of robustness on outofdistribution samples recentresearch finds that Transformers are inherently more robust than CNNsregardless of different training setups. Moreover it is believed that suchsuperiority of Transformers should largely be credited to theirselfattentionlike architectures per se. In this paper we question thatbelief by closely examining the design of Transformers. Our findings lead tothree highly effective architecture designs for boosting robustness yet simpleenough to be implemented in several lines of code namely a patchifying inputimages b enlarging kernel size and c reducing activation layers andnormalization layers. Bringing these components together we are able to buildpure CNN architectures without any attentionlike operations that is as robustas or even more robust than Transformers. We hope this work can help thecommunity better understand the design of robust neural architectures. The codeis publicly available at,2
Forecasting Future World Events with Neural Networks Forecasting future world events is a challenging but valuable task. Forecastsof climate geopolitical conflict pandemics and economic indicators help shapepolicy and decision making. In these domains the judgment of expert humanscontributes to the best forecasts. Given advances in language modeling canthese forecasts be automated To this end we introduce Autocast a datasetcontaining thousands of forecasting questions and an accompanying news corpus.Questions are taken from forecasting tournaments ensuring high qualityrealworld importance and diversity. The news corpus is organized by dateallowing us to precisely simulate the conditions under which humans made pastforecasts avoiding leakage from the future. Motivated by the difficulty offorecasting numbers across orders of magnitude e.g. global cases of COVIDin  we also curate IntervalQA a dataset of numerical questions andmetrics for calibration. We test language models on our forecasting task andfind that performance is far below a human expert baseline. Howeverperformance improves with increased model size and incorporation of relevantinformation from the news corpus. In sum Autocast poses a novel challenge forlarge language models and improved performance could bring large practicalbenefits.,3
Developing Optimal Causal CyberDefence Agents via Cyber Security Simulation In this paper we explore cyber security defence through the unification of anovel cyber security simulator with models for causal decisionmaking throughoptimisation. Particular attention is paid to a recently published approachdynamic causal Bayesian optimisation DCBO. We propose that DCBO can act as ablue agent when provided with a view of a simulated network and a causal modelof how a red agent spreads within that network. To investigate how DCBO canperform optimal interventions on host nodes in order to reduce the cost ofintrusions caused by the red agent. Through this we demonstrate a completecybersimulation system which we use to generate observational data for DCBOand provide numerical quantitative results which lay the foundations for futurework in this space.,3
Generalized Beliefs for Cooperative AI Selfplay is a common paradigm for constructing solutions in Markov gamesthat can yield optimal policies in collaborative settings. However thesepolicies often adopt highlyspecialized conventions that make playing with anovel partner difficult. To address this recent approaches rely on encodingsymmetry and conventionawareness into policy training but these requirestrong environmental assumptions and can complicate policy training. Wetherefore propose moving the learning of conventions to the belief space.Specifically we propose a belief learning model that can maintain beliefs overrollouts of policies not seen at training time and can thus decode and adaptto novel conventions at test time. We show how to leverage this model for bothsearch and training of a best response over various pools of policies togreatly improve adhoc teamplay. We also show how our setup promotesexplainability and interpretability of nuanced agent conventions.,3
A NearOptimal PrimalDual Method for OffPolicy Learning in CMDP As an important framework for safe Reinforcement Learning the ConstrainedMarkov Decision Process CMDP has been extensively studied in the recentliterature. However despite the rich results under various onpolicy learningsettings there still lacks some essential understanding of the offline CMDPproblems in terms of both the algorithm design and the information theoreticsample complexity lower bound. In this paper we focus on solving the CMDPproblems where only offline data are available. By adopting the concept of thesinglepolicy concentrability coefficient C we establish anOmegaleftfracminleftmathcalSmathcalAmathcalSIrightCgammaepsilonright sample complexity lower bound for theoffline CMDP problem where I stands for the number of constraints. Byintroducing a simple but novel deviation control mechanism we propose anearoptimal primaldual learning algorithm called DPDL. This algorithmprovably guarantees zero constraint violation and its sample complexity matchesthe above lower bound except for an tildemathcalOgammafactor. Comprehensive discussion on how to deal with the unknown constant Cand the potential asynchronous structure on the offline dataset are alsoincluded.,4
Delayed Feedback in Generalised Linear Bandits Revisited The stochastic generalised linear bandit is a wellunderstood model forsequential decisionmaking problems with many algorithms achievingnearoptimal regret guarantees under immediate feedback. However in many realworld settings the requirement that the reward is observed immediately is notapplicable. In this setting standard algorithms are no longer theoreticallyunderstood. We study the phenomenon of delayed rewards in a theoretical mannerby introducing a delay between selecting an action and receiving the reward.Subsequently we show that an algorithm based on the optimistic principleimproves on existing approaches for this setting by eliminating the need forprior knowledge of the delay distribution and relaxing assumptions on thedecision set and the delays. This also leads to improving the regret guaranteesfrom  widetilde OsqrtdTsqrtd  mathbbEtau to  widetildeOdsqrtT  dmathbbEtau where mathbbEtau denotes theexpected delay d is the dimension and T the time horizon and we havesuppressed logarithmic terms. We verify our theoretical results throughexperiments on simulated data.,4
Probing the Robustness of Independent Mechanism Analysis for Representation Learning One aim of representation learning is to recover the original latent codethat generated the data a task which requires additional information orinductive biases. A recently proposed approach termed Independent MechanismAnalysis IMA postulates that each latent source should influence the observedmixtures independently complementing standard nonlinear independent componentanalysis and taking inspiration from the principle of independent causalmechanisms. While it was shown in theory and experiments that IMA helpsrecovering the true latents the methods performance was so far onlycharacterized when the modeling assumptions are exactly satisfied. Here wetest the methods robustness to violations of the underlying assumptions. Wefind that the benefits of IMAbased regularization for recovering the truesources extend to mixing functions with various degrees of violation of the IMAprinciple while standard regularizers do not provide the same merits.Moreover we show that unregularized maximum likelihood recovers mixingfunctions which systematically deviate from the IMA principle and provide anargument elucidating the benefits of IMAbased regularization.,4
Probabilistic forecasting for geosteering in fluvial successions using a generative adversarial network Quantitative workflows utilizing realtime data to constrain aheadofbituncertainty have the potential to improve geosteering significantly. Fastupdates based on realtime data are essential when drilling in complexreservoirs with high uncertainties in predrill models. However practicalassimilation of realtime data requires effective geological modeling andmathematically robust parameterization. We propose a generative adversarialdeep neural network GAN trained to reproduce geologically consistent Dsections of fluvial successions. Offline training produces a fast GANbasedapproximation of complex geology parameterized as a dimensional model vectorwith standard Gaussian distribution of each component. Probabilistic forecastsare generated using an ensemble of equiprobable model vector realizations. Aforwardmodeling sequence including a GAN converts the initial priorensemble of realizations into EM log predictions. An ensemble smootherminimizes statistical misfits between predictions and realtime data yieldingan update of model vectors and reduced uncertainty around the well. Updates canbe then translated to probabilistic predictions of facies and resistivities.The present paper demonstrates a workflow for geosteering in an outcropbasedsynthetic fluvial succession. In our example the method reduces uncertaintyand correctly predicts most major geological features up to  meters ahead ofdrillbit.,4
When Does Differentially Private Learning Not Suffer in High Dimensions Large pretrained models can be privately finetuned to achieve performanceapproaching that of nonprivate models. A common theme in these results is thesurprising observation that highdimensional models can achieve favorableprivacyutility tradeoffs. This seemingly contradicts known results on themodelsize dependence of differentially private convex learning and raises thefollowing research question When does the performance of differentiallyprivate learning not degrade with increasing model size We identify that themagnitudes of gradients projected onto subspaces is a key factor thatdetermines performance. To precisely characterize this for private convexlearning we introduce a condition on the objective that we term restrictedLipschitz continuity and derive improved bounds for the excess empirical andpopulation risks that are dimensionindependent under additional conditions. Weempirically show that in private finetuning of large language modelsgradients evaluated near a local optimum are mostly controlled by a fewprincipal components. This behavior is similar to conditions under which weobtain dimensionindependent bounds in convex settings. Our theoretical andempirical results together provide a possible explanation for recent successesin largescale private finetuning.,4
Riemannian Diffusion Schrdinger Bridge Scorebased generative models exhibit state of the art performance on densityestimation and generative modeling tasks. These models typically assume thatthe data geometry is flat yet recent extensions have been developed tosynthesize data living on Riemannian manifolds. Existing methods to acceleratesampling of diffusion models are typically not applicable in the Riemanniansetting and Riemannian scorebased methods have not yet been adapted to theimportant task of interpolation of datasets. To overcome these issues weintroduce emphRiemannian Diffusion Schrdinger Bridge. Our proposed methodgeneralizes Diffusion Schrdinger Bridge introduced incitedebortolineurips to the nonEuclidean setting and extends Riemannianscorebased models beyond the first time reversal. We validate our proposedmethod on synthetic data and real Earth and climate data.,4
Discover Life Skills for Planning with Bandits via Observing and Learning How the World Works We propose a novel approach for planning agents to compose abstract skillsvia observing and learning from historical interactions with the world. Ourframework operates in a Markov statespace model via a set of actions underunknown preconditions. We formulate skills as highlevel abstract policiesthat propose action plans based on the current state. Each policy learns newplans by observing the states transitions while the agent interacts with theworld. Such an approach automatically learns new plans to achieve specificintended effects but the success of such plans is often dependent on thestates in which they are applicable. Therefore we formulate the evaluation ofsuch plans as infinitely many multiarmed bandit problems where we balance theallocation of resources on evaluating the success probability of existing armsand exploring new options. The result is a planner capable of automaticallylearning robust highlevel skills under a noisy environment such skillsimplicitly learn the action precondition without explicit knowledge. We showthat this planning approach is experimentally very competitive inhighdimensional state space domains.,4
pGMM Kernel Regression and Comparisons with Boosted Trees In this work we demonstrate the advantage of the pGMM powered generalizedminmax kernel in the context of ridge regression. In recent priorstudies the pGMM kernel has been extensively evaluated for classificationtasks for logistic regression support vector machines as well as deep neuralnetworks. In this paper we provide an experimental study on ridge regressionto compare the pGMM kernel regression with the ordinary ridge linear regressionas well as the RBF kernel ridge regression. Perhaps surprisingly even withouta tuning parameter i.e. p for the power parameter of the pGMM kernelthe pGMM kernel already performs well. Furthermore by tuning the parameterp this deceptively simple pGMM kernel even performs quite comparably toboosted trees.,4
Variance estimation in graphs with the fused lasso We study the problem of variance estimation in general graphstructuredproblems. First we develop a linear time estimator for the homoscedastic casethat can consistently estimate the variance in general graphs. We show that ourestimator attains minimax rates for the chain and D grid graphs when the meansignal has a total variation with canonical scaling. Furthermore we providegeneral upper bounds on the mean squared error performance of the fused lassoestimator in general graphs under a moment condition and a bound on the tailbehavior of the errors. These upper bounds allow us to generalize for broaderclasses of distributions such as subExponential many existing results on thefused lasso that are only known to hold with the assumption that errors aresubGaussian random variables. Exploiting our upper bounds we then study asimple total variation regularization estimator for estimating the signal ofvariances in the heteroscedastic case. Our results show that the varianceestimator attains minimax rates for estimating signals of bounded variation ingrid graphs Knearest neighbor graphs with very mild assumptions and it isconsistent for estimating the variances in any connected graph. In additionextensive numerical results show that our proposed estimators performreasonably well in a variety of graphstructured models.,4
On uniformintime diffusion approximation for stochastic gradient descent The diffusion approximation of stochastic gradient descent SGD in currentliterature is only valid on a finite time interval. In this paper we establishthe uniformintime diffusion approximation of SGD by only assuming that theexpected loss is strongly convex and some other mild conditions withoutassuming the convexity of each random loss function. The main technique is toestablish the exponential decay rates of the derivatives of the solution to thebackward Kolmogorov equation. The uniformintime approximation allows us tostudy asymptotic behaviors of SGD via the continuous stochastic differentialequation SDE even when the random objective function fcdotxi is notstrongly convex.,4
JAWS Predictive Inference Under Covariate Shift We propose textbfJAWS a series of wrapper methods for distributionfreeuncertainty quantification tasks under covariate shift centered on our coremethod textbfJAW the textbfJAckknife textbfWeighted withlikelihoodratio weights. JAWS also includes computationally efficienttextbfApproximations of JAW using higherorder influence functionstextbfJAWA. Theoretically we show that JAW relaxes the jackknifesassumption of data exchangeability to achieve the same finitesample coverageguarantee even under covariate shift. JAWA further approaches the JAW guaranteein the limit of either the sample size or the influence function order undermild assumptions. Moreover we propose a general approach to repurposing anydistributionfree uncertainty quantification method and its guarantees to thetask of risk assessment a task that generates the estimated probability thatthe true label lies within a userspecified interval. We then proposetextbfJAWR and textbfJAWAR as the repurposed versions of proposedmethods for textbfRisk assessment. Practically JAWS outperform thestateoftheart predictive inference baselines in a variety of biased realworld data sets for both intervalgeneration and riskassessment auditingtasks.,4
UncertaintyAware Learning Against Label Noise on Imbalanced Datasets Learning against label noise is a vital topic to guarantee a reliableperformance for deep neural networks. Recent research usually refers to dynamicnoise modeling with model output probabilities and loss values and thenseparates clean and noisy samples. These methods have gained notable success.However unlike cherrypicked data existing approaches often cannot performwell when facing imbalanced datasets a common scenario in the real world. Wethoroughly investigate this phenomenon and point out two major issues thathinder the performance i.e. emphinterclass loss distribution discrepancyand emphmisleading predictions due to uncertainty. The first issue is thatexisting methods often perform classagnostic noise modeling. However lossdistributions show a significant discrepancy among classes under classimbalance and classagnostic noise modeling can easily get confused with noisysamples and samples in minority classes. The second issue refers to that modelsmay output misleading predictions due to epistemic uncertainty and aleatoricuncertainty thus existing methods that rely solely on the output probabilitiesmay fail to distinguish confident samples. Inspired by our observations wepropose an Uncertaintyaware Label Correction frameworkULC to handle labelnoise on imbalanced datasets. First we perform epistemic uncertaintyawareclassspecific noise modeling to identify trustworthy clean samples andrefinediscard highly confident truecorrupted labels. Then we introducealeatoric uncertainty in the subsequent learning process to prevent noiseaccumulation in the label noise modeling process. We conduct experiments onseveral synthetic and realworld datasets. The results demonstrate theeffectiveness of the proposed method especially on imbalanced datasets.,4
Fast Composite Optimization and Statistical Recovery in Federated Learning As a prevalent distributed learning paradigm Federated Learning FL trainsa global model on a massive amount of devices with infrequent communication.This paper investigates a class of composite optimization and statisticalrecovery problems in the FL setting whose loss function consists of adatadependent smooth loss and a nonsmooth regularizer. Examples includesparse linear regression using Lasso lowrank matrix recovery using nuclearnorm regularization etc. In the existing literature federated compositeoptimization algorithms are designed only from an optimization perspectivewithout any statistical guarantees. In addition they do not consider commonlyused restricted strong convexity in statistical recovery problems. We advancethe frontiers of this problem from both optimization and statisticalperspectives. From optimization upfront we propose a new algorithm namedtextitFast Federated Dual Averaging for strongly convex and smooth loss andestablish stateoftheart iteration and communication complexity in thecomposite setting. In particular we prove that it enjoys a fast rate linearspeedup and reduced communication rounds. From statistical upfront forrestricted strongly convex and smooth loss we design another algorithm namelytextitMultistage Federated Dual Averaging and prove a high probabilitycomplexity bound with linear speedup up to optimal statistical precision.Experiments in both synthetic and real data demonstrate that our methodsperform better than other baselines. To the best of our knowledge this is thefirst work providing fast optimization algorithms and statistical recoveryguarantees for composite problems in FL.,4
A State Transition Model for Mobile Notifications via Survival Analysis Mobile notifications have become a major communication channel for socialnetworking services to keep users informed and engaged. As more mobileapplications push notifications to users they constantly face decisions onwhat to send when and how. A lack of research and methodology commonly leadsto heuristic decision making. Many notifications arrive at an inappropriatemoment or introduce too many interruptions failing to provide value to usersand spurring users complaints. In this paper we explore unique features ofinteractions between mobile notifications and user engagement. We propose astate transition framework to quantitatively evaluate the effectiveness ofnotifications. Within this framework we develop a survival model for badgingnotifications assuming a loglinear structure and a Weibull distribution. Ourresults show that this model achieves more flexibility for applications andsuperior prediction accuracy than a logistic regression model. In particularwe provide an online use case on notification delivery time optimization toshow how we make better decisions drive more user engagement and provide morevalue to users.,4
Statistical and Computational Tradeoffs in Variational Inference A Case Study in Inferential Model Selection Variational inference has recently emerged as a popular alternative to theclassical Markov chain Monte Carlo MCMC in largescale Bayesian inference.The core idea of variational inference is to trade statistical accuracy forcomputational efficiency. It aims to approximate the posterior reducingcomputation costs but potentially compromising its statistical accuracy. Inthis work we study this statistical and computational tradeoff in variationalinference via a case study in inferential model selection. Focusing on Gaussianinferential models a.k.a. variational approximating families with diagonalplus lowrank precision matrices we initiate a theoretical study of thetradeoffs in two aspects Bayesian posterior inference error and frequentistuncertainty quantification error. From the Bayesian posterior inferenceperspective we characterize the error of the variational posterior relative tothe exact posterior. We prove that given a fixed computation budget alowerrank inferential model produces variational posteriors with a higherstatistical approximation error but a lower computational error it reducesvariances in stochastic optimization and in turn accelerates convergence.From the frequentist uncertainty quantification perspective we consider theprecision matrix of the variational posterior as an uncertainty estimate. Wefind that relative to the true asymptotic precision the variationalapproximation suffers from an additional statistical error originating from thesampling uncertainty of the data. Moreover this statistical error becomes thedominant factor as the computation budget increases. As a consequence forsmall datasets the inferential model need not be fullrank to achieve optimalestimation error. We finally demonstrate these statistical and computationaltradeoffs inference across empirical studies corroborating the theoreticalfindings.,4
Joint Application of the Target Trial Causal Framework and Machine Learning Modeling to Optimize Antibiotic Therapy Use Case on Acute Bacterial Skin and Skin Structure Infections due to Methicillinresistant Staphylococcus aureus Bacterial infections are responsible for high mortality worldwide.Antimicrobial resistance underlying the infection and multifaceted patientsclinical status can hamper the correct choice of antibiotic treatment.Randomized clinical trials provide average treatment effect estimates but arenot ideal for risk stratification and optimization of therapeutic choice i.e.individualized treatment effects ITE. Here we leverage largescaleelectronic health record data collected from Southern US academic clinics toemulate a clinical trial i.e. target trial and develop a machine learningmodel of mortality prediction and ITE estimation for patients diagnosed withacute bacterial skin and skin structure infection ABSSSI due tomethicillinresistant Staphylococcus aureus MRSA. ABSSSIMRSA is achallenging condition with reduced treatment options  vancomycin is thepreferred choice but it has nonnegligible side effects. First we usepropensity score matching to emulate the trial and create a treatmentrandomized vancomycin vs. other antibiotics dataset. Next we use this datato train various machine learning methods including boostedLASSO logisticregression support vector machines and random forest and choose the bestmodel in terms of area under the receiver characteristic AUC throughbootstrap validation. Lastly we use the models to calculate ITE and identifypossible averted deaths by therapy change. The outofbag tests indicate thatSVM and RF are the most accurate with AUC of  and  respectively butBLRLASSO is not far behind . By calculating the counterfactuals using theBLRLASSO vancomycin increases the risk of death but it shows a largevariation odds ratio .  range .. and the contribution to outcomeprobability is modest. Instead the RF exhibits stronger changes in ITEsuggesting more complex treatment heterogeneity.,4
Comparing Feature Importance and Rule Extraction for Interpretability on Text Data Complex machine learning algorithms are used more and more often in criticaltasks involving text data leading to the development of interpretabilitymethods. Among local methods two families have emerged those computingimportance scores for each feature and those extracting simple logical rules.In this paper we show that using different methods can lead to unexpectedlydifferent explanations even when applied to simple models for which we wouldexpect qualitative coincidence. To quantify this effect we propose a newapproach to compare explanations produced by different methods.,4
Minimax Rates for Robust Community Detection In this work we study the problem of community detection in the stochasticblock model with adversarial node corruptions. Our main result is an efficientalgorithm that can tolerate an epsilonfraction of corruptions and achieveserror Oepsilon  efracC  pm o where C  sqrta sqrtb is the signaltonoise ratio and an and bn are theintercommunity and intracommunity connection probabilities respectively.These bounds essentially match the minimax rates for the SBM withoutcorruptions. We also give robust algorithms for mathbbZsynchronization.At the heart of our algorithm is a new semidefinite program that uses globalinformation to robustly boost the accuracy of a rough clustering. Moreover weshow that our algorithms are doublyrobust in the sense that they work in aneven more challenging noise model that mixes adversarial corruptions withunbounded monotone changes from the semirandom model.,4
Semantic uncertainty intervals for disentangled latent spaces Meaningful uncertainty quantification in computer vision requires reasoningabout semantic information  say the hair color of the person in a photo orthe location of a car on the street. To this end recent breakthroughs ingenerative modeling allow us to represent semantic information in disentangledlatent spaces but providing uncertainties on the semantic latent variables hasremained challenging. In this work we provide principled uncertainty intervalsthat are guaranteed to contain the true semantic factors for any underlyinggenerative model. The method does the following  it uses quantileregression to output a heuristic uncertainty interval for each element in thelatent space  calibrates these uncertainties such that they contain the truevalue of the latent for a new unseen input. The endpoints of these calibratedintervals can then be propagated through the generator to produce interpretableuncertainty visualizations for each semantic factor. This technique reliablycommunicates semantically meaningful principled and instanceadaptiveuncertainty in inverse problems like image superresolution and imagecompletion.,4
Uniform Stability for FirstOrder Empirical Risk Minimization We consider the problem of designing uniformly stable firstorderoptimization algorithms for empirical risk minimization. Uniform stability isoften used to obtain generalization error bounds for optimization algorithmsand we are interested in a general approach to achieve it. For Euclideangeometry we suggest a blackbox conversion which given a smooth optimizationalgorithm produces a uniformly stable version of the algorithm whilemaintaining its convergence rate up to logarithmic factors. Using thisreduction we obtain a nearly optimal algorithm for smooth optimization withconvergence rate widetildeOT and uniform stability OTnresolving an open problem of Chen et al.  Attia and Koren . Formore general geometries we develop a variant of Mirror Descent for smoothoptimization with convergence rate widetildeOT and uniform stabilityOTn leaving open the question of devising a general conversion method asin the Euclidean case.,4
Nonparametric regression with modified ReLU networks We consider regression estimation with modified ReLU neural networks in whichnetwork weight matrices are first modified by a function alpha before beingmultiplied by input vectors. We give an example of continuous piecewise linearfunction alpha for which the empirical risk minimizers over the classes ofmodified ReLU networks with l and squared l penalties attain up to alogarithmic factor the minimax rate of prediction of unknown betasmoothfunction.,4
Variational Neural Networks Bayesian Neural Networks BNNs provide a tool to estimate the uncertainty ofa neural network by considering a distribution over weights and samplingdifferent models for each input. In this paper we propose a method foruncertainty estimation in neural networks called Variational Neural Networkthat instead of considering a distribution over weights generates parametersfor the output distribution of a layer by transforming its inputs withlearnable sublayers. In uncertainty quality estimation experiments we showthat VNNs achieve better uncertainty quality than Monte Carlo Dropout or BayesBy Backpropagation methods.,4
Matching Normalizing Flows and Probability Paths on Manifolds Continuous Normalizing Flows CNFs are a class of generative models thattransform a prior distribution to a model distribution by solving an ordinarydifferential equation ODE. We propose to train CNFs on manifolds byminimizing probability path divergence PPD a novel family of divergencesbetween the probability density path generated by the CNF and a targetprobability density path. PPD is formulated using a logarithmic massconservation formula which is a linear first order partial differentialequation relating the log target probabilities and the CNFs defining vectorfield. PPD has several key benefits over existing methods it sidesteps theneed to solve an ODE per iteration readily applies to manifold data scales tohigh dimensions and is compatible with a large family of target pathsinterpolating pure noise and data in finite time. Theoretically PPD is shownto bound classical probability divergences. Empirically we show that CNFslearned by minimizing PPD achieve stateoftheart results in likelihoods andsample quality on existing lowdimensional manifold benchmarks and is thefirst example of a generative model to scale to moderately high dimensionalmanifolds.,4
Forgetmenot Contrastive Critics for Mitigating Posterior Collapse Variational autoencoders VAEs suffer from posterior collapse where thepowerful neural networks used for modeling and inference optimize the objectivewithout meaningfully using the latent representation. We introduce inferencecritics that detect and incentivize against posterior collapse by requiringcorrespondence between latent variables and the observations. By connecting thecritics objective to the literature in selfsupervised contrastiverepresentation learning we show both theoretically and empirically thatoptimizing inference critics increases the mutual information betweenobservations and latents mitigating posterior collapse. This approach isstraightforward to implement and requires significantly less training time thanprior methods yet obtains competitive results on three established datasets.Overall the approach lays the foundation to bridge the previously disconnectedframeworks of contrastive learning and probabilistic modeling with variationalautoencoders underscoring the benefits both communities may find at theirintersection.,4
Breaking Feedback Loops in Recommender Systems with Causal Inference Recommender systems play a key role in shaping modern web ecosystems. Thesesystems alternate between  making recommendations  collecting userresponses to these recommendations and  retraining the recommendationalgorithm based on this feedback. During this process the recommender systeminfluences the user behavioral data that is subsequently used to update itthus creating a feedback loop. Recent work has shown that feedback loops maycompromise recommendation quality and homogenize user behavior raising ethicaland performance concerns when deploying recommender systems. To address theseissues we propose the Causal Adjustment for Feedback Loops CAFL analgorithm that provably breaks feedback loops using causal inference and can beapplied to any recommendation algorithm that optimizes a training loss. Ourmain observation is that a recommender system does not suffer from feedbackloops if it reasons about causal quantities namely the interventiondistributions of recommendations on user ratings. Moreover we can calculatethis intervention distribution from observational data by adjusting for therecommender systems predictions of user preferences. Using simulatedenvironments we demonstrate that CAFL improves recommendation quality whencompared to prior correction methods.,4
Learning Bellman Complete Representations for Offline Policy Evaluation We study representation learning for Offline Reinforcement Learning RLfocusing on the important task of Offline Policy Evaluation OPE. Recent workshows that in contrast to supervised learning realizability of the Qfunctionis not enough for learning it. Two sufficient conditions for sampleefficientOPE are Bellman completeness and coverage. Prior work often assumes thatrepresentations satisfying these conditions are given with results beingmostly theoretical in nature. In this work we propose BCRL which directlylearns from data an approximately linear Bellman complete representation withgood coverage. With this learned representation we perform OPE using LeastSquare Policy Evaluation LSPE with linear functions in our learnedrepresentation. We present an endtoend theoretical analysis showing that ourtwostage algorithm enjoys polynomial sample complexity provided somerepresentation in the rich class considered is linear Bellman complete.Empirically we extensively evaluate our algorithm on challenging imagebasedcontinuous control tasks from the Deepmind Control Suite. We show ourrepresentation enables better OPE compared to previous representation learningmethods developed for offpolicy RL e.g. CURL SPR. BCRL achieve competitiveOPE error with the stateoftheart method Fitted QEvaluation FQE and beatsFQE when evaluating beyond the initial state distribution. Our ablations showthat both linear Bellman complete and coverage components of our method arecrucial.,4
FACT HighDimensional Random Forests Inference Random forests is one of the most widely used machine learning methods overthe past decade thanks to its outstanding empirical performance. Yet becauseof its blackbox nature the results by random forests can be hard to interpretin many big data applications. Quantifying the usefulness of individualfeatures in random forests learning can greatly enhance its interpretability.Existing studies have shown that some popularly used feature importancemeasures for random forests suffer from the bias issue. In addition there lackcomprehensive size and power analyses for most of these existing methods. Inthis paper we approach the problem via hypothesis testing and suggest aframework of the selfnormalized featureresidual correlation test FACT forevaluating the significance of a given feature in the random forests model withbiasresistance property where our null hypothesis concerns whether thefeature is conditionally independent of the response given all other features.Such an endeavor on random forests inference is empowered by some recentdevelopments on highdimensional random forests consistency. The vanillaversion of our FACT test can suffer from the bias issue in the presence offeature dependency. We exploit the techniques of imbalancing and conditioningfor bias correction. We further incorporate the ensemble idea into the FACTstatistic through feature transformations for the enhanced power. Under afairly general highdimensional nonparametric model setting with dependentfeatures we formally establish that FACT can provide theoretically justifiedrandom forests feature pvalues and enjoy appealing power through nonasymptoticanalyses. The theoretical results and finitesample advantages of the newlysuggested method are illustrated with several simulation examples and aneconomic forecasting application in relation to COVID.,4
Statistical Hypothesis Testing Based on Machine Learning Large Deviations Analysis We study the performance  and specifically the rate at which the errorprobability converges to zero  of Machine Learning ML classificationtechniques. Leveraging the theory of large deviations we provide themathematical conditions for a ML classifier to exhibit error probabilities thatvanish exponentially say sim expleftnI  on right where n isthe number of informative observations available for testing or anotherrelevant parameter such as the size of the target in an image and I is theerror rate. Such conditions depend on the FenchelLegendre transform of thecumulantgenerating function of the DataDriven Decision Function DF i.e.what is thresholded before the final binary decision is made learned in thetraining phase. As such the DF and consequently the related error rate Idepend on the given training set which is assumed of finite size.Interestingly these conditions can be verified and tested numericallyexploiting the available dataset or a synthetic dataset generated accordingto the available information on the underlying statistical model. In otherwords the classification error probability convergence to zero and its ratecan be computed on a portion of the dataset available for training. Coherentlywith the large deviations theory we can also establish the convergence forn large enough of the normalized DF statistic to a Gaussian distribution.This property is exploited to set a desired asymptotic false alarm probabilitywhich empirically turns out to be accurate even for quite realistic values ofn. Furthermore approximate error probability curves sim zetanexpleftnI right are provided thanks to the refined asymptoticderivation often referred to as exact asymptotics where zetan representsthe most representative subexponential terms of the error probabilities.,4
Markovian Gaussian Process Variational Autoencoders Deep generative models are widely used for modelling highdimensional timeseries such as video animations audio and climate data. Sequentialvariational autoencoders have been successfully considered for manyapplications with many variant models relying on discretetime methods andrecurrent neural networks RNNs. On the other hand continuoustime methodshave recently gained attraction especially in the context ofirregularlysampled time series where they can better handle the data thandiscretetime methods. One such class are Gaussian process variationalautoencoders GPVAEs where the VAE prior is set as a Gaussian process GPsallowing inductive biases to be explicitly encoded via the kernel function andinterpretability of the latent space. However a major limitation of GPVAEs isthat it inherits the same cubic computational cost as GPs. In this work weleverage the equivalent discrete state space representation of Markovian GPs toenable a lineartime GP solver via Kalman filtering and smoothing. We show viacorrupt and missing frames tasks that our method performs favourablyespecially on the latter where it outperforms RNNbased models.,4
Look beyond labels Incorporating functional summary information in Bayesian neural networks Bayesian deep learning offers a principled approach to train neural networksthat accounts for both aleatoric and epistemic uncertainty. In variationalinference priors are often specified over the weight parameters but they donot capture the true prior knowledge in large and complex neural networkarchitectures. We present a simple approach to incorporate summary informationabout the predicted probability such as sigmoid or softmax score outputs inBayesian neural networks BNNs. The available summary information isincorporated as augmented data and modeled with a Dirichlet process and wederive the corresponding emphSummary Evidence Lower BOund. We show how themethod can inform the model about task difficulty or class imbalance. Extensiveempirical experiments show that with negligible computational overhead theproposed method yields a BNN with a better calibration of uncertainty.,4
Modeling Randomly Walking Volatility with Chained Gamma Distributions Volatility clustering is a common phenomenon in financial time series.Typically linear models can be used to describe the temporal autocorrelationof the logarithmic variance of returns. Considering the difficulty inestimating this model we construct a Dynamic Bayesian Network which utilizesthe conjugate prior relation of normalgamma and gammagamma so that itsposterior form locally remains unchanged at each node. This makes it possibleto find approximate solutions using variational methods quickly. Furthermorewe ensure that the volatility expressed by the model is an independentincremental process after inserting dummy gamma nodes between adjacent timesteps. We have found that this model has two advantages  It can be provedthat it can express heavier tails than Gaussians i.e. have positive excesskurtosis compared to popular linear models.  If the variationalinferenceVI is used for state estimation it runs much faster than MonteCarloMC methods since the calculation of the posterior uses only basicarithmetic operations. And its convergence process is deterministic.,4
Learning structures of the French clinical languagedevelopment and validation of word embedding models using  million clinical reports from electronic health records Background,4
Correcting Model Bias with Sparse Implicit Processes Model selection in machine learning ML is a crucial part of the Bayesianlearning procedure. Model choice may impose strong biases on the resultingpredictions which can hinder the performance of methods such as Bayesianneural networks and neural samplers. On the other hand newly proposedapproaches for Bayesian ML exploit features of approximate inference infunction space with implicit stochastic processes a generalization of Gaussianprocesses. The approach of Sparse Implicit Processes SIP is particularlysuccessful in this regard since it is fully trainable and achieves flexiblepredictions. Here we expand on the original experiments to show that SIP iscapable of correcting model bias when the data generating mechanism differsstrongly from the one implied by the model. We use synthetic datasets to showthat SIP is capable of providing predictive distributions that reflect the databetter than the exact predictions of the initial but wrongly assumed model.,4
BiTAT Neural Network Binarization with Taskdependent Aggregated Transformation Neural network quantization aims to transform highprecision weights andactivations of a given neural network into lowprecision weightsactivationsfor reduced memory usage and computation while preserving the performance ofthe original model. However extreme quantization bit weightbitactivations of compactlydesigned backbone architectures e.g. MobileNetsoften used for edgedevice deployments results in severe performancedegeneration. This paper proposes a novel QuantizationAware Training QATmethod that can effectively alleviate performance degeneration even withextreme quantization by focusing on the interweight dependencies between theweights within each layer and across consecutive layers. To minimize thequantization impact of each weight on others we perform an orthonormaltransformation of the weights at each layer by training an inputdependentcorrelation matrix and importance vector such that each weight is disentangledfrom the others. Then we quantize the weights based on their importance tominimize the loss of the information from the original weightsactivations. Wefurther perform progressive layerwise quantization from the bottom layer tothe top so that quantization at each layer reflects the quantizeddistributions of weights and activations at previous layers. We validate theeffectiveness of our method on various benchmark datasets against strong neuralquantization baselines demonstrating that it alleviates the performancedegeneration on ImageNet and successfully preserves the fullprecision modelperformance on CIFAR with compact backbone networks.,4
Selection of the Most Probable Best We consider an expectedvalue ranking and selection problem where all ksolutions simulation outputs depend on a common uncertain input model. Giventhat the uncertainty of the input model is captured by a probability simplex ona finite support we define the most probable best MPB to be the solutionwhose probability of being optimal is the largest. To devise an efficientsampling algorithm to find the MPB we first derive a lower bound to the largedeviation rate of the probability of falsely selecting the MPB then formulatean optimal computing budget allocation OCBA problem to find the optimalstatic sampling ratios for all solutioninput model pairs that maximize thelower bound. We devise a series of sequential algorithms that applyinterpretable and computationally efficient sampling rules and prove theirsampling ratios achieve the optimality conditions for the OCBA problem as thesimulation budget increases. The algorithms are benchmarked against astateoftheart sequential sampling algorithm designed for contextual rankingand selection problems and demonstrated to have superior empirical performancesat finding the MPB.,4
A Universal Tradeoff Between the Model Size Test Loss and Training Loss of Linear Predictors In this work we establish an algorithm and distribution independentnonasymptotic tradeoff between the model size excess test loss and trainingloss of linear predictors. Specifically we show that models that perform wellon the test data have low excess loss are either classical  have trainingloss close to the noise level or are modern  have a much larger number ofparameters compared to the minimum needed to fit the training data exactly.,4
Flowsheet synthesis through hierarchical reinforcement learning and graph neural networks Process synthesis experiences a disruptive transformation accelerated bydigitization and artificial intelligence. We propose a reinforcement learningalgorithm for chemical process design based on a stateoftheart actorcriticlogic. Our proposed algorithm represents chemical processes as graphs and usesgraph convolutional neural networks to learn from process graphs. Inparticular the graph neural networks are implemented within the agentarchitecture to process the states and make decisions. Moreover we implement ahierarchical and hybrid decisionmaking process to generate flowsheets whereunit operations are placed iteratively as discrete decisions and correspondingdesign variables are selected as continuous decisions. We demonstrate thepotential of our method to design economically viable flowsheets in anillustrative case study comprising equilibrium reactions azeotropicseparation and recycles. The results show quick learning in discretecontinuous and hybrid action spaces. Due to the flexible architecture of theproposed reinforcement learning agent the method is predestined to includelarge actionstate spaces and an interface to process simulators in futureresearch.,4
Characterizing the Effect of Class Imbalance on the Learning Dynamics Data imbalance is a common problem in the machine learning literature thatcan have a critical effect on the performance of a model. Various solutionsexist  such as the ones that focus on resampling or data generation  buttheir impact on the convergence of gradientbased optimizers used in deeplearning is not understood. We here elucidate the significant negative impactof data imbalance on learning showing that the learning curves for minorityand majority classes follow suboptimal trajectories when training with agradientbased optimizer. The reason is not only that the gradient signalneglects the minority classes but also that the minority classes are subjectto a larger directional noise which slows their learning by an amount relatedto the imbalance ratio. To address this problem we propose a new algorithmicsolution for which we provide a detailed analysis of its convergence behavior.We show both theoretically and empirically that this new algorithm exhibits abetter behavior with more stable learning curves for each class as well as abetter generalization performance.,4
Improved conformalized quantile regression Conformalized quantile regression is a procedure that inherits the advantagesof conformal prediction and quantile regression. That is we use quantileregression to estimate the true conditional quantile and then apply a conformalstep on a calibration set to ensure marginal coverage. In this way we getadaptive prediction intervals that account for heteroscedasticity. However theaforementioned conformal step lacks adaptiveness as described in Romano etal. . To overcome this limitation instead of applying a single conformalstep after estimating conditional quantiles with quantile regression wepropose to cluster the explanatory variables weighted by their permutationimportance with an optimized kmeans and apply k conformal steps. To show thatthis improved version outperforms the classic version of conformalized quantileregression and is more adaptive to heteroscedasticity we extensively comparethe prediction intervals of both in open datasets.,4
Offthegrid learning of sparse mixtures from a continuous dictionary We consider a general nonlinear model where the signal is a finite mixtureof an unknown possibly increasing number of features issued from a continuousdictionary parameterized by a real nonlinear parameter. The signal is observedwith Gaussian possibly correlated noise in either a continuous or a discretesetup. We propose an offthegrid optimization method that is a method whichdoes not use any discretization scheme on the parameter space to estimate boththe nonlinear parameters of the features and the linear parameters of themixture. We use recent results on the geometry of offthegrid methods to giveminimal separation on the true underlying nonlinear parameters such thatinterpolating certificate functions can be constructed. Using also tail boundsfor suprema of Gaussian processes we bound the prediction error with highprobability. Assuming that the certificate functions can be constructed ourprediction error bound is up to log factors similar to the rates attained bythe Lasso predictor in the linear regression model. We also establishconvergence rates that quantify with high probability the quality of estimationfor both the linear and the nonlinear parameters.,4
Jackknife Variability Estimation For Randomized Matrix Computations Randomized algorithms based on sketching have become a workhorse tool inlowrank matrix approximation. To use these algorithms safely in applicationsthey should be coupled with diagnostics to assess the quality of approximation.To meet this need this paper proposes a jackknife resampling method toestimate the variability of the output of a randomized matrix computation. Thevariability estimate can recognize that a computation requires additional dataor that the computation is intrinsically unstable. As examples the paperstudies jackknife estimates for two randomized lowrank matrix approximationalgorithms. In each case the operation count for the jackknife estimate isindependent of the dimensions of the target matrix. In numerical experimentsthe estimator accurately assesses variability and also provides anorderofmagnitude estimate of the meansquare error.,4
Differentially Private Estimation via Statistical Depth Constructing a differentially private DP estimator requires deriving themaximum influence of an observation which can be difficult in the absence ofexogenous bounds on the input data or the estimator especially in highdimensional settings. This paper shows that standard notions of statisticaldepth i.e. halfspace depth and regression depth are particularlyadvantageous in this regard both in the sense that the maximum influence of asingle observation is easy to analyze and that this value is typically low.This is used to motivate new approximate DP location and regression estimatorsusing the maximizers of these two notions of statistical depth. A morecomputationally efficient variant of the approximate DP regression estimator isalso provided. Also to avoid requiring that users specify a priori bounds onthe estimates andor the observations variants of these DP mechanisms aredescribed that satisfy random differential privacy RDP which is a relaxationof differential privacy provided by Hall Wasserman and Rinaldo . Wealso provide simulations of the two DP regression methods proposed here. Theproposed estimators appear to perform favorably relative to the existing DPregression methods we consider in these simulations when either the sample sizeis at least  or the privacyloss budget is sufficiently high.,4
Package for Fast ABCBoost This report presents the opensource package which implements the series ofour boosting works in the past years. In particular the package includesmainly three lines of techniques among which the following two are already thestandard implementations in popular boosted tree platforms,4
KullbackLeibler and Renyi divergences in reproducing kernel Hilbert space and Gaussian process settings In this work we present formulations for regularized KullbackLeibler andRnyi divergences via the Alpha LogDeterminant LogDet divergences betweenpositive HilbertSchmidt operators on Hilbert spaces in two different settingsnamely i covariance operators and Gaussian measures defined on reproducingkernel Hilbert spaces RKHS and ii Gaussian processes with squaredintegrable sample paths. For characteristic kernels the first setting leads todivergences between arbitrary Borel probability measures on a completeseparable metric space. We show that the Alpha LogDet divergences arecontinuous in the HilbertSchmidt norm which enables us to apply laws of largenumbers for Hilbert spacevalued random variables. As a consequence of this weshow that in both settings the infinitedimensional divergences can beconsistently and efficiently estimated from their finitedimensional versionsusing finitedimensional Gram matricesGaussian measures and finite sampledata with it dimensionindependent sample complexities in all cases. RKHSmethodology plays a central role in the theoretical analysis in both settings.The mathematical formulation is illustrated by numerical experiments.,4
Efficient One Sided Kolmogorov Approximation We present an efficient algorithm that given a discrete random variable Xand a number m computes a random variable whose support is of size at mostm and whose Kolmogorov distance from X is minimal also for the onesidedKolmogorov approximation. We present some variants of the algorithm analysetheir correctness and computational complexity and present a detailedempirical evaluation that shows how they performs in practice. The mainapplication that we examine which is our motivation for this work isestimation of the probability missing deadlines in seriesparallel schedules.Since exact computation of these probabilities is NPhard we propose to usethe algorithms described in this paper to obtain an approximation.,4
Efficient Search of Multiple Neural Architectures with Different Complexities via Importance Sampling Neural architecture search NAS aims to automate architecture designprocesses and improve the performance of deep neural networks. PlatformawareNAS methods consider both performance and complexity and can findwellperforming architectures with low computational resources. Althoughordinary NAS methods result in tremendous computational costs owing to therepetition of model training oneshot NAS which trains the weights of asupernetwork containing all candidate architectures only once during the searchprocess has been reported to result in a lower search cost. This study focuseson the architecture complexityaware oneshot NAS that optimizes the objectivefunction composed of the weighted sum of two metrics such as the predictiveperformance and number of parameters. In existing methods the architecturesearch process must be run multiple times with different coefficients of theweighted sum to obtain multiple architectures with different complexities. Thisstudy aims at reducing the search cost associated with finding multiplearchitectures. The proposed method uses multiple distributions to generatearchitectures with different complexities and updates each distribution usingthe samples obtained from multiple distributions based on importance sampling.The proposed method allows us to obtain multiple architectures with differentcomplexities in a single architecture search resulting in reducing the searchcost. The proposed method is applied to the architecture search ofconvolutional neural networks on the CIAFR and ImageNet datasets.Consequently compared with baseline methods the proposed method findsmultiple architectures with varying complexities while requiring lesscomputational effort.,4
Probabilistic Reconciliation of Count Time Series We propose a principled method for the reconciliation of any probabilisticbase forecasts. We show how probabilistic reconciliation can be obtained bymerging via Bayes rule the information contained in the base forecast forthe bottom and the upper time series. We illustrate our method on a toyhierarchy showing how our framework allows the probabilistic reconciliation ofany base forecast. We perform experiment in the reconciliation of temporalhierarchies of count time series obtaining major improvements compared toprobabilistic reconciliation based on the Gaussian or the truncated Gaussiandistribution.,4
Edge Augmentation on Disconnected Graphs via Eigenvalue Elevation The graphtheoretical task of determining most likely intercommunity edgesbased on disconnected subgraphs intracommunity connectivity is proposed. Analgorithm is developed for this edge augmentation task based on elevating thezero eigenvalues of graphs spectrum. Upper bounds for eigenvalue elevationamplitude and for the corresponding augmented edge density are derived and areauthenticated with simulation on random graphs. The algorithm worksconsistently across synthetic and real networks yielding desirable performanceat connecting graph components. Edge augmentation reverseengineers graphpartition under different community detection methods GirvanNewman methodgreedy modularity maximization label propagation Louvain method and fluidcommunity in most cases producing intercommunity edges at  frequency.,4
Representing Random Utility Choice Models with Neural Networks Motivated by the successes of deep learning we propose a class of neuralnetworkbased discrete choice models called RUMnets which is inspired by therandom utility maximization RUM framework. This model formulates the agentsrandom utility function using the sample average approximation SAA method. Weshow that RUMnets sharply approximate the class of RUM discrete choice modelsany model derived from random utility maximization has choice probabilitiesthat can be approximated arbitrarily closely by a RUMnet. Reciprocally anyRUMnet is consistent with the RUM principle. We derive an upper bound on thegeneralization error of RUMnets fitted on choice data and gain theoreticalinsights on their ability to predict choices on new unseen data depending oncritical parameters of the dataset and architecture. By leveraging opensourcelibraries for neural networks we find that RUMnets outperform otherstateoftheart choice modeling and machine learning methods by a significantmargin on two realworld datasets.,4
A Federated Cox Model with NonProportional Hazards Recent research has shown the potential for neural networks to improve uponclassical survival models such as the Cox model which is widely used inclinical practice. Neural networks however typically rely on data that arecentrally available whereas healthcare data are frequently held in securesilos. We present a federated Cox model that accommodates this data setting andalso relaxes the proportional hazards assumption allowing timevaryingcovariate effects. In this latter respect our model does not require explicitspecification of the timevarying effects reducing upfront organisationalcosts compared to previous works. We experiment with publicly availableclinical datasets and demonstrate that the federated model is able to performas well as a standard model.,4
Wasserstein multivariate autoregressive models for modeling distributional time series and its application in graph learning We propose a new autoregressive model for the statistical analysis ofmultivariate distributional time series. The data of interest consist of acollection of multiple series of probability measures supported over a boundedinterval of the real line and that are indexed by distinct time instants. Theprobability measures are modelled as random objects in the Wasserstein space.We establish the autoregressive model in the tangent space at the Lebesguemeasure by first centering all the raw measures so that their Frchet meansturn to be the Lebesgue measure. Using the theory of iterated random functionsystems results on the existence uniqueness and stationarity of the solutionof such a model are provided. We also propose a consistent estimator for themodel coefficient. In addition to the analysis of simulated data the proposedmodel is illustrated with two real data sets made of observations from agedistribution in different countries and bike sharing network in Paris. Finallydue to the positive and boundedness constraints that we impose on the modelcoefficients the proposed estimator that is learned under these constraintsnaturally has a sparse structure. The sparsity allows furthermore theapplication of the proposed model in learning a graph of temporal dependencyfrom the multivariate distributional time series.,4
Blessing of Nonconvexity in Deep Linear Models Depth Flattens the Optimization Landscape Around the True Solution This work characterizes the effect of depth on the optimization landscape oflinear regression showing that despite their nonconvexity deeper models havemore desirable optimization landscape. We consider a robust andoverparameterized setting where a subset of measurements are grosslycorrupted with noise and the true linear model is captured via an Nlayerlinear neural network. On the negative side we show that this problemtextitdoes not have a benign landscape given any Ngeq  with constantprobability there exists a solution corresponding to the ground truth that isneither local nor global minimum. However on the positive side we prove thatfor any Nlayer model with Ngeq  a simple subgradient method becomesoblivious to such problematic solutions instead it converges to abalanced solution that is not only close to the ground truth but also enjoys aflat local landscape thereby eschewing the need for early stopping. Lastlywe empirically verify that the desirable optimization landscape of deepermodels extends to other robust learning tasks including deep matrix recoveryand deep ReLU networks with ellloss.,4
Orthogonalization of data via GromovWasserstein type feedback for clustering and visualization In this paper we propose an adaptive approach for clustering andvisualization of data by an orthogonalization process. Starting with the datapoints being represented by a Markov process using the diffusion map frameworkthe method adaptively increase the orthogonality of the clusters by applying afeedback mechanism inspired by the GromovWasserstein distance. This mechanismiteratively increases the spectral gap and refines the orthogonality of thedata to achieve a clustering with high specificity. By using the diffusion mapframework and representing the relation between data points using transitionprobabilities the method is robust with respect to both the underlyingdistance noise in the data and random initialization. We prove that the methodconverges globally to a unique fixpoint for certain parameter values. We alsopropose a related approach where the transition probabilities in the Markovprocess are required to be doubly stochastic in which case the methodgenerates a minimizer to a nonconvex optimization problem. We apply the methodon cryoelectron microscopy image data from biopharmaceutical manufacturingwhere we can confirm biologically relevant insights related to therapeuticefficacy. We consider an example with morphological variations of genepackaging and confirm that the method produces biologically meaningfulclustering results consistent with human expert classification.,4
Adaptive StepSize Methods for Compressed SGD Compressed Stochastic Gradient Descent SGD algorithms have been recentlyproposed to address the communication bottleneck in distributed anddecentralized optimization problems such as those that arise in federatedmachine learning. Existing compressed SGD algorithms assume the use ofnonadaptive stepsizesconstant or diminishing to provide theoreticalconvergence guarantees. Typically the stepsizes are finetuned in practice tothe dataset and the learning algorithm to provide good empirical performance.Such finetuning might be impractical in many learning scenarios and it istherefore of interest to study compressed SGD using adaptive stepsizes.Motivated by prior work on adaptive stepsize methods for SGD to train neuralnetworks efficiently in the uncompressed setting we develop an adaptivestepsize method for compressed SGD. In particular we introduce a scalingtechnique for the descent step in compressed SGD which we use to establishorderoptimal convergence rates for convexsmooth and strong convexsmoothobjectives under an interpolation condition and for nonconvex objectives undera strong growth condition. We also show through simulation examples thatwithout this scaling the algorithm can fail to converge. We presentexperimental results on deep neural networks for realworld datasets andcompare the performance of our proposed algorithm with previously proposedcompressed SGD methods in literature and demonstrate improved performance onResNet ResNet and DenseNet architectures for CIFAR and CIFARdatasets at various levels of compression.,4
Journal Impact Factor and Peer Review Thoroughness and Helpfulness A Supervised Machine Learning Study The journal impact factor JIF is often equated with journal quality and thequality of the peer review of the papers submitted to the journal. We examinedthe association between the content of peer review and JIF by analysing peer review reports submitted to  medical and life sciences journals. Tworesearchers handcoded a random sample of  sentences. We then trainedmachine learning models to classify all  sentences as contributing ornot contributing to content categories. We examined the association between tengroups of journals defined by JIF deciles and the content of peer reviews usinglinear mixedeffects models adjusting for the length of the review. The JIFranged from . to .. The length of peer reviews increased from the lowestmedian number of words  to the JIF group  words. The proportion ofsentences allocated to different content categories varied widely even withinJIF groups. For thoroughness sentences on Materials and Methods were morecommon in the highest JIF journals than in the lowest JIF group difference of. percentage points  CI . to .. The trend for Presentation andReporting went in the opposite direction with the highest JIF journals givingless emphasis to such content difference .  CI . to .. Forhelpfulness reviews for higher JIF journals devoted less attention toSuggestion and Solution and provided fewer Examples than lower impact factorjournals. No or only small differences were evident for other contentcategories. In conclusion peer review in journals with higher JIF tends to bemore thorough in discussing the methods used but less helpful in terms ofsuggesting solutions and providing examples. Differences were modest andvariability high indicating that the JIF is a bad predictor for the quality ofpeer review of an individual manuscript.,4
FeedForward SourceFree Latent Domain Adaptation via CrossAttention We study the highly practical but comparatively understudied problem oflatentdomain adaptation where a source model should be adapted to a targetdataset that contains a mixture of unlabelled domainrelevant anddomainirrelevant examples. Furthermore motivated by the requirements for dataprivacy and the need for embedded and resourceconstrained devices of all kindsto adapt to local data distributions we focus on the setting of feedforwardsourcefree domain adaptation where adaptation should not require access tothe source dataset and also be back propagationfree. Our solution is tometalearn a network capable of embedding the mixedrelevance target datasetand dynamically adapting inference for target examples using crossattention.The resulting framework leads to consistent improvement on strong ERMbaselines. We also show that our framework sometimes even improves on the upperbound of domainsupervised adaptation where only domainrelevant instances areprovided for adaptation. This suggests that human annotated domain labels maynot always be optimal and raises the possibility of doing better throughautomated instance selection.,4
