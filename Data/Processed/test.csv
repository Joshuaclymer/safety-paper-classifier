text,label
Unsolved Problems in ML Safety Machine learning  ML  systems are rapidly increasing in size  are acquiring new capabilities  and are increasingly deployed in high stakes settings. As with other powerful technologies  safety for ML should be a leading research priority. In response to emerging safety challenges in ML  such as those introduced by recent large scale models  we provide a new roadmap for ML Safety and refine the technical problems that the field needs to address. We present four problems ready for research  namely withstanding hazards   Robustness    identifying hazards   Monitoring    reducing inherent model hazards   Alignment    and reducing systemic hazards   Systemic Safety  . Throughout  we clarify each problem s motivation and provide concrete research directions.,0
Provably Safe Reinforcement Learning  A Theoretical and Experimental Comparison Ensuring safety of reinforcement learning  RL  algorithms is crucial for many real world tasks. However  vanilla RL does not guarantee safety for an agent. In recent years  several methods have been proposed to provide safety guarantees for RL. To the best of our knowledge  there is no comprehensive comparison of these provably safe RL methods. We therefore introduce a categorization for existing provably safe RL methods  and present the theoretical foundations for both continuous and discrete action spaces. Additionally  we evaluate provably safe RL on an inverted pendulum. In the experiments  it is shown that indeed only provably safe RL methods guarantee safety.,0
Deep Imitative Models for Flexible Inference  Planning  and Control Imitation Learning  IL  is an appealing approach to learn desirable autonomous behavior. However  directing IL to achieve arbitrary goals is difficult. In contrast  planning based algorithms use dynamics models and reward functions to achieve goals. Yet  reward functions that evoke desirable behavior are often difficult to specify. In this paper  we propose Imitative Models to combine the benefits of IL and goal directed planning. Imitative Models are probabilistic predictive models of desirable behavior able to plan interpretable expert like trajectories to achieve specified goals. We derive families of flexible goal objectives  including constrained goal regions  unconstrained goal sets  and energy based goals. We show that our method can use these objectives to successfully direct behavior. Our method substantially outperforms six IL approaches and a planning based approach in a dynamic simulated autonomous driving task  and is efficiently learned from expert demonstrations without online data collection. We also show our approach is robust to poorly specified goals  such as goals on the wrong side of the road.,0
One shot Neural Backdoor Erasing via Adversarial Weight Masking Recent studies show that despite achieving high accuracy on a number of real world applications  deep neural networks  DNNs  can be backdoored  by injecting triggered data samples into the training dataset  the adversary can mislead the trained model into classifying any test data to the target class as long as the trigger pattern is presented. To nullify such backdoor threats  various methods have been proposed. Particularly  a line of research aims to purify the potentially compromised model. However  one major limitation of this line of work is the requirement to access sufficient original training data  the purifying performance is a lot worse when the available training data is limited. In this work  we propose Adversarial Weight Masking  AWM   a novel method capable of erasing the neural backdoors even in the one shot setting. The key idea behind our method is to formulate this into a min max optimization problem  first  adversarially recover the trigger patterns and then  soft  mask the network weights that are sensitive to the recovered patterns. Comprehensive evaluations of several benchmark datasets suggest that AWM can largely improve the purifying effects over other state of the art methods on various available training dataset sizes.,0
Natural Language Descriptions of Deep Visual Features Some neurons in deep networks specialize in recognizing highly specific perceptual  structural  or semantic features of inputs. In computer vision  techniques exist for identifying neurons that respond to individual concept categories like colors  textures  and object classes. But these techniques are limited in scope  labeling only a small subset of neurons and behaviors in any network. Is a richer characterization of neuron level computation possible  We introduce a procedure  called MILAN  for mutual information guided linguistic annotation of neurons  that automatically labels neurons with open ended  compositional  natural language descriptions. Given a neuron  MILAN generates a description by searching for a natural language string that maximizes pointwise mutual information with the image regions in which the neuron is active. MILAN produces fine grained descriptions that capture categorical  relational  and logical structure in learned features. These descriptions obtain high agreement with human generated feature descriptions across a diverse set of model architectures and tasks  and can aid in understanding and controlling learned models. We highlight three applications of natural language neuron descriptions. First  we use MILAN for analysis  characterizing the distribution and importance of neurons selective for attribute  category  and relational information in vision models. Second  we use MILAN for auditing  surfacing neurons sensitive to human faces in datasets designed to obscure them. Finally  we use MILAN for editing  improving robustness in an image classifier by deleting neurons sensitive to text features spuriously correlated with class labels.,0
Grokking  Generalization Beyond Overfitting on Small Algorithmic Datasets In this paper we propose to study generalization of neural networks on small algorithmically generated datasets. In this setting  questions about data efficiency  memorization  generalization  and speed of learning can be studied in great detail. In some situations we show that neural networks learn through a process of  grokking  a pattern in the data  improving generalization performance from random chance level to perfect generalization  and that this improvement in generalization can happen well past the point of overfitting. We also study generalization as a function of dataset size and find that smaller datasets require increasing amounts of optimization for generalization. We argue that these datasets provide a fertile ground for studying a poorly understood aspect of deep learning  generalization of overparametrized neural networks beyond memorization of the finite training dataset.,0
ViM  Out Of Distribution with Virtual logit Matching Most of the existing Out Of Distribution  OOD  detection algorithms depend on single input source  the feature  the logit  or the softmax probability. However  the immense diversity of the OOD examples makes such methods fragile. There are OOD samples that are easy to identify in the feature space while hard to distinguish in the logit space and vice versa. Motivated by this observation  we propose a novel OOD scoring method named Virtual logit Matching  ViM   which combines the class agnostic score from feature space and the In Distribution  ID  class dependent logits. Specifically  an additional logit representing the virtual OOD class is generated from the residual of the feature against the principal space  and then matched with the original logits by a constant scaling. The probability of this virtual logit after softmax is the indicator of OOD ness. To facilitate the evaluation of large scale OOD detection in academia  we create a new OOD dataset for ImageNet  K  which is human annotated and is  . x the size of existing datasets. We conducted extensive experiments  including CNNs and vision transformers  to demonstrate the effectiveness of the proposed ViM score. In particular  using the BiT S model  our method gets an average AUROC   .    on four difficult OOD benchmarks  which is    ahead of the best baseline. Code and dataset are available at,0
Understanding Game Playing Agents with Natural Language Annotations We present a new dataset containing   K human annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability. Given a board state and its associated comment  our approach uses linear probing to predict mentions of domain specific terms  e.g.  ko  atari  from the intermediate state representations of game playing agents like AlphaGo Zero. We find these game concepts are nontrivially encoded in two distinct policy networks  one trained via imitation learning and another trained via reinforcement learning. Furthermore  mentions of domain specific terms are most easily predicted from the later layers of both models  suggesting that these policy networks encode high level abstractions similar to those used in the natural language annotations.,0
Increasing Confidence in Adversarial Robustness Evaluations Hundreds of defenses have been proposed to make deep neural networks robust against minimal  adversarial  input perturbations. However  only a handful of these defenses held up their claims because correctly evaluating robustness is extremely challenging  Weak attacks often fail to find adversarial examples even if they unknowingly exist  thereby making a vulnerable network look robust. In this paper  we propose a test to identify weak attacks  and thus weak defense evaluations. Our test slightly modifies a neural network to guarantee the existence of an adversarial example for every sample. Consequentially  any correct attack must succeed in breaking this modified network. For eleven out of thirteen previously published defenses  the original evaluation of the defense fails our test  while stronger attacks that break these defenses pass it. We hope that attack unit tests   such as ours   will be a major component in future robustness evaluations and increase confidence in an empirical field that is currently riddled with skepticism.,0
Smooth Adversarial Training It is commonly believed that networks cannot be both accurate and robust  that gaining robustness means losing accuracy. It is also generally believed that  unless making networks larger  network architectural elements would otherwise matter little in improving adversarial robustness. Here we present evidence to challenge these common beliefs by a careful study about adversarial training. Our key observation is that the widely used ReLU activation function significantly weakens adversarial training due to its non smooth nature. Hence we propose smooth adversarial training  SAT   in which we replace ReLU with its smooth approximations to strengthen adversarial training. The purpose of smooth activation functions in SAT is to allow it to find harder adversarial examples and compute better gradient updates during adversarial training.,0
Adversarial Examples for Evaluating Reading Comprehension Systems Standard accuracy metrics indicate that reading comprehension systems are making rapid progress  but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities  we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset  SQuAD . Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences  which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting  the accuracy of sixteen published models drops from an average of        F  score to         when the adversary is allowed to add ungrammatical sequences of words  average accuracy on four models decreases further to      . We hope our insights will motivate the development of new models that understand language more precisely.,0
BERT ATTACK  Adversarial Attack Against BERT Using BERT Adversarial attacks for discrete data  such as texts  have been proved significantly more challenging than continuous data  such as images  since it is difficult to generate adversarial samples with gradient based methods. Current successful attack methods for texts usually adopt heuristic replacement strategies on the character or word level  which remains challenging to find the optimal solution in the massive space of possible combinations of replacements while preserving semantic consistency and language fluency. In this paper  we propose  textbf BERT Attack   a high quality and effective method to generate adversarial samples using pre trained masked language models exemplified by BERT. We turn BERT against its fine tuned models and other deep neural models in downstream tasks so that we can successfully mislead the target models to predict incorrectly. Our method outperforms state of the art attack strategies in both success rate and perturb percentage  while the generated adversarial samples are fluent and semantically preserved. Also  the cost of calculation is low  thus possible for large scale generations. The code is available at,0
Back to the Source  Diffusion Driven Test Time Adaptation Test time adaptation harnesses test inputs to improve the accuracy of a model trained on source data when tested on shifted target data. Existing methods update the source model by  re  training on each target domain. While effective  re training is sensitive to the amount and order of the data and the hyperparameters for optimization. We instead update the target data  by projecting all test inputs toward the source domain with a generative diffusion model. Our diffusion driven adaptation method  DDA  shares its models for classification and generation across all domains. Both models are trained on the source domain  then fixed during testing. We augment diffusion with image guidance and self ensembling to automatically decide how much to adapt. Input adaptation by DDA is more robust than prior model adaptation approaches across a variety of corruptions  architectures  and data regimes on the ImageNet C benchmark. With its input wise updates  DDA succeeds where model adaptation degrades on too little data in small batches  dependent data in non uniform order  or mixed data with multiple corruptions.,0
On Single Point Forecasts for Fat Tailed Variables We discuss common errors and fallacies when using naive  evidence based  empiricism and point forecasts for fat tailed variables  as well as the insufficiency of using naive first order scientific methods for tail risk management. We use the COVID    pandemic as the background for the discussion and as an example of a phenomenon characterized by a multiplicative nature  and what mitigating policies must result from the statistical properties and associated risks. In doing so  we also respond to the points raised by Ioannidis et al.       .,0
Forecasting Future World Events with Neural Networks Forecasting future world events is a challenging but valuable task. Forecasts of climate  geopolitical conflict  pandemics and economic indicators help shape policy and decision making. In these domains  the judgment of expert humans contributes to the best forecasts. Given advances in language modeling  can these forecasts be automated  To this end  we introduce Autocast  a dataset containing thousands of forecasting questions and an accompanying news corpus. Questions are taken from forecasting tournaments  ensuring high quality  real world importance  and diversity. The news corpus is organized by date  allowing us to precisely simulate the conditions under which humans made past forecasts  avoiding leakage from the future . Motivated by the difficulty of forecasting numbers across orders of magnitude  e.g. global cases of COVID    in        we also curate IntervalQA  a dataset of numerical questions and metrics for calibration. We test language models on our forecasting task and find that performance is far below a human expert baseline. However  performance improves with increased model size and incorporation of relevant information from the news corpus. In sum  Autocast poses a novel challenge for large language models and improved performance could bring large practical benefits.,0
Grounding Aleatoric Uncertainty in Unsupervised Environment Design Adaptive curricula in reinforcement learning  RL  have proven effective for producing policies robust to discrepancies between the train and test environment. Recently  the Unsupervised Environment Design  UED  framework generalized RL curricula to generating sequences of entire environments  leading to new methods with robust minimax regret properties. Problematically  in partially observable or stochastic settings  optimal policies may depend on the ground truth distribution over aleatoric parameters of the environment in the intended deployment setting  while curriculum learning necessarily shifts the training distribution. We formalize this phenomenon as curriculum induced covariate shift  CICS   and describe how its occurrence in aleatoric parameters can lead to suboptimal policies. Directly sampling these parameters from the ground truth distribution avoids the issue  but thwarts curriculum learning. We propose SAMPLR  a minimax regret UED method that optimizes the ground truth utility function  even when the underlying training data is biased due to CICS. We prove  and validate on challenging domains  that our approach preserves optimality under the ground truth distribution  while promoting robustness across the full range of environment settings.,1
Online Lewis Weight Sampling The seminal work of Cohen and Peng introduced Lewis weight sampling to the theoretical computer science community  yielding fast row sampling algorithms for approximating  d  dimensional subspaces of   ell p  up to      epsilon   error. Several works have extended this important primitive to other settings  including the online coreset  sliding window  and adversarial streaming models. However  these results are only for  p in          and results for  p    require a suboptimal   tilde O d    epsilon     samples.,1
Using Model Based Trees with Boosting to Fit Low Order Functional ANOVA Models Low order functional ANOVA  fANOVA  models have been rediscovered in the machine learning  ML  community under the guise of inherently interpretable machine learning. Explainable Boosting Machines or EBM  Lou et al.       and GAMI Net  Yang et al.       are two recently proposed ML algorithms for fitting functional main effects and second order interactions. We propose a new algorithm  called GAMI Tree  that is similar to EBM  but has a number of features that lead to better performance. It uses model based trees as base learners and incorporates a new interaction filtering method that is better at capturing the underlying interactions. In addition  our iterative training method converges to a model with better predictive performance  and the embedded purification ensures that interactions are hierarchically orthogonal to main effects. The algorithm does not need extensive tuning  and our implementation is fast and efficient. We use simulated and real datasets to compare the performance and interpretability of GAMI Tree with EBM and GAMI Net.,1
JAWS  Predictive Inference Under Covariate Shift We propose  textbf JAWS   a series of wrapper methods for distribution free uncertainty quantification tasks under covariate shift  centered on our core method  textbf JAW   the  textbf JA ckknife   textbf W eighted with likelihood ratio weights. JAWS also includes computationally efficient  textbf A pproximations of JAW using higher order influence functions   textbf JAWA . Theoretically  we show that JAW relaxes the jackknife  s assumption of data exchangeability to achieve the same finite sample coverage guarantee even under covariate shift. JAWA further approaches the JAW guarantee in the limit of either the sample size or the influence function order under mild assumptions. Moreover  we propose a general approach to repurposing any distribution free uncertainty quantification method and its guarantees to the task of risk assessment  a task that generates the estimated probability that the true label lies within a user specified interval. We then propose  textbf JAW R  and  textbf JAWA R  as the repurposed versions of proposed methods for  textbf R isk assessment. Practically  JAWS outperform the state of the art predictive inference baselines in a variety of biased real world data sets for both interval generation and risk assessment auditing tasks.,1
Nonlinear Sufficient Dimension Reduction for Distribution on Distribution Regression We introduce a novel framework for nonlinear sufficient dimension reduction where both the predictor and the response are distributional data  which are modeled as members of a metric space. Our key step to achieving the nonlinear sufficient dimension reduction is to build universal kernels on the metric spaces  which results in reproducing kernel Hilbert spaces for the predictor and response that are rich enough to characterize the conditional independence that determines sufficient dimension reduction. For univariate distributions  we use the well known quantile representation of the Wasserstein distance to construct the universal kernel  for multivariate distributions  we resort to the recently developed sliced Wasserstein distance to achieve this purpose. Since the sliced Wasserstein distance can be computed by aggregation of quantile representation of the univariate Wasserstein distance  the computation of multivariate Wasserstein distance is kept at a manageable level. The method is applied to several data sets  including fertility and mortality distribution data and Calgary temperature data.,1
A Supervised Tensor Dimension Reduction Based Prognostics Model for Applications with Incomplete Imaging Data This paper proposes a supervised dimension reduction methodology for tensor data which has two advantages over most image based prognostic models. First  the model does not require tensor data to be complete which expands its application to incomplete data. Second  it utilizes time to failure  TTF  to supervise the extraction of low dimensional features which makes the extracted features more effective for the subsequent prognostic. Besides  an optimization algorithm is proposed for parameter estimation and closed form solutions are derived under certain distributions.,1
Correcting Model Bias with Sparse Implicit Processes Model selection in machine learning  ML  is a crucial part of the Bayesian learning procedure. Model choice may impose strong biases on the resulting predictions  which can hinder the performance of methods such as Bayesian neural networks and neural samplers. On the other hand  newly proposed approaches for Bayesian ML exploit features of approximate inference in function space with implicit stochastic processes  a generalization of Gaussian processes . The approach of Sparse Implicit Processes  SIP  is particularly successful in this regard  since it is fully trainable and achieves flexible predictions. Here  we expand on the original experiments to show that SIP is capable of correcting model bias when the data generating mechanism differs strongly from the one implied by the model. We use synthetic datasets to show that SIP is capable of providing predictive distributions that reflect the data better than the exact predictions of the initial  but wrongly assumed model.,1
Deeply Learned Generalized Linear Models with Missing Data Deep Learning  DL  methods have dramatically increased in popularity in recent years  with significant growth in their application to supervised learning problems in the biomedical sciences. However  the greater prevalence and complexity of missing data in modern biomedical datasets present significant challenges for DL methods. Here  we provide a formal treatment of missing data in the context of deeply learned generalized linear models  a supervised DL architecture for regression and classification problems. We propose a new architecture   textit dlglm   that is one of the first to be able to flexibly account for both ignorable and non ignorable patterns of missingness in input features and response at training time. We demonstrate through statistical simulation that our method outperforms existing approaches for supervised learning tasks in the presence of missing not at random  MNAR  missingness. We conclude with a case study of a Bank Marketing dataset from the UCI Machine Learning Repository  in which we predict whether clients subscribed to a product based on phone survey data.,1
Statistical and Computational Trade offs in Variational Inference  A Case Study in Inferential Model Selection Variational inference has recently emerged as a popular alternative to the classical Markov chain Monte Carlo  MCMC  in large scale Bayesian inference. The core idea of variational inference is to trade statistical accuracy for computational efficiency. It aims to approximate the posterior  reducing computation costs but potentially compromising its statistical accuracy. In this work  we study this statistical and computational trade off in variational inference via a case study in inferential model selection. Focusing on Gaussian inferential models  a.k.a. variational approximating families  with diagonal plus low rank precision matrices  we initiate a theoretical study of the trade offs in two aspects  Bayesian posterior inference error and frequentist uncertainty quantification error. From the Bayesian posterior inference perspective  we characterize the error of the variational posterior relative to the exact posterior. We prove that  given a fixed computation budget  a lower rank inferential model produces variational posteriors with a higher statistical approximation error  but a lower computational error  it reduces variances in stochastic optimization and  in turn  accelerates convergence. From the frequentist uncertainty quantification perspective  we consider the precision matrix of the variational posterior as an uncertainty estimate. We find that  relative to the true asymptotic precision  the variational approximation suffers from an additional statistical error originating from the sampling uncertainty of the data. Moreover  this statistical error becomes the dominant factor as the computation budget increases. As a consequence  for small datasets  the inferential model need not be full rank to achieve optimal estimation error. We finally demonstrate these statistical and computational trade offs inference across empirical studies  corroborating the theoretical findings.,1
Lagrangian Density Space Time Deep Neural Network Topology As a network based functional approximator  we have proposed a  Lagrangian Density Space Time Deep Neural Networks   LDDNN  topology. It is qualified for unsupervised training and learning to predict the dynamics of underlying physical science governed phenomena. The prototypical network respects the fundamental conservation laws of nature through the succinctly described Lagrangian and Hamiltonian density of the system by a given data set of generalized nonlinear partial differential equations. The objective is to parameterize the Lagrangian density over a neural network and directly learn from it through data instead of hand crafting an exact time dependent  Action solution  of Lagrangian density for the physical system. With this novel approach  can understand and open up the information inference aspect of the  Black box deep machine learning representation  for the physical dynamics of nature by constructing custom tailored network interconnect topologies  activation  and loss cost functions based on the underlying physical differential operators. This article will discuss statistical physics interpretation of neural networks in the Lagrangian and Hamiltonian domains.,1
Jackknife Variability Estimation For Randomized Matrix Computations Randomized algorithms based on sketching have become a workhorse tool in low rank matrix approximation. To use these algorithms safely in applications  they should be coupled with diagnostics to assess the quality of approximation. To meet this need  this paper proposes a jackknife resampling method to estimate the variability of the output of a randomized matrix computation. The variability estimate can recognize that a computation requires additional data or that the computation is intrinsically unstable. As examples  the paper studies jackknife estimates for two randomized low rank matrix approximation algorithms. In each case  the operation count for the jackknife estimate is independent of the dimensions of the target matrix. In numerical experiments  the estimator accurately assesses variability and also provides an order of magnitude estimate of the mean square error.,1
Pavlov Learning Machines As well known  Hebb s learning traces its origin in Pavlov s Classical Conditioning  however  while the former has been extensively modelled in the past decades  e.g.  by Hopfield model and countless variations on theme   as for the latter modelling has remained largely unaddressed so far  further  a bridge between these two pillars is totally lacking. The main difficulty towards this goal lays in the intrinsically different scales of the information involved  Pavlov s theory is about correlations among  emph concepts  that are  dynamically  stored in the synaptic matrix as exemplified by the celebrated experiment starring a dog and a ring bell  conversely  Hebb s theory is about correlations among pairs of adjacent neurons as summarized by the famous statement   em neurons that fire together wire together . In this paper we rely on stochastic process theory and model neural and synaptic dynamics via Langevin equations  to prove that    as long as we keep neurons  and synapses  timescales largely split    Pavlov mechanism spontaneously takes place and ultimately gives rise to synaptic weights that recover the Hebbian kernel.,1
Causal Graphs Underlying Generative Models  Path to Learning with Limited Data Training generative models that capture rich semantics of the data and interpreting the latent representations encoded by such models are very important problems in unsupervised learning. In this work  we provide a simple algorithm that relies on perturbation experiments on latent codes of a pre trained generative autoencoder to uncover a causal graph that is implied by the generative model. We leverage pre trained attribute classifiers and perform perturbation experiments to check for influence of a given latent variable on a subset of attributes. Given this  we show that one can fit an effective causal graph that models a structural equation model between latent codes taken as exogenous variables and attributes taken as observed variables. One interesting aspect is that a single latent variable controls multiple overlapping subsets of attributes unlike conventional approach that tries to impose full independence. Using a pre trained RNN based generative autoencoder trained on a dataset of peptide sequences  we demonstrate that the learnt causal graph from our algorithm between various attributes and latent codes can be used to predict a specific property for sequences which are unseen. We compare prediction models trained on either all available attributes or only the ones in the Markov blanket and empirically show that in both the unsupervised and supervised regimes  typically  using the predictor that relies on Markov blanket attributes generalizes better for out of distribution sequences.,1
Package for Fast ABC Boost This report presents the open source package which implements the series of our boosting works in the past years. In particular  the package includes mainly three lines of techniques  among which the following two are already the standard implementations in popular boosted tree platforms ,1
Journal Impact Factor and Peer Review Thoroughness and Helpfulness  A Supervised Machine Learning Study The journal impact factor  JIF  is often equated with journal quality and the quality of the peer review of the papers submitted to the journal. We examined the association between the content of peer review and JIF by analysing        peer review reports submitted to       medical and life sciences journals. Two researchers hand coded a random sample of       sentences. We then trained machine learning models to classify all         sentences as contributing or not contributing to content categories. We examined the association between ten groups of journals defined by JIF deciles and the content of peer reviews using linear mixed effects models  adjusting for the length of the review. The JIF ranged from  .   to   .  . The length of peer reviews increased from the lowest  median number of words      to the JIF group      words . The proportion of sentences allocated to different content categories varied widely  even within JIF groups. For thoroughness  sentences on  Materials and Methods  were more common in the highest JIF journals than in the lowest JIF group  difference of  .  percentage points      CI  .  to   .   . The trend for  Presentation and Reporting  went in the opposite direction  with the highest JIF journals giving less emphasis to such content  difference   .        CI    .  to   .   . For helpfulness  reviews for higher JIF journals devoted less attention to  Suggestion and Solution  and provided fewer Examples than lower impact factor journals. No  or only small differences were evident for other content categories. In conclusion  peer review in journals with higher JIF tends to be more thorough in discussing the methods used but less helpful in terms of suggesting solutions and providing examples. Differences were modest and variability high  indicating that the JIF is a bad predictor for the quality of peer review of an individual manuscript.,1
A Federated Cox Model with Non Proportional Hazards Recent research has shown the potential for neural networks to improve upon classical survival models such as the Cox model  which is widely used in clinical practice. Neural networks  however  typically rely on data that are centrally available  whereas healthcare data are frequently held in secure silos. We present a federated Cox model that accommodates this data setting and also relaxes the proportional hazards assumption  allowing time varying covariate effects. In this latter respect  our model does not require explicit specification of the time varying effects  reducing upfront organisational costs compared to previous works. We experiment with publicly available clinical datasets and demonstrate that the federated model is able to perform as well as a standard model.,1
Benign  Tempered  or Catastrophic  A Taxonomy of Overfitting The practical success of overparameterized neural networks has motivated the recent scientific study of interpolating methods  which perfectly fit their training data. Certain interpolating methods  including neural networks  can fit noisy training data without catastrophically bad test performance  in defiance of standard intuitions from statistical learning theory. Aiming to explain this  a body of recent work has studied   textit benign overfitting    a phenomenon where some interpolating methods approach Bayes optimality  even in the presence of noise. In this work we argue that while benign overfitting has been instructive and fruitful to study  many real interpolating methods like neural networks   textit do not fit benignly    modest noise in the training set causes nonzero  but non infinite  excess risk at test time  implying these models are neither benign nor catastrophic but rather fall in an intermediate regime. We call this intermediate regime   textit tempered overfitting    and we initiate its systematic study. We first explore this phenomenon in the context of kernel  ridge  regression  KR  by obtaining conditions on the ridge parameter and kernel eigenspectrum under which KR exhibits each of the three behaviors. We find that kernels with powerlaw spectra  including Laplace kernels and ReLU neural tangent kernels  exhibit tempered overfitting. We then empirically study deep neural networks through the lens of our taxonomy  and find that those trained to interpolation are tempered  while those stopped early are benign. We hope our work leads to a more refined understanding of overfitting in modern learning.,1
Fairness aware Network Revenue Management with Demand Learning In addition to maximizing the total revenue  decision makers in lots of industries would like to guarantee fair consumption across different resources and avoid saturating certain resources. Motivated by these practical needs  this paper studies the price based network revenue management problem with both demand learning and fairness concern about the consumption across different resources. We introduce the regularized revenue  i.e.  the total revenue with a fairness regularization  as our objective to incorporate fairness into the revenue maximization goal. We propose a primal dual type online policy with the Upper Confidence Bound  UCB  demand learning method to maximize the regularized revenue. We adopt several innovative techniques to make our algorithm a unified and computationally efficient framework for the continuous price set and a wide class of fairness regularizers. Our algorithm achieves a worst case regret of   tilde O N       sqrt T     where  N  denotes the number of products and  T  denotes the number of time periods. Numerical experiments in a few NRM examples demonstrate the effectiveness of our algorithm for balancing revenue and fairness.,1
Markovian Gaussian Process Variational Autoencoders Deep generative models are widely used for modelling high dimensional time series  such as video animations  audio and climate data. Sequential variational autoencoders have been successfully considered for many applications  with many variant models relying on discrete time methods and recurrent neural networks  RNNs . On the other hand  continuous time methods have recently gained attraction  especially in the context of irregularly sampled time series  where they can better handle the data than discrete time methods. One such class are Gaussian process variational autoencoders  GPVAEs   where the VAE prior is set as a Gaussian process  GPs   allowing inductive biases to be explicitly encoded via the kernel function and interpretability of the latent space. However  a major limitation of GPVAEs is that it inherits the same cubic computational cost as GPs. In this work  we leverage the equivalent discrete state space representation of Markovian GPs to enable a linear time GP solver via Kalman filtering and smoothing. We show via corrupt and missing frames tasks that our method performs favourably  especially on the latter where it outperforms RNN based models.,1
Instance optimal PAC Algorithms for Contextual Bandits In the stochastic contextual bandit setting  regret minimizing algorithms have been extensively researched  but their instance minimizing best arm identification counterparts remain seldom studied. In this work  we focus on the stochastic bandit problem in the    epsilon  delta     textit PAC   setting  given a policy class   Pi  the goal of the learner is to return a policy   pi in  Pi  whose expected reward is within   epsilon  of the optimal policy with probability greater than     delta . We characterize the first   textit instance dependent   PAC sample complexity of contextual bandits through a quantity   rho   Pi    and provide matching upper and lower bounds in terms of   rho   Pi   for the agnostic and linear contextual best arm identification settings. We show that no algorithm can be simultaneously minimax optimal for regret minimization and instance dependent PAC for best arm identification. Our main result is a new instance optimal and computationally efficient algorithm that relies on a polynomial number of calls to an argmax oracle.,1
Rethinking Optimization with Differentiable Simulation from a Global Perspective Differentiable simulation is a promising toolkit for fast gradient based policy optimization and system identification. However  existing approaches to differentiable simulation have largely tackled scenarios where obtaining smooth gradients has been relatively easy  such as systems with mostly smooth dynamics. In this work  we study the challenges that differentiable simulation presents when it is not feasible to expect that a single descent reaches a global optimum  which is often a problem in contact rich scenarios. We analyze the optimization landscapes of diverse scenarios that contain both rigid bodies and deformable objects. In dynamic environments with highly deformable objects and fluids  differentiable simulators produce rugged landscapes with nonetheless useful gradients in some parts of the space. We propose a method that combines Bayesian optimization with semi local  leaps  to obtain a global search method that can use gradients effectively  while also maintaining robust performance in regions with noisy gradients. We show that our approach outperforms several gradient based and gradient free baselines on an extensive set of experiments in simulation  and also validate the method using experiments with a real robot and deformables. Videos and supplementary materials are available at,1
Energy Trees  Regression and Classification With Structured and Mixed Type Covariates The continuous growth of data complexity requires methods and models that adequately account for non trivial structures  as any simplification may induce loss of information. Many analytical tools have been introduced to work with complex data objects in their original form  but such tools can typically deal with single type variables only. In this work  we propose Energy Trees as a model for regression and classification tasks where covariates are potentially both structured and of different types. Energy Trees incorporate Energy Statistics to generalize Conditional Trees  from which they inherit statistically sound foundations  interpretability  scale invariance  and lack of distributional assumptions. We focus on functions and graphs as structured covariates and we show how the model can be easily adapted to work with almost any other type of variable. Through an extensive simulation study  we highlight the good performance of our proposal in terms of variable selection and robustness to overfitting. Finally  we validate the model s predictive ability through two empirical analyses with human biological data.,1
Randomly pivoted Cholesky  Practical approximation of a kernel matrix with few entry evaluations Randomly pivoted Cholesky  RPCholesky  is a natural algorithm for computing a rank k approximation of an N x N positive semidefinite  psd  matrix. RPCholesky can be implemented with just a few lines of code. It requires only  k   N entry evaluations and O k   N  additional arithmetic operations. This paper offers the first serious investigation of its experimental and theoretical behavior. Empirically  RPCholesky matches or improves on the performance of alternative algorithms for low rank psd approximation. Furthermore  RPCholesky provably achieves near optimal approximation guarantees. The simplicity  effectiveness  and robustness of this algorithm strongly support its use in scientific computing and machine learning applications.,1
