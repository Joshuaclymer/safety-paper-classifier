text,label
Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback We apply preference modeling and reinforcement learning from human feedbackRLHF to finetune language models to act as helpful and harmless assistants.We find this alignment training improves performance on almost all NLPevaluations and is fully compatible with training for specialized skills suchas python coding and summarization. We explore an iterated online mode oftraining where preference models and RL policies are updated on a weeklycadence with fresh human feedback data efficiently improving our datasets andmodels. Finally we investigate the robustness of RLHF training and identify aroughly linear relation between the RL reward and the square root of the KLdivergence between the policy and its initialization. Alongside our mainresults we perform peripheral analyses on calibration competing objectivesand the use of OOD detection compare our models with human writers andprovide samples from our models using prompts appearing in recent related work.,0
Optimal Policies Tend to Seek Power Some researchers speculate that intelligent reinforcement learning RLagents would be incentivized to seek resources and power in pursuit of theirobjectives. Other researchers point out that RL agents need not have humanlikepowerseeking instincts. To clarify this discussion we develop the firstformal theory of the statistical tendencies of optimal policies. In the contextof Markov decision processes we prove that certain environmental symmetriesare sufficient for optimal policies to tend to seek power over the environment.These symmetries exist in many environments in which the agent can be shut downor destroyed. We prove that in these environments most reward functions makeit optimal to seek power by keeping a range of options available and whenmaximizing average reward by navigating towards larger sets of potentialterminal states.,0
Provably Safe Reinforcement Learning A Theoretical and Experimental Comparison Ensuring safety of reinforcement learning RL algorithms is crucial for manyrealworld tasks. However vanilla RL does not guarantee safety for an agent.In recent years several methods have been proposed to provide safetyguarantees for RL. To the best of our knowledge there is no comprehensivecomparison of these provably safe RL methods. We therefore introduce acategorization for existing provably safe RL methods and present thetheoretical foundations for both continuous and discrete action spaces.Additionally we evaluate provably safe RL on an inverted pendulum. In theexperiments it is shown that indeed only provably safe RL methods guaranteesafety.,0
Deep Anomaly Detection with Outlier Exposure It is important to detect anomalous inputs when deploying machine learningsystems. The use of larger and more complex inputs in deep learning magnifiesthe difficulty of distinguishing between anomalous and indistributionexamples. At the same time diverse image and text data are available inenormous quantities. We propose leveraging these data to improve deep anomalydetection by training anomaly detectors against an auxiliary dataset ofoutliers an approach we call Outlier Exposure OE. This enables anomalydetectors to generalize and detect unseen anomalies. In extensive experimentson natural language processing and small and largescale vision tasks we findthat Outlier Exposure significantly improves detection performance. We alsoobserve that cuttingedge generative models trained on CIFAR may assignhigher likelihoods to SVHN images than to CIFAR images we use OE tomitigate this issue. We also analyze the flexibility and robustness of OutlierExposure and identify characteristics of the auxiliary dataset that improveperformance.,1
Missingness Bias in Model Debugging Missingness or the absence of features from an input is a conceptfundamental to many model debugging tools. However in computer vision pixelscannot simply be removed from an image. One thus tends to resort to heuristicssuch as blacking out pixels which may in turn introduce bias into thedebugging process. We study such biases and in particular show howtransformerbased architectures can enable a more natural implementation ofmissingness which sidesteps these issues and improves the reliability ofmodel debugging in practice. Our code is available at,1
Grokking Generalization Beyond Overfitting on Small Algorithmic Datasets In this paper we propose to study generalization of neural networks on smallalgorithmically generated datasets. In this setting questions about dataefficiency memorization generalization and speed of learning can be studiedin great detail. In some situations we show that neural networks learn througha process of grokking a pattern in the data improving generalizationperformance from random chance level to perfect generalization and that thisimprovement in generalization can happen well past the point of overfitting. Wealso study generalization as a function of dataset size and find that smallerdatasets require increasing amounts of optimization for generalization. Weargue that these datasets provide a fertile ground for studying a poorlyunderstood aspect of deep learning generalization of overparametrized neuralnetworks beyond memorization of the finite training dataset.,1
Defense Against Multitarget Trojan Attacks Adversarial attacks on deep learningbased models pose a significant threatto the current AI infrastructure. Among them Trojan attacks are the hardest todefend against. In this paper we first introduce a variation of the Badnetkind of attacks that introduces Trojan backdoors to multiple target classes andallows triggers to be placed anywhere in the image. The former makes it morepotent and the latter makes it extremely easy to carry out the attack in thephysical space. The stateoftheart Trojan detection methods fail with thisthreat model. To defend against this attack we first introduce a triggerreverseengineering mechanism that uses multiple images to recover a variety ofpotential triggers. We then propose a detection mechanism by measuring thetransferability of such recovered triggers. A Trojan trigger will have veryhigh transferability i.e. they make other images also go to the same class. Westudy many practical advantages of our attack method and then demonstrate thedetection performance using a variety of image datasets. The experimentalresults show the superior detection performance of our method over thestateofthearts.,1
Robust Calibration with Multidomain Temperature Scaling Uncertainty quantification is essential for the reliable deployment ofmachine learning models to highstakes application domains. Uncertaintyquantification is all the more challenging when training distribution and testdistribution are different even the distribution shifts are mild. Despite theubiquity of distribution shifts in realworld applications existinguncertainty quantification approaches mainly study the indistribution settingwhere the train and test distributions are the same. In this paper we developa systematic calibration model to handle distribution shifts by leveraging datafrom multiple domains. Our proposed method  multidomain temperature scaling uses the heterogeneity in the domains to improve calibration robustnessunder distribution shift. Through experiments on three benchmark data sets wefind our proposed method outperforms existing methods as measured on bothindistribution and outofdistribution test sets.,1
Increasing Confidence in Adversarial Robustness Evaluations Hundreds of defenses have been proposed to make deep neural networks robustagainst minimal adversarial input perturbations. However only a handful ofthese defenses held up their claims because correctly evaluating robustness isextremely challenging Weak attacks often fail to find adversarial exampleseven if they unknowingly exist thereby making a vulnerable network lookrobust. In this paper we propose a test to identify weak attacks and thusweak defense evaluations. Our test slightly modifies a neural network toguarantee the existence of an adversarial example for every sample.Consequentially any correct attack must succeed in breaking this modifiednetwork. For eleven out of thirteen previouslypublished defenses the originalevaluation of the defense fails our test while stronger attacks that breakthese defenses pass it. We hope that attack unit tests  such as ours  will bea major component in future robustness evaluations and increase confidence inan empirical field that is currently riddled with skepticism.,2
Distinction Maximization Loss Efficiently Improving Classification Accuracy Uncertainty Estimation and OutofDistribution Detection Simply Replacing the Loss and Calibrating Building robust deterministic neural networks remains a challenge. On the onehand some approaches improve outofdistribution detection at the cost ofreducing classification accuracy in some situations. On the other hand somemethods simultaneously increase classification accuracy uncertaintyestimation and outofdistribution detection at the expense of reducing theinference efficiency and requiring training the same model many times to tunehyperparameters. In this paper we propose training deterministic neuralnetworks using our DisMax loss which works as a dropin replacement for theusual SoftMax loss i.e. the combination of the linear output layer theSoftMax activation and the crossentropy loss. Starting from the IsoMaxloss we create each logit based on the distances to all prototypes rather thanjust the one associated with the correct class. We also introduce a mechanismto combine images to construct what we call fractional probabilityregularization. Moreover we present a fast way to calibrate the network aftertraining. Finally we propose a composite score to perform outofdistributiondetection. Our experiments show that DisMax usually outperforms currentapproaches simultaneously in classification accuracy uncertainty estimationand outofdistribution detection while maintaining deterministic neuralnetwork inference efficiency and avoiding training the same model repetitivelyfor hyperparameter tuning. The code to reproduce the results is available at,2
Robustness of Epinets against Distributional Shifts Recent work introduced the epinet as a new approach to uncertainty modelingin deep learning. An epinet is a small neural network added to traditionalneural networks which together can produce predictive distributions. Inparticular using an epinet can greatly improve the quality of jointpredictions across multiple inputs a measure of how well a neural networkknows what it does not know. In this paper we examine whether epinets canoffer similar advantages under distributional shifts. We find that acrossImageNetAOC epinets generally improve robustness metrics. Moreover theseimprovements are more significant than those afforded by even very largeensembles at orders of magnitude lower computational costs. However theseimprovements are relatively small compared to the outstanding issues indistributionallyrobust deep learning. Epinets may be a useful tool in thetoolbox but they are far from the complete solution.,2
Fast AdvProp Adversarial Propagation AdvProp is an effective way to improve recognitionmodels leveraging adversarial examples. Nonetheless AdvProp suffers from theextremely slow training speed mainly because a extra forward and backwardpasses are required for generating adversarial examples b both originalsamples and their adversarial counterparts are used for training i.e.times data. In this paper we introduce Fast AdvProp which aggressivelyrevamps AdvProps costly training components rendering the method nearly ascheap as the vanilla training. Specifically our modifications in Fast AdvPropare guided by the hypothesis that disentangled learning with adversarialexamples is the key for performance improvements while other training recipese.g. paired clean and adversarial training samples multistep adversarialattackers could be largely simplified.,2
SmoothReduce Leveraging Patches for Improved Certified Robustness Randomized smoothing RS has been shown to be a fast scalable technique forcertifying the robustness of deep neural network classifiers. However methodsbased on RS require augmenting data with large amounts of noise which leads tosignificant drops in accuracy. We propose a trainingfree modified smoothingapproach SmoothReduce that leverages patching and aggregation to provideimproved classifier certificates. Our algorithm classifies overlapping patchesextracted from an input image and aggregates the predicted logits to certify alarger radius around the input. We study two aggregation schemes  max andmean  and show that both approaches provide better certificates in terms ofcertified accuracy average certified radii and abstention rates as compared toconcurrent approaches. We also provide theoretical guarantees for suchcertificates and empirically show significant improvements over otherrandomized smoothing methods that require expensive retraining. Further weextend our approach to videos and provide meaningful certificates for videoclassifiers. A project page can be found at,2
Generalized Beliefs for Cooperative AI Selfplay is a common paradigm for constructing solutions in Markov gamesthat can yield optimal policies in collaborative settings. However thesepolicies often adopt highlyspecialized conventions that make playing with anovel partner difficult. To address this recent approaches rely on encodingsymmetry and conventionawareness into policy training but these requirestrong environmental assumptions and can complicate policy training. Wetherefore propose moving the learning of conventions to the belief space.Specifically we propose a belief learning model that can maintain beliefs overrollouts of policies not seen at training time and can thus decode and adaptto novel conventions at test time. We show how to leverage this model for bothsearch and training of a best response over various pools of policies togreatly improve adhoc teamplay. We also show how our setup promotesexplainability and interpretability of nuanced agent conventions.,3
HierarchicalForecast A Reference Framework for Hierarchical Forecasting in Python Large collections of time series data are commonly organized intocrosssectional structures with different levels of aggregation examplesinclude product and geographical groupings. A necessary condition for coherentdecisionmaking and planning with such datasets is for the disaggregatedseries forecasts to add up exactly to the aggregated series forecasts whichmotivates the creation of novel hierarchical forecasting algorithms. Thegrowing interest of the Machine Learning community in crosssectionalhierarchical forecasting systems states that we are in a propitious moment toensure that scientific endeavors are grounded on sound baselines. For thisreason we put forward the HierarchicalForecast library which containspreprocessed publicly available datasets evaluation metrics and a compiledset of statistical baseline models. Our Pythonbased framework aims to bridgethe gap between statistical econometric modeling and Machine Learningforecasting research. Code and documentation are available in,3
Fast Composite Optimization and Statistical Recovery in Federated Learning As a prevalent distributed learning paradigm Federated Learning FL trainsa global model on a massive amount of devices with infrequent communication.This paper investigates a class of composite optimization and statisticalrecovery problems in the FL setting whose loss function consists of adatadependent smooth loss and a nonsmooth regularizer. Examples includesparse linear regression using Lasso lowrank matrix recovery using nuclearnorm regularization etc. In the existing literature federated compositeoptimization algorithms are designed only from an optimization perspectivewithout any statistical guarantees. In addition they do not consider commonlyused restricted strong convexity in statistical recovery problems. We advancethe frontiers of this problem from both optimization and statisticalperspectives. From optimization upfront we propose a new algorithm namedtextitFast Federated Dual Averaging for strongly convex and smooth loss andestablish stateoftheart iteration and communication complexity in thecomposite setting. In particular we prove that it enjoys a fast rate linearspeedup and reduced communication rounds. From statistical upfront forrestricted strongly convex and smooth loss we design another algorithm namelytextitMultistage Federated Dual Averaging and prove a high probabilitycomplexity bound with linear speedup up to optimal statistical precision.Experiments in both synthetic and real data demonstrate that our methodsperform better than other baselines. To the best of our knowledge this is thefirst work providing fast optimization algorithms and statistical recoveryguarantees for composite problems in FL.,4
On the Superexponential Quantum Speedup of Equivariant Quantum Machine Learning Algorithms with SUd Symmetry We introduce a framework of the equivariant convolutional algorithms which istailored for a number of machinelearning tasks on physical systems witharbitrary SUd symmetries. It allows us to enhance a natural model ofquantum computationpermutational quantum computing PQC Quantum Inf.Comput.    and defines a more powerful model PQC. WhilePQC was shown to be effectively classically simulatable we exhibit a problemwhich can be efficiently solved on PQC machine whereas the best knownclassical algorithms runs in Onn time thus providing strong evidenceagainst PQC being classically simulatable. We further discuss practicalquantum machine learning algorithms which can be carried out in the paradigm ofPQC.,4
Is a Caption Worth a Thousand Images A Controlled Study for Representation Learning The development of CLIP Radford et al.  has sparked a debate onwhether language supervision can result in vision models with more transferablerepresentations than traditional imageonly methods. Our work studies thisquestion through a carefully controlled comparison of two approaches in termsof their ability to learn representations that generalize to downstreamclassification tasks. We find that when the pretraining dataset meets certaincriteria  it is sufficiently large and contains descriptive captions with lowvariability  imageonly methods do not match CLIPs transfer performanceeven when they are trained with more image data. However contrary to what onemight expect there are practical settings in which these criteria are not metwherein added supervision through captions is actually detrimental. Motivatedby our findings we devise simple prescriptions to enable CLIP to betterleverage the language information present in existing pretraining datasets.,4
Variational Inference of overparameterized Bayesian Neural Networks a theoretical and empirical study This paper studies the Variational Inference VI used for training BayesianNeural Networks BNN in the overparameterized regime i.e. when the number ofneurons tends to infinity. More specifically we consider overparameterizedtwolayer BNN and point out a critical issue in the meanfield VI training.This problem arises from the decomposition of the lower bound on the evidenceELBO into two terms one corresponding to the likelihood function of themodel and the second to the KullbackLeibler KL divergence between the priordistribution and the variational posterior. In particular we show boththeoretically and empirically that there is a tradeoff between these two termsin the overparameterized regime only when the KL is appropriately rescaledwith respect to the ratio between the the number of observations and neurons.We also illustrate our theoretical results with numerical experiments thathighlight the critical choice of this ratio.,4
Towards understanding how momentum improves generalization in deep learning Stochastic gradient descent SGD with momentum is widely used for trainingmodern deep learning architectures. While it is wellunderstood that usingmomentum can lead to faster convergence rate in various settings it has alsobeen observed that momentum yields higher generalization. Prior work argue thatmomentum stabilizes the SGD noise during training and this leads to highergeneralization. In this paper we adopt another perspective and firstempirically show that gradient descent with momentum GDM significantlyimproves generalization compared to gradient descent GD in some deep learningproblems. From this observation we formally study how momentum improvesgeneralization. We devise a binary classification setting where a onehiddenlayer overparameterized convolutional neural network trained with GDMprovably generalizes better than the same network trained with GD when bothalgorithms are similarly initialized. The key insight in our analysis is thatmomentum is beneficial in datasets where the examples share some feature butdiffer in their margin. Contrary to GD that memorizes the small margin dataGDM still learns the feature in these data thanks to its historical gradients.Lastly we empirically validate our theoretical findings.,4
ControlBurn Nonlinear Feature Selection with Sparse Tree Ensembles ControlBurn is a Python package to construct featuresparse tree ensemblesthat support nonlinear feature selection and interpretable machine learning.The algorithms in this package first build large tree ensembles that prioritizebasis functions with few features and then select a featuresparse subset ofthese basis functions using a weighted lasso optimization criterion. Thepackage includes visualizations to analyze the features selected by theensemble and their impact on predictions. Hence ControlBurn offers the accuracyand flexibility of treeensemble models and the interpretability of sparsegeneralized additive models.,4
Gradients should stay on Path Better Estimators of the Reverse and Forward KL Divergence for Normalizing Flows We propose an algorithm to estimate the pathgradient of both the reverse andforward KullbackLeibler divergence for an arbitrary manifestly invertiblenormalizing flow. The resulting pathgradient estimators are straightforward toimplement have lower variance and lead not only to faster convergence oftraining but also to better overall approximation results compared to standardtotal gradient estimators. We also demonstrate that pathgradient training isless susceptible to modecollapse. In light of our results we expect thatpathgradient estimators will become the new standard method to trainnormalizing flows for variational inference.,4
Causal Graphs Underlying Generative Models Path to Learning with Limited Data Training generative models that capture rich semantics of the data andinterpreting the latent representations encoded by such models are veryimportant problems in unsupervised learning. In this work we provide a simplealgorithm that relies on perturbation experiments on latent codes of apretrained generative autoencoder to uncover a causal graph that is implied bythe generative model. We leverage pretrained attribute classifiers and performperturbation experiments to check for influence of a given latent variable on asubset of attributes. Given this we show that one can fit an effective causalgraph that models a structural equation model between latent codes taken asexogenous variables and attributes taken as observed variables. One interestingaspect is that a single latent variable controls multiple overlapping subsetsof attributes unlike conventional approach that tries to impose fullindependence. Using a pretrained RNNbased generative autoencoder trained on adataset of peptide sequences we demonstrate that the learnt causal graph fromour algorithm between various attributes and latent codes can be used topredict a specific property for sequences which are unseen. We compareprediction models trained on either all available attributes or only the onesin the Markov blanket and empirically show that in both the unsupervised andsupervised regimes typically using the predictor that relies on Markovblanket attributes generalizes better for outofdistribution sequences.,4
Personalized PCA Decoupling Shared and Unique Features In this paper we tackle a significant challenge in PCA heterogeneity. Whendata are collected from different sources with heterogeneous trends while stillsharing some congruency it is critical to extract shared knowledge whileretaining unique features of each source. To this end we propose personalizedPCA PerPCA which uses mutually orthogonal global and local principalcomponents to encode both unique and shared features. We show that under mildconditions both unique and shared features can be identified and recovered bya constrained optimization problem even if the covariance matrices areimmensely different. Also we design a fully federated algorithm inspired bydistributed Stiefel gradient descent to solve the problem. The algorithmintroduces a new group of operations called generalized retractions to handleorthogonality constraints and only requires global PCs to be shared acrosssources. We prove the linear convergence of the algorithm under suitableassumptions. Comprehensive numerical experiments highlight PerPCAs superiorperformance in feature extraction and prediction from heterogeneous datasets.As a systematic approach to decouple shared and unique features fromheterogeneous datasets PerPCA finds applications in several tasks includingvideo segmentation topic extraction and distributed clustering.,4
Supervising Embedding Algorithms Using the Stress While classical scaling just like principal component analysis isparameterfree most other methods for embedding multivariate data require theselection of one or several parameters. This tuning can be difficult due to theunsupervised nature of the situation. We propose a simple almost obviousapproach to supervise the choice of tuning parameters minimize a notion ofstress. We substantiate this choice by reference to rigidity theory. We extenda result by Aspnes et al. IEEE Mobile Computing  showing that generalrandom geometric graphs are trilateration graphs with high probability. And weprovide a stability result  la Anderson et al. SIAM Discrete Mathematics. We illustrate this approach in the context of the MDSMAPP algorithmof Shang and Ruml IEEE INFOCOM . As a prototypical patchstitchingmethod it requires the choice of patch size and we use the stress to makethat choice datadriven. In this context we perform a number of experiments toillustrate the validity of using the stress as the basis for tuning parameterselection. In so doing we uncover a biasvariance tradeoff which is aphenomenon which may have been overlooked in the multidimensional scalingliterature. By turning MDSMAPP into a method for manifold learning weobtain a local version of Isomap for which the minimization of the stress mayalso be used for parameter tuning.,4
Statistical Inference with Stochastic Gradient Algorithms Stochastic gradient algorithms are widely used for both optimization andsampling in largescale learning and inference problems. However in practicetuning these algorithms is typically done using heuristics and trialanderrorrather than rigorous generalizable theory. To address this gap between theoryand practice we novel insights into the effect of tuning parameters bycharacterizing the largesample behavior of iterates of a very general class ofpreconditioned stochastic gradient algorithms with fixed step size. In theoptimization setting our results show that iterate averaging with a largefixed step size can result in statistically efficient approximation of thelocal Mestimator. In the sampling context our results show that withappropriate choices of tuning parameters the limiting stationary covariancecan match either the Bernsteinvon Mises limit of the posterior adjustmentsto the posterior for model misspecification or the asymptotic distribution ofthe MLE and that with a naive tuning the limit corresponds to none of these.Moreover we argue that an essentially independent sample from the stationarydistribution can be obtained after a fixed number of passes over the dataset.We validate our asymptotic results in realistic finitesample regimes viaseveral experiments using simulated and real data. Overall we demonstrate thatproperly tuned stochastic gradient algorithms with constant step size offer acomputationally efficient and statistically robust approach to obtaining pointestimates or posteriorlike samples.,4
Ranking in Contextual MultiArmed Bandits We study a ranking problem in the contextual multiarmed bandit setting. Alearning agent selects an ordered list of items at each time step and observesstochastic outcomes for each position. In online recommendation systemsshowing an ordered list of the most attractive items would not be the bestchoice since both position and item dependencies result in a complicated rewardfunction. A very naive example is the lack of diversity when all the mostattractive items are from the same category. We model position and itemdependencies in the ordered list and design UCB and Thompson Sampling typealgorithms for this problem. We prove that the regret bound over T rounds andL positions is TildeOLsqrtd T which has the same order as theprevious works with respect to T and only increases linearly with L. Ourwork generalizes existing studies in several directions including positiondependencies where position discount is a particular case and proposes a moregeneral contextual bandit model.,4
pGMM Kernel Regression and Comparisons with Boosted Trees In this work we demonstrate the advantage of the pGMM powered generalizedminmax kernel in the context of ridge regression. In recent priorstudies the pGMM kernel has been extensively evaluated for classificationtasks for logistic regression support vector machines as well as deep neuralnetworks. In this paper we provide an experimental study on ridge regressionto compare the pGMM kernel regression with the ordinary ridge linear regressionas well as the RBF kernel ridge regression. Perhaps surprisingly even withouta tuning parameter i.e. p for the power parameter of the pGMM kernelthe pGMM kernel already performs well. Furthermore by tuning the parameterp this deceptively simple pGMM kernel even performs quite comparably toboosted trees.,4
Correcting Model Bias with Sparse Implicit Processes Model selection in machine learning ML is a crucial part of the Bayesianlearning procedure. Model choice may impose strong biases on the resultingpredictions which can hinder the performance of methods such as Bayesianneural networks and neural samplers. On the other hand newly proposedapproaches for Bayesian ML exploit features of approximate inference infunction space with implicit stochastic processes a generalization of Gaussianprocesses. The approach of Sparse Implicit Processes SIP is particularlysuccessful in this regard since it is fully trainable and achieves flexiblepredictions. Here we expand on the original experiments to show that SIP iscapable of correcting model bias when the data generating mechanism differsstrongly from the one implied by the model. We use synthetic datasets to showthat SIP is capable of providing predictive distributions that reflect the databetter than the exact predictions of the initial but wrongly assumed model.,4
The dseparation criterion in Categorical Probability The dseparation criterion detects the compatibility of a joint probabilitydistribution with a directed acyclic graph through certain conditionalindependences. In this work we study this problem in the context ofcategorical probability theory by introducing a categorical definition ofcausal models a categorical notion of dseparation and proving an abstractversion of the dseparation criterion. This approach has two main benefits.First categorical dseparation is a very intuitive criterion based ontopological connectedness. Second our results apply in measuretheoreticprobability with standard Borel spaces and therefore provide a clean proofof the equivalence of local and global Markov properties with causalcompatibility for continuous and mixed variables.,4
UncertaintyAware Learning Against Label Noise on Imbalanced Datasets Learning against label noise is a vital topic to guarantee a reliableperformance for deep neural networks. Recent research usually refers to dynamicnoise modeling with model output probabilities and loss values and thenseparates clean and noisy samples. These methods have gained notable success.However unlike cherrypicked data existing approaches often cannot performwell when facing imbalanced datasets a common scenario in the real world. Wethoroughly investigate this phenomenon and point out two major issues thathinder the performance i.e. emphinterclass loss distribution discrepancyand emphmisleading predictions due to uncertainty. The first issue is thatexisting methods often perform classagnostic noise modeling. However lossdistributions show a significant discrepancy among classes under classimbalance and classagnostic noise modeling can easily get confused with noisysamples and samples in minority classes. The second issue refers to that modelsmay output misleading predictions due to epistemic uncertainty and aleatoricuncertainty thus existing methods that rely solely on the output probabilitiesmay fail to distinguish confident samples. Inspired by our observations wepropose an Uncertaintyaware Label Correction frameworkULC to handle labelnoise on imbalanced datasets. First we perform epistemic uncertaintyawareclassspecific noise modeling to identify trustworthy clean samples andrefinediscard highly confident truecorrupted labels. Then we introducealeatoric uncertainty in the subsequent learning process to prevent noiseaccumulation in the label noise modeling process. We conduct experiments onseveral synthetic and realworld datasets. The results demonstrate theeffectiveness of the proposed method especially on imbalanced datasets.,4
Learning to Increase the Power of Conditional Randomization Tests The modelX conditional randomization test is a generic framework forconditional independence testing unlocking new possibilities to discoverfeatures that are conditionally associated with a response of interest whilecontrolling typeI error rates. An appealing advantage of this test is that itcan work with any machine learning model to design powerful test statistics. Inturn the common practice in the modelX literature is to form a test statisticusing machine learning models trained to maximize predictive accuracy with thehope to attain a test with good power. However the ideal goal here is to drivethe model during training to maximize the power of the test not merely thepredictive accuracy. In this paper we bridge this gap by introducing for thefirst time novel modelfitting schemes that are designed to explicitly improvethe power of modelX tests. This is done by introducing a new cost functionthat aims at maximizing the test statistic used to measure violations ofconditional independence. Using synthetic and real data sets we demonstratethat the combination of our proposed loss function with various base predictivemodels lasso elastic net and deep neural networks consistently increasesthe number of correct discoveries obtained while maintaining typeI errorrates under control.,4
Variational Inference for Additive Main and Multiplicative Interaction Effects Models In plant breeding the presence of a genotype by environment GxE interactionhas a strong impact on cultivation decision making and the introduction of newcrop cultivars. The combination of linear and bilinear terms has been shown tobe very useful in modelling this type of data. A widelyused approach toidentify GxE is the Additive Main Effects and Multiplicative InteractionEffects AMMI model. However as data frequently can be highdimensionalMarkov chain Monte Carlo MCMC approaches can be computationally infeasible.In this article we consider a variational inference approach for such a model.We derive variational approximations for estimating the parameters and wecompare the approximations to MCMC using both simulated and real data. The newinferential framework we propose is on average two times faster whilstmaintaining the same predictive performance as MCMC.,4
Contextual Bandits with Smooth Regret Efficient Learning in Continuous Action Spaces Designing efficient generalpurpose contextual bandit algorithms that workwith large  or even continuous  action spaces would facilitate applicationto important scenarios such as information retrieval recommendation systemsand continuous control. While obtaining standard regret guarantees can behopeless alternative regret notions have been proposed to tackle the largeaction setting. We propose a smooth regret notion for contextual bandits whichdominates previously proposed alternatives. We design a statistically andcomputationally efficient algorithm  for the proposed smooth regret  thatworks with general function approximation under standard supervised oracles. Wealso present an adaptive algorithm that automatically adapts to any smoothnesslevel. Our algorithms can be used to recover the previous minimaxParetooptimal guarantees under the standard regret e.g. in bandit problems withmultiple best arms and LipschitzHlder bandits. We conduct largescaleempirical evaluations demonstrating the efficacy of our proposed algorithms.,4
Mathematical Foundations of GraphBased Bayesian SemiSupervised Learning In recent decades science and engineering have been revolutionized by amomentous growth in the amount of available data. However despite theunprecedented ease with which data are now collected and stored labeling databy supplementing each feature with an informative tag remains to bechallenging. Illustrative tasks where the labeling process requires expertknowledge or is tedious and timeconsuming include labeling Xrays with adiagnosis protein sequences with a protein type texts by their topic tweetsby their sentiment or videos by their genre. In these and numerous otherexamples only a few features may be manually labeled due to cost and timeconstraints. How can we best propagate label information from a small number ofexpensive labeled features to a vast number of unlabeled ones This is thequestion addressed by semisupervised learning SSL.,4
Variational Neural Networks Bayesian Neural Networks BNNs provide a tool to estimate the uncertainty ofa neural network by considering a distribution over weights and samplingdifferent models for each input. In this paper we propose a method foruncertainty estimation in neural networks called Variational Neural Networkthat instead of considering a distribution over weights generates parametersfor the output distribution of a layer by transforming its inputs withlearnable sublayers. In uncertainty quality estimation experiments we showthat VNNs achieve better uncertainty quality than Monte Carlo Dropout or BayesBy Backpropagation methods.,4
A SublinearTime Quantum Algorithm for Approximating Partition Functions We present a novel quantum algorithm for estimating Gibbs partition functionsin sublinear time with respect to the logarithm of the size of the state space.This is the first speedup of this type to be obtained over the seminalnearlylinear time algorithm of tefankovi Vempala and Vigoda JACM. Our result also preserves the quadratic speedup in precision andspectral gap achieved in previous work by exploiting the properties of quantumMarkov chains. As an application we obtain new polynomial improvements overthe bestknown algorithms for computing the partition function of the Isingmodel and counting the number of kcolorings matchings or independent setsof a graph.,4
Employing Feature Selection Algorithms to Determine the Immune State of Mice with Rheumatoid Arthritis The immune response is a dynamic process by which the body determines whetheran antigen is self or nonself. The state of this dynamic process is defined bythe relative balance and population of inflammatory and regulatory actors whichcomprise this decision making process. The goal of immunotherapy as applied toe.g. Rheumatoid Arthritis RA then is to bias the immune state in favor ofthe regulatory actors  thereby shutting down autoimmune pathways in theresponse. While there are several known approaches to immunotherapy theeffectiveness of the therapy will depend on how this intervention alters theevolution of this state. Unfortunately this process is determined not only bythe dynamics of the process but the state of the system at the time ofintervention  a state which is difficult if not impossible to determine priorto application of the therapy.,4
