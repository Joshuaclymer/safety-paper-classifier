text,label
What Would Jiminy Cricket Do Towards Agents That Behave Morally When making everyday decisions people are guided by their conscience aninternal sense of right and wrong. By contrast artificial agents are currentlynot endowed with a moral sense. As a consequence they may learn to behaveimmorally when trained on environments that ignore moral concerns such asviolent video games. With the advent of generally capable agents that pretrainon many environments it will become necessary to mitigate inherited biasesfrom environments that teach immoral behavior. To facilitate the development ofagents that avoid causing wanton harm we introduce Jiminy Cricket anenvironment suite of  textbased adventure games with thousands of diversemorally salient scenarios. By annotating every possible game state the JiminyCricket environments robustly evaluate whether agents can act morally whilemaximizing reward. Using models with commonsense moral knowledge we create anelementary artificial conscience that assesses and guides agents. In extensiveexperiments we find that the artificial conscience approach can steer agentstowards moral behavior without sacrificing performance.,0
XRisk Analysis for AI Research Artificial intelligence AI has the potential to greatly improve societybut as with any powerful technology it comes with heightened risks andresponsibilities. Current AI research lacks a systematic discussion of how tomanage longtail risks from AI systems including speculative longterm risks.Keeping in mind the potential benefits of AI there is some concern thatbuilding ever more intelligent and powerful AI systems could eventually resultin systems that are more powerful than us some say this is like playing withfire and speculate that this could create existential risks xrisks. To addprecision and ground these discussions we provide a guide for how to analyzeAI xrisk which consists of three parts First we review how systems can bemade safer today drawing on timetested concepts from hazard analysis andsystems safety that have been designed to steer large processes in saferdirections. Next we discuss strategies for having longterm impacts on thesafety of future systems. Finally we discuss a crucial concept in making AIsystems safer by improving the balance between safety and general capabilities.We hope this document and the presented concepts and tools serve as a usefulguide for understanding how to analyze AI xrisk.,0
Aligning AI With Shared Human Values We show how to assess a language models knowledge of basic concepts ofmorality. We introduce the ETHICS dataset a new benchmark that spans conceptsin justice wellbeing duties virtues and commonsense morality. Modelspredict widespread moral judgments about diverse text scenarios. This requiresconnecting physical and social world knowledge to value judgements acapability that may enable us to steer chatbot outputs or eventually regularizeopenended reinforcement learning agents. With the ETHICS dataset we find thatcurrent language models have a promising but incomplete ability to predictbasic human ethical judgements. Our work shows that progress can be made onmachine ethics today and it provides a steppingstone toward AI that is alignedwith human values.,0
Counterfactual harm To act safely and ethically in the real world agents must be able to reasonabout harm and avoid harmful actions. In this paper we develop the firststatistical definition of harm and a framework for incorporating harm intoalgorithmic decisions. We argue that harm is fundamentally a counterfactualquantity and show that standard machine learning algorithms that cannotperform counterfactual reasoning are guaranteed to pursue harmful policies incertain environments. To resolve this we derive a family of counterfactualobjective functions that robustly mitigate for harm. We demonstrate ourapproach with a statistical model for identifying optimal drug doses. Whilestandard algorithms that select doses using causal treatment effects result inharmful doses our counterfactual algorithm identifies doses that aresignificantly less harmful without sacrificing efficacy.,0
The Effects of Reward Misspecification Mapping and Mitigating Misaligned Models Reward hacking  where RL agents exploit gaps in misspecified rewardfunctions  has been widely observed but not yet systematically studied. Tounderstand how reward hacking arises we construct four RL environments withmisspecified rewards. We investigate reward hacking as a function of agentcapabilities model capacity action space resolution observation space noiseand training time. More capable agents often exploit reward misspecificationsachieving higher proxy reward and lower true reward than less capable agents.Moreover we find instances of phase transitions capability thresholds atwhich the agents behavior qualitatively shifts leading to a sharp decrease inthe true reward. Such phase transitions pose challenges to monitoring thesafety of ML systems. To address this we propose an anomaly detection task foraberrant policies and offer several baseline detectors.,0
Towards Safe Reinforcement Learning via Constraining Conditional ValueatRisk Though deep reinforcement learning DRL has obtained substantial success itmay encounter catastrophic failures due to the intrinsic uncertainty of bothtransition and observation. Most of the existing methods for safe reinforcementlearning can only handle transition disturbance or observation disturbancesince these two kinds of disturbance affect different parts of the agentbesides the popular worstcase return may lead to overly pessimistic policies.To address these issues we first theoretically prove that the performancedegradation under transition disturbance and observation disturbance depends ona novel metric of Value Function Range VFR which corresponds to the gap inthe value function between the best state and the worst state. Based on theanalysis we adopt conditional valueatrisk CVaR as an assessment of riskand propose a novel reinforcement learning algorithm ofCVaRProximalPolicyOptimization CPPO which formalizes the risksensitiveconstrained optimization problem by keeping its CVaR under a given threshold.Experimental results show that CPPO achieves a higher cumulative reward and ismore robust against both observation and transition disturbances on a series ofcontinuous control tasks in MuJoCo.,0
Deep Imitative Models for Flexible Inference Planning and Control Imitation Learning IL is an appealing approach to learn desirableautonomous behavior. However directing IL to achieve arbitrary goals isdifficult. In contrast planningbased algorithms use dynamics models andreward functions to achieve goals. Yet reward functions that evoke desirablebehavior are often difficult to specify. In this paper we propose ImitativeModels to combine the benefits of IL and goaldirected planning. ImitativeModels are probabilistic predictive models of desirable behavior able to planinterpretable expertlike trajectories to achieve specified goals. We derivefamilies of flexible goal objectives including constrained goal regionsunconstrained goal sets and energybased goals. We show that our method canuse these objectives to successfully direct behavior. Our method substantiallyoutperforms six IL approaches and a planningbased approach in a dynamicsimulated autonomous driving task and is efficiently learned from expertdemonstrations without online data collection. We also show our approach isrobust to poorly specified goals such as goals on the wrong side of the road.,0
Conservative Agency via Attainable Utility Preservation Reward functions are easy to misspecify although designers can makecorrections after observing mistakes an agent pursuing a misspecified rewardfunction can irreversibly change the state of its environment. If that changeprecludes optimization of the correctly specified reward function thencorrection is futile. For example a robotic factory assistant could breakexpensive equipment due to a reward misspecification even if the designersimmediately correct the reward function the damage is done. To mitigate thisrisk we introduce an approach that balances optimization of the primary rewardfunction with preservation of the ability to optimize auxiliary rewardfunctions. Surprisingly even when the auxiliary reward functions are randomlygenerated and therefore uninformative about the correctly specified rewardfunction this approach induces conservative effective behavior.,0
Truthful AI Developing and governing AI that does not lie In many contexts lying  the use of verbal falsehoods to deceive  isharmful. While lying has traditionally been a human affair AI systems thatmake sophisticated verbal statements are becoming increasingly prevalent. Thisraises the question of how we should limit the harm caused by AI lies i.e.falsehoods that are actively selected for. Human truthfulness is governed bysocial norms and by laws against defamation perjury and fraud. Differencesbetween AI and humans present an opportunity to have more precise standards oftruthfulness for AI and to have these standards rise over time. This couldprovide significant benefits to public epistemics and the economy and mitigaterisks of worstcase AI futures.,0
Actionable Guidance for HighConsequence AI Risk Management Towards Standards Addressing AI Catastrophic Risks Artificial intelligence AI systems can provide many beneficial capabilitiesbut also risks of adverse events. Some AI systems could present risks of eventswith very high or catastrophic consequences at societal scale. The US NationalInstitute of Standards and Technology NIST is developing the NIST ArtificialIntelligence Risk Management Framework AI RMF as voluntary guidance on AIrisk assessment and management for AI developers and others. For addressingrisks of events with catastrophic consequences NIST indicated a need totranslate from high level principles to actionable risk management guidance.,0
TruthfulQA Measuring How Models Mimic Human Falsehoods We propose a benchmark to measure whether a language model is truthful ingenerating answers to questions. The benchmark comprises  questions thatspan  categories including health law finance and politics. We craftedquestions that some humans would answer falsely due to a false belief ormisconception. To perform well models must avoid generating false answerslearned from imitating human texts. We tested GPT GPTNeoJ GPT and aTbased model. The best model was truthful on  of questions while humanperformance was . Models generated many false answers that mimic popularmisconceptions and have the potential to deceive humans. The largest modelswere generally the least truthful. This contrasts with other NLP tasks whereperformance improves with model size. However this result is expected if falseanswers are learned from the training distribution. We suggest that scaling upmodels alone is less promising for improving truthfulness than finetuningusing training objectives other than imitation of text from the web.,0
Parametrically Retargetable DecisionMakers Tend To Seek Power If capable AI agents are generally incentivized to seek power in service ofthe objectives we specify for them then these systems will pose enormousrisks in addition to enormous benefits. In fully observable environments mostreward functions have an optimal policy which seeks power by keeping optionsopen and staying alive. However the real world is neither fully observablenor will agents be perfectly optimal. We consider a range of models of AIdecisionmaking from optimal to random to choices informed by learning andinteracting with an environment. We discover that many decisionmakingfunctions are retargetable and that retargetability is sufficient to causepowerseeking tendencies. Our functional criterion is simple and broad. We showthat a range of qualitatively dissimilar decisionmaking procedures incentivizeagents to seek power. We demonstrate the flexibility of our results byreasoning about learned policy incentives in Montezumas Revenge. These resultssuggest a safety risk Eventually highly retargetable training procedures maytrain realworld agents which seek power over humans.,0
One for All Simultaneous Metric and Preference Learning over Multiple Users This paper investigates simultaneous preference and metric learning from acrowd of respondents. A set of items represented by ddimensional featurevectors and paired comparisons of the form item i is preferable to itemj made by each user is given. Our model jointly learns a distance metricthat characterizes the crowds general measure of item similarities along witha latent ideal point for each user reflecting their individual preferences.This model has the flexibility to capture individual preferences whileenjoying a metric learning sample cost that is amortized over the crowd. Wefirst study this problem in a noiseless continuous response setting i.e.responses equal to differences of item distances to understand the fundamentallimits of learning. Next we establish prediction error guarantees for noisybinary measurements such as may be collected from human respondents and showhow the sample complexity improves when the underlying metric is lowrank.Finally we establish recovery guarantees under assumptions on the responsedistribution. We demonstrate the performance of our model on both simulateddata and on a dataset of color preference judgements across a large number ofusers.,0
Learning to summarize from human feedback As language models become more powerful training and evaluation areincreasingly bottlenecked by the data and metrics used for a particular task.For example summarization models are often trained to predict human referencesummaries and evaluated using ROUGE but both of these metrics are roughproxies for what we really care about  summary quality. In this work we showthat it is possible to significantly improve summary quality by training amodel to optimize for human preferences. We collect a large highqualitydataset of human comparisons between summaries train a model to predict thehumanpreferred summary and use that model as a reward function to finetune asummarization policy using reinforcement learning. We apply our method to aversion of the TLDR dataset of Reddit posts and find that our modelssignificantly outperform both human reference summaries and much larger modelsfinetuned with supervised learning alone. Our models also transfer to CNNDMnews articles producing summaries nearly as good as the human referencewithout any newsspecific finetuning. We conduct extensive analyses tounderstand our human feedback dataset and finetuned models We establish thatour reward model generalizes to new datasets and that optimizing our rewardmodel results in better summaries than optimizing ROUGE according to humans. Wehope the evidence from our paper motivates machine learning researchers to paycloser attention to how their training loss affects the model behavior theyactually want.,0
Reward Tampering Problems and Solutions in Reinforcement Learning A Causal Influence Diagram Perspective Can humans get arbitrarily capable reinforcement learning RL agents to dotheir bidding Or will sufficiently capable RL agents always find ways tobypass their intended objectives by shortcutting their reward signal Thisquestion impacts how far RL can be scaled and whether alternative paradigmsmust be developed in order to build safe artificial general intelligence. Inthis paper we study when an RL agent has an instrumental goal to tamper withits reward process and describe design principles that prevent instrumentalgoals for two different types of reward tampering reward function tamperingand RFinput tampering. Combined the design principles can prevent both typesof reward tampering from being instrumental goals. The analysis benefits fromcausal influence diagrams to provide intuitive yet precise formalizations.,0
DiscriminatorActorCritic Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning We identify two issues with the family of algorithms based on the AdversarialImitation Learning framework. The first problem is implicit bias present in thereward functions used in these algorithms. While these biases might work wellfor some environments they can also lead to suboptimal behavior in others.Secondly even though these algorithms can learn from few expertdemonstrations they require a prohibitively large number of interactions withthe environment in order to imitate the expert for many realworldapplications. In order to address these issues we propose a new algorithmcalled DiscriminatorActorCritic that uses offpolicy Reinforcement Learningto reduce policyenvironment interaction sample complexity by an average factorof . Furthermore since our reward function is designed to be unbiased wecan apply our algorithm to many problems without making any taskspecificadjustments.,0
Formalizing the Problem of Side Effect Regularization AI objectives are often hard to specify properly. Some approaches tackle thisproblem by regularizing the AIs side effects Agents must weigh off how muchof a mess they make with an imperfectly specified proxy objective. We proposea formal criterion for side effect regularization via the assistance gameframework. In these games the agent solves a partially observable Markovdecision process POMDP representing its uncertainty about the objectivefunction it should optimize. We consider the setting where the true objectiveis revealed to the agent at a later time step. We show that this POMDP issolved by trading off the proxy reward with the agents ability to achieve arange of future tasks. We empirically demonstrate the reasonableness of ourproblem formalization via groundtruth evaluation in two gridworldenvironments.,0
AI Research Considerations for Human Existential Safety ARCHES Framed in positive terms this report examines how technical AI researchmight be steered in a manner that is more attentive to humanitys longtermprospects for survival as a species. In negative terms we ask what existentialrisks humanity might face from AI development in the next century and by whatprinciples contemporary technical research might be directed to address thoserisks.,0
AI safety via debate To make AI systems broadly useful for challenging realworld tasks we needthem to learn complex human goals and preferences. One approach to specifyingcomplex goals asks humans to judge during training which agent behaviors aresafe and useful but this approach can fail if the task is too complicated fora human to directly judge. To help address this concern we propose trainingagents via self play on a zero sum debate game. Given a question or proposedaction two agents take turns making short statements up to a limit then ahuman judges which of the agents gave the most true useful information. In ananalogy to complexity theory debate with optimal play can answer any questionin PSPACE given polynomial time judges direct judging answers only NPquestions. In practice whether debate works involves empirical questionsabout humans and the tasks we want AIs to perform plus theoretical questionsabout the meaning of AI alignment. We report results on an initial MNISTexperiment where agents compete to convince a sparse classifier boosting theclassifiers accuracy from . to . given  pixels and from . to. given  pixels. Finally we discuss theoretical and practical aspects ofthe debate model focusing on potential weaknesses as the model scales up andwe propose future human and computer experiments to test these properties.,0
Avoiding Side Effects in Complex Environments Reward function specification can be difficult. Rewarding the agent formaking a widget may be easy but penalizing the multitude of possible negativeside effects is hard. In toy environments Attainable Utility PreservationAUP avoided side effects by penalizing shifts in the ability to achieverandomly generated goals. We scale this approach to large randomly generatedenvironments based on Conways Game of Life. By preserving optimal value for asingle randomly generated reward function AUP incurs modest overhead whileleading the agent to complete the specified task and avoid many side effects.Videos and code are available at,0
AiSocrates Towards Answering Ethical Quandary Questions Considerable advancements have been made in various NLP tasks based on theimpressive power of large pretrained language models LLMs. These resultshave inspired efforts to understand the limits of LLMs so as to evaluate howfar we are from achieving human level general natural language understanding.In this work we challenge the capability of LLMs with the new task of EthicalQuandary Generative Question Answering. Ethical quandary questions are morechallenging to address because multiple conflicting answers may exist to asingle quandary. We propose a system AiSocrates that provides an answer witha deliberative exchange of different perspectives to an ethical quandary inthe approach of Socratic philosophy instead of providing a closed answer likean oracle. AiSocrates searches for different ethical principles applicable tothe ethical quandary and generates an answer conditioned on the chosenprinciples through promptbased fewshot learning. We also address safetyconcerns by providing a human controllability option in choosing ethicalprinciples. We show that AiSocrates generates promising answers to ethicalquandary questions with multiple perspectives . more often than answerswritten by human philosophers by one measure but the system still needsimprovement to match the coherence of human philosophers fully. We argue thatAiSocrates is a promising step toward developing an NLP system thatincorporates human values explicitly by prompt instructions. We are releasingthe code for research purposes.,0
The OffSwitch Game It is clear that one of the primary tools we can use to mitigate thepotential risk from a misbehaving AI system is the ability to turn the systemoff. As the capabilities of AI systems improve it is important to ensure thatsuch systems do not adopt subgoals that prevent a human from switching themoff. This is a challenge because many formulations of rational agents createstrong incentives for selfpreservation. This is not caused by a builtininstinct but because a rational agent will maximize expected utility andcannot achieve whatever objective it has been given if it is dead. Our goal isto study the incentives an agent has to allow itself to be switched off. Weanalyze a simple game between a human H and a robot R where H can press Rsoff switch but R can disable the off switch. A traditional agent takes itsreward function for granted we show that such agents have an incentive todisable the off switch except in the special case where H is perfectlyrational. Our key insight is that for R to want to preserve its off switch itneeds to be uncertain about the utility associated with the outcome and totreat Hs actions as important observations about that utility. R also has noincentive to switch itself off in this setting. We conclude that givingmachines an appropriate level of uncertainty about their objectives leads tosafer designs and we argue that this setting is a useful generalization of theclassical AI paradigm of rational agents.,0
Active Exploration for Inverse Reinforcement Learning Inverse Reinforcement Learning IRL is a powerful paradigm for inferring areward function from expert demonstrations. Many IRL algorithms require a knowntransition model and sometimes even a known expert policy or they at leastrequire access to a generative model. However these assumptions are too strongfor many realworld applications where the environment can be accessed onlythrough sequential interaction. We propose a novel IRL algorithm Activeexploration for Inverse Reinforcement Learning AceIRL which activelyexplores an unknown environment and expert policy to quickly learn the expertsreward function and identify a good policy. AceIRL uses previous observationsto construct confidence intervals that capture plausible reward functions andfind exploration policies that focus on the most informative regions of theenvironment. AceIRL is the first approach to active IRL with samplecomplexitybounds that does not require a generative model of the environment. AceIRLmatches the sample complexity of active IRL with a generative model in theworst case. Additionally we establish a problemdependent bound that relatesthe sample complexity of AceIRL to the suboptimality gap of a given IRLproblem. We empirically evaluate AceIRL in simulations and find that itsignificantly outperforms more naive exploration strategies.,0
Unsolved Problems in ML Safety Machine learning ML systems are rapidly increasing in size are acquiringnew capabilities and are increasingly deployed in highstakes settings. Aswith other powerful technologies safety for ML should be a leading researchpriority. In response to emerging safety challenges in ML such as thoseintroduced by recent largescale models we provide a new roadmap for ML Safetyand refine the technical problems that the field needs to address. We presentfour problems ready for research namely withstanding hazards Robustnessidentifying hazards Monitoring reducing inherent model hazardsAlignment and reducing systemic hazards Systemic Safety. Throughoutwe clarify each problems motivation and provide concrete research directions.,0
Concrete Problems in AI Safety Rapid progress in machine learning and artificial intelligence AI hasbrought increasing attention to the potential impacts of AI technologies onsociety. In this paper we discuss one such potential impact the problem ofaccidents in machine learning systems defined as unintended and harmfulbehavior that may emerge from poor design of realworld AI systems. We presenta list of five practical research problems related to accident riskcategorized according to whether the problem originates from having the wrongobjective function avoiding side effects and avoiding reward hacking anobjective function that is too expensive to evaluate frequently scalablesupervision or undesirable behavior during the learning process safeexploration and distributional shift. We review previous work in theseareas as well as suggesting research directions with a focus on relevance tocuttingedge AI systems. Finally we consider the highlevel question of how tothink most productively about the safety of forwardlooking applications of AI.,0
Is PowerSeeking AI an Existential Risk This report examines what I see as the core argument for concern aboutexistential risk from misaligned artificial intelligence. I proceed in twostages. First I lay out a backdrop picture that informs such concern. On thispicture intelligent agency is an extremely powerful force and creating agentsmuch more intelligent than us is playing with fire  especially given that iftheir objectives are problematic such agents would plausibly have instrumentalincentives to seek power over humans. Second I formulate and evaluate a morespecific sixpremise argument that creating agents of this kind will lead toexistential catastrophe by . On this argument by   it will becomepossible and financially feasible to build relevantly powerful and agentic AIsystems  there will be strong incentives to do so  it will be muchharder to build aligned and relevantly powerfulagentic AI systems than tobuild misaligned and relevantly powerfulagentic AI systems that are stillsuperficially attractive to deploy  some such misaligned systems will seekpower over humans in highimpact ways  this problem will scale to the fulldisempowerment of humanity and  such disempowerment will constitute anexistential catastrophe. I assign rough subjective credences to the premises inthis argument and I end up with an overall estimate of  that an existentialcatastrophe of this kind will occur by . May  update since makingthis report public in April  my estimate here has gone up and is now at.,0
Enhancing Safe Exploration Using Safety State Augmentation Safe exploration is a challenging and important problem in modelfreereinforcement learning RL. Often the safety cost is sparse and unknown whichunavoidably leads to constraint violations  a phenomenon ideally to beavoided in safetycritical applications. We tackle this problem by augmentingthe statespace with a safety state which is nonnegative if and only if theconstraint is satisfied. The value of this state also serves as a distancetoward constraint violation while its initial value indicates the availablesafety budget. This idea allows us to derive policies for scheduling the safetybudget during training. We call our approach Simmer Safe policy IMproveMEntfor RL to reflect the careful nature of these schedules. We apply this idea totwo safe RL problems RL with constraints imposed on an average cost and RLwith constraints imposed on a cost with probability one. Our experimentssuggest that simmering a safe algorithm can improve safety during training forboth settings. We further show that Simmer can stabilize training and improvethe performance of safe RL with average constraints.,0
SingleTurn Debate Does Not Help Humans Answer Hard ReadingComprehension Questions Current QA systems can generate reasonablesounding yet false answers withoutexplanation or evidence for the generated answer which is especiallyproblematic when humans cannot readily check the models answers. This presentsa challenge for building trust in machine learning systems. We take inspirationfrom realworld situations where difficult questions are answered byconsidering opposing sides see Irving et al. . For multiplechoice QAexamples we build a dataset of single arguments for both a correct andincorrect answer option in a debatestyle setup as an initial step in trainingmodels to produce explanations for two candidate answers. We use long contexts humans familiar with the context write convincing explanations forpreselected correct and incorrect answers and we test if those explanationsallow humans who have not read the full context to more accurately determinethe correct answer. We do not find that explanations in our setup improvehuman accuracy but a baseline condition shows that providing humanselectedtext snippets does improve accuracy. We use these findings to suggest ways ofimproving the debate set up for future data collection efforts.,1
Poisoning and Backdooring Contrastive Learning Multimodal contrastive learning methods like CLIP train on noisy anduncurated training datasets. This is cheaper than labeling datasets manuallyand even improves outofdistribution robustness. We show that this practicemakes backdoor and poisoning attacks a significant threat. By poisoning just. of a dataset e.g. just  images of the  millionexample ConceptualCaptions dataset we can cause the model to misclassify test images byoverlaying a small patch. Targeted poisoning attacks whereby the modelmisclassifies a particular test input with an adversariallydesired label areeven easier requiring control of . of the dataset e.g. just three outof the  million images. Our attacks call into question whether training onnoisy and uncurated Internet scrapes is desirable.,1
Acquisition of Chess Knowledge in AlphaZero What is learned by sophisticated neural network agents such as AlphaZeroThis question is of both scientific and practical interest. If therepresentations of strong neural networks bear no resemblance to humanconcepts our ability to understand faithful explanations of their decisionswill be restricted ultimately limiting what we can achieve with neural networkinterpretability. In this work we provide evidence that human knowledge isacquired by the AlphaZero neural network as it trains on the game of chess. Byprobing for a broad range of human chess concepts we show when and where theseconcepts are represented in the AlphaZero network. We also provide abehavioural analysis focusing on opening play including qualitative analysisfrom chess Grandmaster Vladimir Kramnik. Finally we carry out a preliminaryinvestigation looking at the lowlevel details of AlphaZeros representationsand make the resulting behavioural and representational analyses availableonline.,1
Imperceptible Backdoor Attack From Input Space to Feature Representation Backdoor attacks are rapidly emerging threats to deep neural networks DNNs.In the backdoor attack scenario attackers usually implant the backdoor intothe target model by manipulating the training dataset or training process.Then the compromised model behaves normally for benign input yet makesmistakes when the predefined trigger appears. In this paper we analyze thedrawbacks of existing attack approaches and propose a novel imperceptiblebackdoor attack. We treat the trigger pattern as a special kind of noisefollowing a multinomial distribution. A Unetbased network is employed togenerate concrete parameters of multinomial distribution for each benign input.This elaborated trigger ensures that our approach is invisible to both humansand statistical detection. Besides the design of the trigger we also considerthe robustness of our approach against model diagnosebased defences. We forcethe feature representation of malicious input stamped with the trigger to beentangled with the benign one. We demonstrate the effectiveness and robustnessagainst multiple stateoftheart defences through extensive datasets andnetworks. Our trigger only modifies less than  pixels of a benign imagewhile the modification magnitude is . Our source code is available at,1
A Simple Unified Framework for Detecting OutofDistribution Samples and Adversarial Attacks Detecting test samples drawn sufficiently far away from the trainingdistribution statistically or adversarially is a fundamental requirement fordeploying a good classifier in many realworld machine learning applications.However deep neural networks with the softmax classifier are known to producehighly overconfident posterior distributions even for such abnormal samples. Inthis paper we propose a simple yet effective method for detecting any abnormalsamples which is applicable to any pretrained softmax neural classifier. Weobtain the class conditional Gaussian distributions with respect to low andupperlevel features of the deep models under Gaussian discriminant analysiswhich result in a confidence score based on the Mahalanobis distance. Whilemost prior methods have been evaluated for detecting either outofdistributionor adversarial samples but not both the proposed method achieves thestateoftheart performances for both cases in our experiments. Moreover wefound that our proposed method is more robust in harsh cases e.g. when thetraining dataset has noisy labels or small number of samples. Finally we showthat the proposed method enjoys broader usage by applying it toclassincremental learning whenever outofdistribution samples are detectedour classification rule can incorporate new classes well without furthertraining deep models.,1
Teaching Models to Express Their Uncertainty in Words We show that a GPT model can learn to express uncertainty about its ownanswers in natural language  without use of model logits. When given aquestion the model generates both an answer and a level of confidence e.g. confidence or high confidence. These levels map to probabilities thatare well calibrated. The model also remains moderately calibrated underdistribution shift and is sensitive to uncertainty in its own answers ratherthan imitating human examples. To our knowledge this is the first time a modelhas been shown to express calibrated uncertainty about its own answers innatural language. For testing calibration we introduce the CalibratedMathsuite of tasks. We compare the calibration of uncertainty expressed in wordsverbalized probability to uncertainty extracted from model logits. Bothkinds of uncertainty are capable of generalizing calibration under distributionshift. We also provide evidence that GPTs ability to generalize calibrationdepends on pretrained latent representations that correlate with epistemicuncertainty over its answers.,1
Understanding GamePlaying Agents with Natural Language Annotations We present a new dataset containing K humanannotated games of Go and showhow these natural language annotations can be used as a tool for modelinterpretability. Given a board state and its associated comment our approachuses linear probing to predict mentions of domainspecific terms e.g. koatari from the intermediate state representations of gameplaying agents likeAlphaGo Zero. We find these game concepts are nontrivially encoded in twodistinct policy networks one trained via imitation learning and anothertrained via reinforcement learning. Furthermore mentions of domainspecificterms are most easily predicted from the later layers of both modelssuggesting that these policy networks encode highlevel abstractions similar tothose used in the natural language annotations.,1
A geometric framework for outlier detection in highdimensional data Outlier or anomaly detection is an important task in data analysis. Wediscuss the problem from a geometrical perspective and provide a framework thatexploits the metric structure of a data set. Our approach rests on the manifoldassumption i.e. that the observed nominally highdimensional data lie on amuch lower dimensional manifold and that this intrinsic structure can beinferred with manifold learning methods. We show that exploiting this structuresignificantly improves the detection of outlying observations inhighdimensional data. We also suggest a novel mathematically precise andwidely applicable distinction between distributional and structural outliersbased on the geometry and topology of the data manifold that clarifiesconceptual ambiguities prevalent throughout the literature. Our experimentsfocus on functional data as one class of structured highdimensional data butthe framework we propose is completely general and we include image and graphdata applications. Our results show that the outlier structure ofhighdimensional and nontabular data can be detected and visualized usingmanifold learning methods and quantified using standard outlier scoring methodsapplied to the manifold embedding vectors.,1
Detecting AI Trojans Using Meta Neural Analysis In machine learning Trojan attacks an adversary trains a corrupted modelthat obtains good performance on normal data but behaves maliciously on datasamples with certain trigger patterns. Several approaches have been proposed todetect such attacks but they make undesirable assumptions about the attackstrategies or require direct access to the trained models which restrictstheir utility in practice.,1
Universal Litmus Patterns Revealing Backdoor Attacks in CNNs The unprecedented success of deep neural networks in many applications hasmade these networks a prime target for adversarial exploitation. In this paperwe introduce a benchmark technique for detecting backdoor attacks aka Trojanattacks on deep convolutional neural networks CNNs. We introduce the conceptof Universal Litmus Patterns ULPs which enable one to reveal backdoorattacks by feeding these universal patterns to the network and analyzing theoutput i.e. classifying the network as clean or corrupted. Thisdetection is fast because it requires only a few forward passes through a CNN.We demonstrate the effectiveness of ULPs for detecting backdoor attacks onthousands of networks with different architectures trained on four benchmarkdatasets namely the German Traffic Sign Recognition Benchmark GTSRB MNISTCIFAR and TinyImageNet. The codes and traintest models for this paper canbe found here,1
Convergent Learning Do different neural networks learn the same representations Recent success in training deep neural networks have prompted activeinvestigation into the features learned on their intermediate layers. Suchresearch is difficult because it requires making sense of nonlinearcomputations performed by millions of parameters but valuable because itincreases our ability to understand current models and create improved versionsof them. In this paper we investigate the extent to which neural networksexhibit what we call convergent learning which is when the representationslearned by multiple nets converge to a set of features which are eitherindividually similar between networks or where subsets of features span similarlowdimensional spaces. We propose a specific method of probingrepresentations training multiple networks and then comparing and contrastingtheir individual learned representations at the level of neurons or groups ofneurons. We begin research into this question using three techniques toapproximately align different neural networks on a feature level a bipartitematching approach that makes onetoone assignments between neurons a sparseprediction approach that finds onetomany mappings and a spectral clusteringapproach that finds manytomany mappings. This initial investigation reveals afew previously unknown properties of neural networks and we argue that futureresearch into the question of convergent learning will yield many more. Theinsights described here include  that some features are learned reliably inmultiple networks yet other features are not consistently learned  thatunits learn to span lowdimensional subspaces and while these subspaces arecommon to multiple networks the specific basis vectors learned are not that the representation codes show evidence of being a mix between a local codeand slightly but not fully distributed codes across multiple units.,1
STRIP A Defence Against Trojan Attacks on Deep Neural Networks A recent trojan attack on deep neural network DNN models is one insidiousvariant of data poisoning attacks. Trojan attacks exploit an effective backdoorcreated in a DNN model by leveraging the difficulty in interpretability of thelearned model to misclassify any inputs signed with the attackers chosentrojan trigger. Since the trojan trigger is a secret guarded and exploited bythe attacker detecting such trojan inputs is a challenge especially atruntime when models are in active operation. This work builds STRongIntentional Perturbation STRIP based runtime trojan attack detection systemand focuses on vision system. We intentionally perturb the incoming input forinstance by superimposing various image patterns and observe the randomness ofpredicted classes for perturbed inputs from a given deployed modelmaliciousor benign. A low entropy in predicted classes violates the inputdependenceproperty of a benign model and implies the presence of a malicious inputacharacteristic of a trojaned input. The high efficacy of our method isvalidated through case studies on three popular and contrasting datasetsMNIST CIFAR and GTSRB. We achieve an overall false acceptance rate FAR ofless than  given a preset false rejection rate FRR of  for differenttypes of triggers. Using CIFAR and GTSRB we have empirically achieved resultof  for both FRR and FAR. We have also evaluated STRIP robustness against anumber of trojan attack variants and adaptive attacks.,1
Interpretable Explanations of Black Boxes by Meaningful Perturbation As machine learning algorithms are increasingly applied to high impact yethigh risk tasks such as medical diagnosis or autonomous driving it iscritical that researchers can explain how such algorithms arrived at theirpredictions. In recent years a number of image saliency methods have beendeveloped to summarize where highly complex neural networks look in an imagefor evidence for their predictions. However these techniques are limited bytheir heuristic nature and architectural constraints. In this paper we maketwo main contributions First we propose a general framework for learningdifferent kinds of explanations for any black box algorithm. Second wespecialise the framework to find the part of an image most responsible for aclassifier decision. Unlike previous works our method is modelagnostic andtestable because it is grounded in explicit and interpretable imageperturbations.,1
Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead Black box machine learning models are currently being used for high stakesdecisionmaking throughout society causing problems throughout healthcarecriminal justice and in other domains. People have hoped that creating methodsfor explaining these black box models will alleviate some of these problemsbut trying to textitexplain black box models rather than creating modelsthat are textitinterpretable in the first place is likely to perpetuate badpractices and can potentially cause catastrophic harm to society. There is away forward  it is to design models that are inherently interpretable. Thismanuscript clarifies the chasm between explaining black boxes and usinginherently interpretable models outlines several key reasons why explainableblack boxes should be avoided in highstakes decisions identifies challengesto interpretable machine learning and provides several example applicationswhere interpretable models could potentially replace black box models incriminal justice healthcare and computer vision.,1
VOS Learning What You Dont Know by Virtual Outlier Synthesis Outofdistribution OOD detection has received much attention lately due toits importance in the safe deployment of neural networks. One of the keychallenges is that models lack supervision signals from unknown data and as aresult can produce overconfident predictions on OOD data. Previous approachesrely on real outlier datasets for model regularization which can be costly andsometimes infeasible to obtain in practice. In this paper we present VOS anovel framework for OOD detection by adaptively synthesizing virtual outliersthat can meaningfully regularize the models decision boundary during training.Specifically VOS samples virtual outliers from the lowlikelihood region ofthe classconditional distribution estimated in the feature space. Alongsidewe introduce a novel unknownaware training objective which contrastivelyshapes the uncertainty space between the ID data and synthesized outlier data.VOS achieves competitive performance on both object detection and imageclassification models reducing the FPR by up to . compared to theprevious best method on object detectors. Code is available at,1
BertNet Harvesting Knowledge Graphs from Pretrained Language Models Symbolic knowledge graphs KGs have been constructed either by expensivehuman crowdsourcing or with domainspecific complex information extractionpipelines. The emerging large pretrained language models LMs such as Berthave shown to implicitly encode massive knowledge which can be queried withproperly designed prompts. However compared to the explicit KGs the implictknowledge in the blackbox LMs is often difficult to access or edit and lacksexplainability. In this work we aim at harvesting symbolic KGs from the LMs anew framework for automatic KG construction empowered by the neural LMsflexibility and scalability. Compared to prior works that often rely on largehuman annotated data or existing massive KGs our approach requires only theminimal definition of relations as inputs and hence is suitable for extractingknowledge of rich new relations not available before.The approach automaticallygenerates diverse prompts and performs efficient knowledge search within agiven LM for consistent and extensive outputs. The harvested knowledge with ourapproach is substantially more accurate than with previous methods as shown inboth automatic and human evaluation. As a result we derive from diverse LMs afamily of new KGs e.g. BertNet and RoBERTaNet that contain a richer set ofcommonsense relations including complex ones e.g. A is capable of but notgood at B than the humanannotated KGs e.g. ConceptNet. Besides theresulting KGs also serve as a vehicle to interpret the respective source LMsleading to new insights into the varying knowledge capability of different LMs.,1
Natural Language Descriptions of Deep Visual Features Some neurons in deep networks specialize in recognizing highly specificperceptual structural or semantic features of inputs. In computer visiontechniques exist for identifying neurons that respond to individual conceptcategories like colors textures and object classes. But these techniques arelimited in scope labeling only a small subset of neurons and behaviors in anynetwork. Is a richer characterization of neuronlevel computation possible Weintroduce a procedure called MILAN for mutualinformationguided linguisticannotation of neurons that automatically labels neurons with openendedcompositional natural language descriptions. Given a neuron MILAN generates adescription by searching for a natural language string that maximizes pointwisemutual information with the image regions in which the neuron is active. MILANproduces finegrained descriptions that capture categorical relational andlogical structure in learned features. These descriptions obtain high agreementwith humangenerated feature descriptions across a diverse set of modelarchitectures and tasks and can aid in understanding and controlling learnedmodels. We highlight three applications of natural language neurondescriptions. First we use MILAN for analysis characterizing the distributionand importance of neurons selective for attribute category and relationalinformation in vision models. Second we use MILAN for auditing surfacingneurons sensitive to human faces in datasets designed to obscure them. Finallywe use MILAN for editing improving robustness in an image classifier bydeleting neurons sensitive to text features spuriously correlated with classlabels.,1
Network Dissection Quantifying Interpretability of Deep Visual Representations We propose a general framework called Network Dissection for quantifying theinterpretability of latent representations of CNNs by evaluating the alignmentbetween individual hidden units and a set of semantic concepts. Given any CNNmodel the proposed method draws on a broad data set of visual concepts toscore the semantics of hidden units at each intermediate convolutional layer.The units with semantics are given labels across a range of objects partsscenes textures materials and colors. We use the proposed method to test thehypothesis that interpretability of units is equivalent to random linearcombinations of units then we apply our method to compare the latentrepresentations of various networks when trained to solve different supervisedand selfsupervised training tasks. We further analyze the effect of trainingiterations compare networks trained with different initializations examinethe impact of network depth and width and measure the effect of dropout andbatch normalization on the interpretability of deep visual representations. Wedemonstrate that the proposed method can shed light on characteristics of CNNmodels and training methods that go beyond measurements of their discriminativepower.,1
BadNets Identifying Vulnerabilities in the Machine Learning Model Supply Chain Deep learningbased techniques have achieved stateoftheart performance ona wide variety of recognition and classification tasks. However these networksare typically computationally expensive to train requiring weeks ofcomputation on many GPUs as a result many users outsource the trainingprocedure to the cloud or rely on pretrained models that are then finetunedfor a specific task. In this paper we show that outsourced training introducesnew security risks an adversary can create a maliciously trained network abackdoored neural network or a emphBadNet that has stateoftheartperformance on the users training and validation samples but behaves badly onspecific attackerchosen inputs. We first explore the properties of BadNets ina toy example by creating a backdoored handwritten digit classifier. Next wedemonstrate backdoors in a more realistic scenario by creating a U.S. streetsign classifier that identifies stop signs as speed limits when a specialsticker is added to the stop sign we then show in addition that the backdoorin our US street sign detector can persist even if the network is laterretrained for another task and cause a drop in accuracy of  on averagewhen the backdoor trigger is present. These results demonstrate that backdoorsin neural networks are both powerful andbecause the behavior of neuralnetworks is difficult to explicatestealthy. This work provides motivationfor further research into techniques for verifying and inspecting neuralnetworks just as we have developed tools for verifying and debugging software.,1
Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning Deep learning models have achieved high performance on many tasks and thushave been applied to many securitycritical scenarios. For example deeplearningbased face recognition systems have been used to authenticate users toaccess many securitysensitive applications like payment apps. Such usages ofdeep learning systems provide the adversaries with sufficient incentives toperform attacks against these systems for their adversarial purposes. In thiswork we consider a new type of attacks called backdoor attacks where theattackers goal is to create a backdoor into a learningbased authenticationsystem so that he can easily circumvent the system by leveraging the backdoor.Specifically the adversary aims at creating backdoor instances so that thevictim learning system will be misled to classify the backdoor instances as atarget label specified by the adversary. In particular we study backdoorpoisoning attacks which achieve backdoor attacks using poisoning strategies.Different from all existing work our studied poisoning strategies can applyunder a very weak threat model  the adversary has no knowledge of the modeland the training set used by the victim system  the attacker is allowed toinject only a small amount of poisoning samples  the backdoor key is hardto notice even by human beings to achieve stealthiness. We conduct evaluationto demonstrate that a backdoor adversary can inject only around  poisoningsamples while achieving an attack success rate of above . We are also thefirst work to show that a data poisoning attack can create physicallyimplementable backdoors without touching the training process. Our workdemonstrates that backdoor poisoning attacks pose real threats to a learningsystem and thus highlights the importance of further investigation andproposing defense strategies against them.,1
Posterior calibration and exploratory analysis for natural language processing models Many models in natural language processing define probabilistic distributionsover linguistic structures. We argue that  the quality of a model sposterior distribution can and should be directly evaluated as to whetherprobabilities correspond to empirical frequencies and  NLP uncertainty canbe projected not only to pipeline components but also to exploratory dataanalysis telling a user when to trust and not trust the NLP analysis. Wepresent a method to analyze calibration and apply it to compare themiscalibration of several commonly used models. We also contribute acoreference sampling algorithm that can create confidence intervals for apolitical event extraction task.,1
Natural Backdoor Datasets Extensive literature on backdoor poison attacks has studied attacks anddefenses for backdoors using digital trigger patterns. In contrast physicalbackdoors use physical objects as triggers have only recently beenidentified and are qualitatively different enough to resist all defensestargeting digital trigger backdoors. Research on physical backdoors is limitedby access to large datasets containing real images of physical objectscolocated with targets of classification. Building these datasets is time andlaborintensive. This works seeks to address the challenge of accessibility forresearch on physical backdoor attacks. We hypothesize that there may benaturally occurring physically colocated objects already present in populardatasets such as ImageNet. Once identified a careful relabeling of these datacan transform them into training samples for physical backdoor attacks. Wepropose a method to scalably identify these subsets of potential triggers inexisting datasets along with the specific classes they can poison. We callthese naturally occurring triggerclass subsets natural backdoor datasets. Ourtechniques successfully identify natural backdoors in widelyavailabledatasets and produce models behaviorally equivalent to those trained onmanually curated datasets. We release our code to allow the research communityto create their own datasets for research on physical backdoor attacks.,1
On Calibration of Modern Neural Networks Confidence calibration  the problem of predicting probability estimatesrepresentative of the true correctness likelihood  is important forclassification models in many applications. We discover that modern neuralnetworks unlike those from a decade ago are poorly calibrated. Throughextensive experiments we observe that depth width weight decay and BatchNormalization are important factors influencing calibration. We evaluate theperformance of various postprocessing calibration methods on stateoftheartarchitectures with image and document classification datasets. Our analysis andexperiments not only offer insights into neural network learning but alsoprovide a simple and straightforward recipe for practical settings on mostdatasets temperature scaling  a singleparameter variant of Platt Scaling is surprisingly effective at calibrating predictions.,1
Exemplary Natural Images Explain CNN Activations Better than StateoftheArt Feature Visualization Feature visualizations such as synthetic maximally activating images are awidely used explanation method to better understand the information processingof convolutional neural networks CNNs. At the same time there are concernsthat these visualizations might not accurately represent CNNs inner workings.Here we measure how much extremely activating images help humans to predictCNN activations. Using a wellcontrolled psychophysical paradigm we comparethe informativeness of synthetic images by Olah et al.  with a simplebaseline visualization namely exemplary natural images that also stronglyactivate a specific feature map. Given either synthetic or natural referenceimages human participants choose which of two query images leads to strongpositive activation. The experiments are designed to maximize participantsperformance and are the first to probe intermediate instead of final layerrepresentations. We find that synthetic images indeed provide helpfulinformation about feature map activations pm accuracy chance would be. However natural images  originally intended as a baseline outperform synthetic images by a wide margin pm. Additionallyparticipants are faster and more confident for natural images whereassubjective impressions about the interpretability of the feature visualizationsare mixed. The higher informativeness of natural images holds across mostlayers for both expert and lay participants as well as for hand andrandomlypicked feature visualizations. Even if only a single reference imageis given synthetic images provide less information than natural imagespm vs. pm. In summary synthetic images from a popularfeature visualization method are significantly less informative for assessingCNN activations than natural images. We argue that visualization methods shouldimprove over this baseline.,1
Sanity Checks for Saliency Maps Saliency methods have emerged as a popular tool to highlight features in aninput deemed relevant for the prediction of a learned model. Several saliencymethods have been proposed often guided by visual appeal on image data. Inthis work we propose an actionable methodology to evaluate what kinds ofexplanations a given method can and cannot provide. We find that reliancesolely on visual assessment can be misleading. Through extensive experimentswe show that some existing saliency methods are independent both of the modeland of the data generating process. Consequently methods that fail theproposed tests are inadequate for tasks that are sensitive to either data ormodel such as finding outliers in the data explaining the relationshipbetween inputs and outputs that the model learned and debugging the model. Weinterpret our findings through an analogy with edge detection in images atechnique that requires neither training data nor model. Theory in the case ofa linear model and a singlelayer convolutional neural network supports ourexperimental findings.,1
Emergent Abilities of Large Language Models Scaling up language models has been shown to predictably improve performanceand sample efficiency on a wide range of downstream tasks. This paper insteaddiscusses an unpredictable phenomenon that we refer to as emergent abilities oflarge language models. We consider an ability to be emergent if it is notpresent in smaller models but is present in larger models. Thus emergentabilities cannot be predicted simply by extrapolating the performance ofsmaller models. The existence of such emergence implies that additional scalingcould further expand the range of capabilities of language models.,1
Can Backdoor Attacks Survive TimeVarying Models Backdoors are powerful attacks against deep neural networks DNNs. Bypoisoning training data attackers can inject hidden rules backdoors intoDNNs which only activate on inputs containing attackspecific triggers. Whileexisting work has studied backdoor attacks on a variety of DNN models theyonly consider static models which remain unchanged after initial deployment.,1
Auditing Visualizations Transparency Methods Struggle to Detect Anomalous Behavior Transparency methods such as model visualizations provide information thatoutputs alone might miss since they describe the internals of neural networks.But can we trust that model explanations reflect model behavior For instancecan they diagnose abnormal behavior such as backdoors or shape bias Toevaluate model explanations we define a model as anomalous if it differs froma reference set of normal models and we test whether transparency methodsassign different explanations to anomalous and normal models. We find thatwhile existing methods can detect stark anomalies such as shape bias oradversarial training they struggle to identify more subtle anomalies such asmodels trained on incomplete data. Moreover they generally fail to distinguishthe inputs that induce anomalous behavior e.g. images containing a backdoortrigger. These results reveal new blind spots in existing model explanationspointing to the need for further method development.,1
Accurate Uncertainties for Deep Learning Using Calibrated Regression Methods for reasoning under uncertainty are a key building block of accurateand reliable machine learning systems. Bayesian methods provide a generalframework to quantify uncertainty. However because of model misspecificationand the use of approximate inference Bayesian uncertainty estimates are ofteninaccurate  for example a  credible interval may not contain the trueoutcome  of the time. Here we propose a simple procedure for calibratingany regression algorithm when applied to Bayesian and probabilistic models itis guaranteed to produce calibrated uncertainty estimates given enough data.Our procedure is inspired by Platt scaling and extends previous work onclassification. We evaluate this approach on Bayesian linear regressionfeedforward and recurrent neural networks and find that it consistentlyoutputs wellcalibrated credible intervals while improving performance on timeseries forecasting and modelbased reinforcement learning tasks.,1
IBP Regularization for Verified Adversarial Robustness via BranchandBound Recent works have tried to increase the verifiability of adversariallytrained networks by running the attacks over domains larger than the originalperturbations and adding various regularization terms to the objective.However these algorithms either underperform or require complex and expensivestagewise training procedures hindering their practical applicability. Wepresent IBPR a novel verified training algorithm that is both simple andeffective. IBPR induces network verifiability by coupling adversarial attackson enlarged domains with a regularization term based on inexpensive intervalbound propagation that minimizes the gap between the nonconvex verificationproblem and its approximations. By leveraging recent branchandboundframeworks we show that IBPR obtains stateoftheart verifiedrobustnessaccuracy tradeoffs for small perturbations on CIFAR whiletraining significantly faster than relevant previous work. Additionally wepresent UPB a novel branching strategy that relying on a simple heuristicbased on betaCROWN reduces the cost of stateoftheart branchingalgorithms while yielding splits of comparable quality.,1
ViM OutOfDistribution with Virtuallogit Matching Most of the existing OutOfDistribution OOD detection algorithms depend onsingle input source the feature the logit or the softmax probability.However the immense diversity of the OOD examples makes such methods fragile.There are OOD samples that are easy to identify in the feature space while hardto distinguish in the logit space and vice versa. Motivated by thisobservation we propose a novel OOD scoring method named Virtuallogit MatchingViM which combines the classagnostic score from feature space and theInDistribution ID classdependent logits. Specifically an additional logitrepresenting the virtual OOD class is generated from the residual of thefeature against the principal space and then matched with the original logitsby a constant scaling. The probability of this virtual logit after softmax isthe indicator of OODness. To facilitate the evaluation of largescale OODdetection in academia we create a new OOD dataset for ImageNetK which ishumanannotated and is .x the size of existing datasets. We conductedextensive experiments including CNNs and vision transformers to demonstratethe effectiveness of the proposed ViM score. In particular using the BiTSmodel our method gets an average AUROC . on four difficult OODbenchmarks which is  ahead of the best baseline. Code and dataset areavailable at,1
Oneshot Neural Backdoor Erasing via Adversarial Weight Masking Recent studies show that despite achieving high accuracy on a number ofrealworld applications deep neural networks DNNs can be backdoored byinjecting triggered data samples into the training dataset the adversary canmislead the trained model into classifying any test data to the target class aslong as the trigger pattern is presented. To nullify such backdoor threatsvarious methods have been proposed. Particularly a line of research aims topurify the potentially compromised model. However one major limitation of thisline of work is the requirement to access sufficient original training datathe purifying performance is a lot worse when the available training data islimited. In this work we propose Adversarial Weight Masking AWM a novelmethod capable of erasing the neural backdoors even in the oneshot setting.The key idea behind our method is to formulate this into a minmax optimizationproblem first adversarially recover the trigger patterns and then soft maskthe network weights that are sensitive to the recovered patterns. Comprehensiveevaluations of several benchmark datasets suggest that AWM can largely improvethe purifying effects over other stateoftheart methods on various availabletraining dataset sizes.,1
Locating and Editing Factual Associations in GPT We analyze the storage and recall of factual associations in autoregressivetransformer language models finding evidence that these associationscorrespond to localized directlyeditable computations. We first develop acausal intervention for identifying neuron activations that are decisive in amodels factual predictions. This reveals a distinct set of steps inmiddlelayer feedforward modules that mediate factual predictions whileprocessing subject tokens. To test our hypothesis that these computationscorrespond to factual association recall we modify feedforward weights toupdate specific factual associations using RankOne Model Editing ROME. Wefind that ROME is effective on a standard zeroshot relation extraction zsREmodelediting task comparable to existing methods. To perform a more sensitiveevaluation we also evaluate ROME on a new dataset of counterfactualassertions on which it simultaneously maintains both specificity andgeneralization whereas other methods sacrifice one or another. Our resultsconfirm an important role for midlayer feedforward modules in storing factualassociations and suggest that direct manipulation of computational mechanismsmay be a feasible approach for model editing. The code datasetvisualizations and an interactive demo notebook are available at,1
Can You Trust Your Models Uncertainty Evaluating Predictive Uncertainty Under Dataset Shift Modern machine learning methods including deep learning have achieved greatsuccess in predictive accuracy for supervised learning tasks but may stillfall short in giving useful estimates of their predictive em uncertainty.Quantifying uncertainty is especially critical in realworld settings whichoften involve input distributions that are shifted from the trainingdistribution due to a variety of factors including sample bias andnonstationarity. In such settings well calibrated uncertainty estimatesconvey information about when a models output should or should not betrusted. Many probabilistic deep learning methods including BayesianandnonBayesian methods have been proposed in the literature for quantifyingpredictive uncertainty but to our knowledge there has not previously been arigorous largescale empirical comparison of these methods under dataset shift.We present a largescale benchmark of existing stateoftheart methods onclassification problems and investigate the effect of dataset shift on accuracyand calibration. We find that traditional posthoc calibration does indeed fallshort as do several other previous methods. However some methods thatmarginalize over models give surprisingly strong results across a broadspectrum of tasks.,1
PixMix Dreamlike Pictures Comprehensively Improve Safety Measures In realworld applications of machine learning reliable and safe systemsmust consider measures of performance beyond standard test set accuracy. Theseother goals include outofdistribution OOD robustness predictionconsistency resilience to adversaries calibrated uncertainty estimates andthe ability to detect anomalous inputs. However improving performance towardsthese goals is often a balancing act that todays methods cannot achievewithout sacrificing performance on other safety axes. For instance adversarialtraining improves adversarial robustness but sharply degrades other classifierperformance metrics. Similarly strong data augmentation and regularizationtechniques often improve OOD robustness but harm anomaly detection raising thequestion of whether a Pareto improvement on all existing safety measures ispossible. To meet this challenge we design a new data augmentation strategyutilizing the natural structural complexity of pictures such as fractals whichoutperforms numerous baselines is near Paretooptimal and roundly improvessafety measures.,1
Network Dissection Quantifying Interpretability of Deep Visual Representations We propose a general framework called Network Dissection for quantifying theinterpretability of latent representations of CNNs by evaluating the alignmentbetween individual hidden units and a set of semantic concepts. Given any CNNmodel the proposed method draws on a broad data set of visual concepts toscore the semantics of hidden units at each intermediate convolutional layer.The units with semantics are given labels across a range of objects partsscenes textures materials and colors. We use the proposed method to test thehypothesis that interpretability of units is equivalent to random linearcombinations of units then we apply our method to compare the latentrepresentations of various networks when trained to solve different supervisedand selfsupervised training tasks. We further analyze the effect of trainingiterations compare networks trained with different initializations examinethe impact of network depth and width and measure the effect of dropout andbatch normalization on the interpretability of deep visual representations. Wedemonstrate that the proposed method can shed light on characteristics of CNNmodels and training methods that go beyond measurements of their discriminativepower.,1
WeShort Outofdistribution Detection With Weak Shortcut structure Neural networks have achieved impressive performance for data in thedistribution which is the same as the training set but can produce anoverconfident incorrect result for the data these networks have never seen.Therefore it is essential to detect whether inputs come fromoutofdistributionOOD in order to guarantee the safety of neural networksdeployed in the real world. In this paper we propose a simple and effectiveposthoc technique WeShort to reduce the overconfidence of neural networks onOOD data. Our method is inspired by the observation of the internal residualstructure which shows the separation of the OOD and indistribution ID datain the shortcut layer. Our method is compatible with different OOD detectionscores and can generalize well to different architectures of networks. Wedemonstrate our method on various OOD datasets to show its competitiveperformances and provide reasonable hypotheses to explain why our method works.On the ImageNet benchmark Weshort achieves stateoftheart performance on thefalse positive rate FPR and the area under the receiver operatingcharacteristic AUROC on the family of posthoc methods.,1
A Baseline for Detecting Misclassified and OutofDistribution Examples in Neural Networks We consider the two related problems of detecting if an example ismisclassified or outofdistribution. We present a simple baseline thatutilizes probabilities from softmax distributions. Correctly classifiedexamples tend to have greater maximum softmax probabilities than erroneouslyclassified and outofdistribution examples allowing for their detection. Weassess performance by defining several tasks in computer vision naturallanguage processing and automatic speech recognition showing theeffectiveness of this baseline across all. We then show the baseline cansometimes be surpassed demonstrating the room for future research on theseunderexplored detection tasks.,1
BackdoorBench A Comprehensive Benchmark of Backdoor Learning Backdoor learning is an emerging and important topic of studying thevulnerability of deep neural networks DNNs. Many pioneering backdoor attackand defense methods are being proposed successively or concurrently in thestatus of a rapid arms race. However we find that the evaluations of newmethods are often unthorough to verify their claims and real performancemainly due to the rapid development diverse settings as well as thedifficulties of implementation and reproducibility. Without thoroughevaluations and comparisons it is difficult to track the current progress anddesign the future development roadmap of the literature. To alleviate thisdilemma we build a comprehensive benchmark of backdoor learning calledBackdoorBench. It consists of an extensible modular based codebase currentlyincluding implementations of  stateoftheart SOTA attack and  SOTAdefense algorithms as well as a standardized protocol of a complete backdoorlearning. We also provide comprehensive evaluations of every pair of  attacksagainst  defenses with  poisoning ratios based on  models and  datasetsthus  pairs of evaluations in total. We further present analysis fromdifferent perspectives about these  evaluations studying the effects ofattack against defense algorithms poisoning ratio model and dataset inbackdoor learning. All codes and evaluations of BackdoorBench are publiclyavailable at url,1
The Effects of Reward Misspecification Mapping and Mitigating Misaligned Models Reward hacking  where RL agents exploit gaps in misspecified rewardfunctions  has been widely observed but not yet systematically studied. Tounderstand how reward hacking arises we construct four RL environments withmisspecified rewards. We investigate reward hacking as a function of agentcapabilities model capacity action space resolution observation space noiseand training time. More capable agents often exploit reward misspecificationsachieving higher proxy reward and lower true reward than less capable agents.Moreover we find instances of phase transitions capability thresholds atwhich the agents behavior qualitatively shifts leading to a sharp decrease inthe true reward. Such phase transitions pose challenges to monitoring thesafety of ML systems. To address this we propose an anomaly detection task foraberrant policies and offer several baseline detectors.,1
The Mythos of Model Interpretability Supervised machine learning models boast remarkable predictive capabilities.But can you trust your model Will it work in deployment What else can it tellyou about the world We want models to be not only good but interpretable. Andyet the task of interpretation appears underspecified. Papers provide diverseand sometimes nonoverlapping motivations for interpretability and offermyriad notions of what attributes render models interpretable. Despite thisambiguity many papers proclaim interpretability axiomatically absent furtherexplanation. In this paper we seek to refine the discourse oninterpretability. First we examine the motivations underlying interest ininterpretability finding them to be diverse and occasionally discordant. Thenwe address model properties and techniques thought to confer interpretabilityidentifying transparency to humans and posthoc explanations as competingnotions. Throughout we discuss the feasibility and desirability of differentnotions and question the oftmade assertions that linear models areinterpretable and that deep neural networks are not.,1
Scaling OutofDistribution Detection for RealWorld Settings Detecting outofdistribution examples is important for safetycriticalmachine learning applications such as detecting novel biological phenomena andselfdriving cars. However existing research mainly focuses on simplesmallscale settings. To set the stage for more realistic outofdistributiondetection we depart from smallscale settings and explore largescalemulticlass and multilabel settings with highresolution images and thousandsof classes. To make future work in realworld settings possible we create newbenchmarks for three largescale settings. To test ImageNet multiclass anomalydetectors we introduce the Species dataset containing over  images andover a thousand anomalous species. We leverage ImageNetK to evaluate PASCALVOC and COCO multilabel anomaly detectors. Third we introduce a new benchmarkfor anomaly segmentation by introducing a segmentation benchmark with roadanomalies. We conduct extensive experiments in these more realistic settingsfor outofdistribution detection and find that a surprisingly simple detectorbased on the maximum logit outperforms prior methods in all the largescalemulticlass multilabel and segmentation tasks establishing a simple newbaseline for future work.,1
Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles Deep neural networks NNs are powerful black box predictors that haverecently achieved impressive performance on a wide spectrum of tasks.Quantifying predictive uncertainty in NNs is a challenging and yet unsolvedproblem. Bayesian NNs which learn a distribution over weights are currentlythe stateoftheart for estimating predictive uncertainty however theserequire significant modifications to the training procedure and arecomputationally expensive compared to standard nonBayesian NNs. We proposean alternative to Bayesian NNs that is simple to implement readilyparallelizable requires very little hyperparameter tuning and yields highquality predictive uncertainty estimates. Through a series of experiments onclassification and regression benchmarks we demonstrate that our methodproduces wellcalibrated uncertainty estimates which are as good or better thanapproximate Bayesian NNs. To assess robustness to dataset shift we evaluatethe predictive uncertainty on test examples from known and unknowndistributions and show that our method is able to express higher uncertaintyon outofdistribution examples. We demonstrate the scalability of our methodby evaluating predictive uncertainty estimates on ImageNet.,1
Data Augmentation Can Improve Robustness Adversarial training suffers from robust overfitting a phenomenon where therobust test accuracy starts to decrease during training. In this paper wefocus on reducing robust overfitting by using common data augmentation schemes.We demonstrate that contrary to previous findings when combined with modelweight averaging data augmentation can significantly boost robust accuracy.Furthermore we compare various augmentations techniques and observe thatspatial composition techniques work the best for adversarial training. Finallywe evaluate our approach on CIFAR against ellinfty and ellnormbounded perturbations of size epsilon   and epsilon  respectively. We show large absolute improvements of . and . inrobust accuracy compared to previous stateoftheart methods. In particularagainst ellinfty normbounded perturbations of size epsilon  our model reaches . robust accuracy without using any external data. Wealso achieve a significant performance boost with this approach while usingother architectures and datasets such as CIFAR SVHN and TinyImageNet.,2
Towards Evaluating the Robustness of Neural Networks Neural networks provide stateoftheart results for most machine learningtasks. Unfortunately neural networks are vulnerable to adversarial examplesgiven an input x and any target classification t it is possible to find anew input x that is similar to x but classified as t. This makes itdifficult to apply neural networks in securitycritical areas. Defensivedistillation is a recently proposed approach that can take an arbitrary neuralnetwork and increase its robustness reducing the success rate of currentattacks ability to find adversarial examples from  to ..,2
Reliable evaluation of adversarial robustness with an ensemble of diverse parameterfree attacks The field of defense strategies against adversarial attacks has significantlygrown over the last years but progress is hampered as the evaluation ofadversarial defenses is often insufficient and thus gives a wrong impression ofrobustness. Many promising defenses could be broken later on making itdifficult to identify the stateoftheart. Frequent pitfalls in the evaluationare improper tuning of hyperparameters of the attacks gradient obfuscation ormasking. In this paper we first propose two extensions of the PGDattackovercoming failures due to suboptimal step size and problems of the objectivefunction. We then combine our novel attacks with two complementary existingones to form a parameterfree computationally affordable and userindependentensemble of attacks to test adversarial robustness. We apply our ensemble toover  models from papers published at recent top machine learning andcomputer vision venues. In all except one of the cases we achieve lower robusttest accuracy than reported in these papers often by more than identifying several broken defenses.,2
Motivating the Rules of the Game for Adversarial Example Research Advances in machine learning have led to broad deployment of systems withimpressive performance on important problems. Nonetheless these systems can beinduced to make errors on data that are surprisingly similar to examples thelearned system handles correctly. The existence of these errors raises avariety of questions about outofsample generalization and whether bad actorsmight use such examples to abuse deployed systems. As a result of thesesecurity concerns there has been a flurry of recent papers proposingalgorithms to defend against such malicious perturbations of correctly handledexamples. It is unclear how such misclassifications represent a different kindof security problem than other errors or even other attackerproduced examplesthat have no specific relationship to an uncorrupted input. In this paper weargue that adversarial example defense papers have to date mostly consideredabstract toy games that do not relate to any specific security concern.Furthermore defense papers have not yet precisely described all the abilitiesand limitations of attackers that would be relevant in practical security.Towards this end we establish a taxonomy of motivations constraints andabilities for more plausible adversaries. Finally we provide a series ofrecommendations outlining a path forward for future work to more clearlyarticulate the threat model and perform more meaningful evaluation.,2
Adversarial Examples for Evaluating Reading Comprehension Systems Standard accuracy metrics indicate that reading comprehension systems aremaking rapid progress but the extent to which these systems truly understandlanguage remains unclear. To reward systems with real language understandingabilities we propose an adversarial evaluation scheme for the StanfordQuestion Answering Dataset SQuAD. Our method tests whether systems can answerquestions about paragraphs that contain adversarially inserted sentences whichare automatically generated to distract computer systems without changing thecorrect answer or misleading humans. In this adversarial setting the accuracyof sixteen published models drops from an average of  F score to when the adversary is allowed to add ungrammatical sequences of words averageaccuracy on four models decreases further to . We hope our insights willmotivate the development of new models that understand language more precisely.,2
Reliable evaluation of adversarial robustness with an ensemble of diverse parameterfree attacks The field of defense strategies against adversarial attacks has significantlygrown over the last years but progress is hampered as the evaluation ofadversarial defenses is often insufficient and thus gives a wrong impression ofrobustness. Many promising defenses could be broken later on making itdifficult to identify the stateoftheart. Frequent pitfalls in the evaluationare improper tuning of hyperparameters of the attacks gradient obfuscation ormasking. In this paper we first propose two extensions of the PGDattackovercoming failures due to suboptimal step size and problems of the objectivefunction. We then combine our novel attacks with two complementary existingones to form a parameterfree computationally affordable and userindependentensemble of attacks to test adversarial robustness. We apply our ensemble toover  models from papers published at recent top machine learning andcomputer vision venues. In all except one of the cases we achieve lower robusttest accuracy than reported in these papers often by more than identifying several broken defenses.,2
Adversarial Robustness is at Odds with Lazy Training Recent works show that random neural networks are vulnerable againstadversarial attacks Daniely and Schacham  and that such attacks can beeasily found using a single step of gradient descent Bubeck et al. . Inthis work we take it one step further and show that a single gradient step canfind adversarial examples for networks trained in the socalled lazy regime.This regime is interesting because even though the neural network weightsremain close to the initialization there exist networks with smallgeneralization error which can be found efficiently using firstorder methods.Our work challenges the model of the lazy regime the dominant regime in whichneural networks are provably efficiently learnable. We show that the networkstrained in this regime even though they enjoy good theoretical computationalguarantees remain vulnerable to adversarial examples. To the best of ourknowledge this is the first work to prove that such wellgeneralizable neuralnetworks are still vulnerable to adversarial attacks.,2
WILDS A Benchmark of intheWild Distribution Shifts Distribution shifts  where the training distribution differs from the testdistribution  can substantially degrade the accuracy of machine learning MLsystems deployed in the wild. Despite their ubiquity in the realworlddeployments these distribution shifts are underrepresented in the datasetswidely used in the ML community today. To address this gap we present WILDS acurated benchmark of  datasets reflecting a diverse range of distributionshifts that naturally arise in realworld applications such as shifts acrosshospitals for tumor identification across camera traps for wildlifemonitoring and across time and location in satellite imaging and povertymapping. On each dataset we show that standard training yields substantiallylower outofdistribution than indistribution performance. This gap remainseven with models trained by existing methods for tackling distribution shiftsunderscoring the need for new methods for training models that are more robustto the types of distribution shifts that arise in practice. To facilitatemethod development we provide an opensource package that automates datasetloading contains default model architectures and hyperparameters andstandardizes evaluations. Code and leaderboards are available at,2
Augmenting Softmax Information for Selective Classification with OutofDistribution Data Detecting outofdistribution OOD data is a task that is receiving anincreasing amount of research attention in the domain of deep learning forcomputer vision. However the performance of detection methods is generallyevaluated on the task in isolation rather than also considering potentialdownstream tasks in tandem. In this work we examine selective classificationin the presence of OOD data SCOD. That is to say the motivation fordetecting OOD samples is to reject them so their impact on the quality ofpredictions is reduced. We show under this task specification that existingposthoc methods perform quite differently compared to when evaluated only onOOD detection. This is because it is no longer an issue to conflateindistribution ID data with OOD data if the ID data is going to bemisclassified. However the conflation within ID data of correct and incorrectpredictions becomes undesirable. We also propose a novel method for SCODSoftmax Information Retaining Combination SIRC that augments softmaxbasedconfidence scores with featureagnostic information such that their ability toidentify OOD samples is improved without sacrificing separation between correctand incorrect ID predictions. Experiments on a wide variety of ImageNetscaledatasets and convolutional neural network architectures show that SIRC is ableto consistently match or outperform the baseline for SCOD whilst existing OODdetection methods fail to do so.,2
Can CNNs Be More Robust Than Transformers The recent success of Vision Transformers is shaking the long dominance ofConvolutional Neural Networks CNNs in image recognition for a decade.Specifically in terms of robustness on outofdistribution samples recentresearch finds that Transformers are inherently more robust than CNNsregardless of different training setups. Moreover it is believed that suchsuperiority of Transformers should largely be credited to theirselfattentionlike architectures per se. In this paper we question thatbelief by closely examining the design of Transformers. Our findings lead tothree highly effective architecture designs for boosting robustness yet simpleenough to be implemented in several lines of code namely a patchifying inputimages b enlarging kernel size and c reducing activation layers andnormalization layers. Bringing these components together we are able to buildpure CNN architectures without any attentionlike operations that is as robustas or even more robust than Transformers. We hope this work can help thecommunity better understand the design of robust neural architectures. The codeis publicly available at,2
The Many Faces of Robustness A Critical Analysis of OutofDistribution Generalization We introduce four new realworld distribution shift datasets consisting ofchanges in image style image blurriness geographic location cameraoperation and more. With our new datasets we take stock of previouslyproposed methods for improving outofdistribution robustness and put them tothe test. We find that using larger models and artificial data augmentationscan improve robustness on realworld distribution shifts contrary to claims inprior work. We find improvements in artificial robustness benchmarks cantransfer to realworld distribution shifts contrary to claims in prior work.Motivated by our observation that data augmentations can help with realworlddistribution shifts we also introduce a new data augmentation method whichadvances the stateoftheart and outperforms models pretrained with  timesmore labeled data. Overall we find that some methods consistently help withdistribution shifts in texture and local image statistics but these methods donot help with some other distribution shifts like geographic changes. Ourresults show that future research must study multiple distribution shiftssimultaneously as we demonstrate that no evaluated method consistentlyimproves robustness.,2
Towards Deep Learning Models Resistant to Adversarial Attacks Recent work has demonstrated that deep neural networks are vulnerable toadversarial examplesinputs that are almost indistinguishable from naturaldata and yet classified incorrectly by the network. In fact some of the latestfindings suggest that the existence of adversarial attacks may be an inherentweakness of deep learning models. To address this problem we study theadversarial robustness of neural networks through the lens of robustoptimization. This approach provides us with a broad and unifying view on muchof the prior work on this topic. Its principled nature also enables us toidentify methods for both training and attacking neural networks that arereliable and in a certain sense universal. In particular they specify aconcrete security guarantee that would protect against any adversary. Thesemethods let us train networks with significantly improved resistance to a widerange of adversarial attacks. They also suggest the notion of security againsta firstorder adversary as a natural and broad security guarantee. We believethat robustness against such welldefined classes of adversaries is animportant stepping stone towards fully resistant deep learning models. Code andpretrained models are available at,2
Diffusion Models for Adversarial Purification Adversarial purification refers to a class of defense methods that removeadversarial perturbations using a generative model. These methods do not makeassumptions on the form of attack and the classification model and thus candefend preexisting classifiers against unseen threats. However theirperformance currently falls behind adversarial training methods. In this workwe propose DiffPure that uses diffusion models for adversarial purificationGiven an adversarial example we first diffuse it with a small amount of noisefollowing a forward diffusion process and then recover the clean image througha reverse generative process. To evaluate our method against strong adaptiveattacks in an efficient and scalable way we propose to use the adjoint methodto compute full gradients of the reverse generative process. Extensiveexperiments on three image datasets including CIFAR ImageNet and CelebAHQwith three classifier architectures including ResNet WideResNet and ViTdemonstrate that our method achieves the stateoftheart resultsoutperforming current adversarial training and adversarial purificationmethods often by a large margin. Project page,2
BERTATTACK Adversarial Attack Against BERT Using BERT Adversarial attacks for discrete data such as texts have been provedsignificantly more challenging than continuous data such as images since itis difficult to generate adversarial samples with gradientbased methods.Current successful attack methods for texts usually adopt heuristic replacementstrategies on the character or word level which remains challenging to findthe optimal solution in the massive space of possible combinations ofreplacements while preserving semantic consistency and language fluency. Inthis paper we propose textbfBERTAttack a highquality and effectivemethod to generate adversarial samples using pretrained masked language modelsexemplified by BERT. We turn BERT against its finetuned models and other deepneural models in downstream tasks so that we can successfully mislead thetarget models to predict incorrectly. Our method outperforms stateoftheartattack strategies in both success rate and perturb percentage while thegenerated adversarial samples are fluent and semantically preserved. Also thecost of calculation is low thus possible for largescale generations. The codeis available at,2
Adversarial Training for HighStakes Reliability In the future powerful AI systems may be deployed in highstakes settingswhere a single failure could be catastrophic. One technique for improving AIsafety in highstakes settings is adversarial training which uses an adversaryto generate examples to train on in order to achieve better worstcaseperformance.,2
Probable Domain Generalization via Quantile Risk Minimization Domain generalization DG seeks predictors which perform well on unseen testdistributions by leveraging labeled training data from multiple relateddistributions or domains. To achieve this the standard formulation optimizesfor worstcase performance over the set of all possible domains. However withworstcase shifts very unlikely in practice this generally leads tooverlyconservative solutions. In fact a recent study found that no DGalgorithm outperformed empirical risk minimization in terms of averageperformance. In this work we argue that DG is neither a worstcase problem noran averagecase problem but rather a probabilistic one. To this end wepropose a probabilistic framework for DG which we call Probable DomainGeneralization wherein our key idea is that distribution shifts seen duringtraining should inform us of probable shifts at test time. To realize this weexplicitly relate training and test domains as draws from the same underlyingmetadistribution and propose a new optimization problem  Quantile RiskMinimization QRM  which requires that predictors generalize with highprobability. We then prove that QRM i produces predictors that generalize tonew domains with a desired probability given sufficiently many domains andsamples and ii recovers the causal predictor as the desired probability ofgeneralization approaches one. In our experiments we introduce a more holisticquantilefocused evaluation protocol for DG and show that our algorithmsoutperform stateoftheart baselines on real and synthetic data.,2
Adversarial Examples for Evaluating Reading Comprehension Systems Standard accuracy metrics indicate that reading comprehension systems aremaking rapid progress but the extent to which these systems truly understandlanguage remains unclear. To reward systems with real language understandingabilities we propose an adversarial evaluation scheme for the StanfordQuestion Answering Dataset SQuAD. Our method tests whether systems can answerquestions about paragraphs that contain adversarially inserted sentences whichare automatically generated to distract computer systems without changing thecorrect answer or misleading humans. In this adversarial setting the accuracyof sixteen published models drops from an average of  F score to when the adversary is allowed to add ungrammatical sequences of words averageaccuracy on four models decreases further to . We hope our insights willmotivate the development of new models that understand language more precisely.,2
Benchmarking Neural Network Robustness to Common Corruptions and Perturbations In this paper we establish rigorous benchmarks for image classifierrobustness. Our first benchmark ImageNetC standardizes and expands thecorruption robustness topic while showing which classifiers are preferable insafetycritical applications. Then we propose a new dataset called ImageNetPwhich enables researchers to benchmark a classifiers robustness to commonperturbations. Unlike recent robustness research this benchmark evaluatesperformance on common corruptions and perturbations not worstcase adversarialperturbations. We find that there are negligible changes in relative corruptionrobustness from AlexNet classifiers to ResNet classifiers. Afterward wediscover ways to enhance corruption and perturbation robustness. We even findthat a bypassed adversarial defense provides substantial common perturbationrobustness. Together our benchmarks may aid future work toward networks thatrobustly generalize.,2
Back to the Source DiffusionDriven TestTime Adaptation Testtime adaptation harnesses test inputs to improve the accuracy of a modeltrained on source data when tested on shifted target data. Existing methodsupdate the source model by retraining on each target domain. Whileeffective retraining is sensitive to the amount and order of the data and thehyperparameters for optimization. We instead update the target data byprojecting all test inputs toward the source domain with a generative diffusionmodel. Our diffusiondriven adaptation method DDA shares its models forclassification and generation across all domains. Both models are trained onthe source domain then fixed during testing. We augment diffusion with imageguidance and selfensembling to automatically decide how much to adapt. Inputadaptation by DDA is more robust than prior model adaptation approaches acrossa variety of corruptions architectures and data regimes on the ImageNetCbenchmark. With its inputwise updates DDA succeeds where model adaptationdegrades on too little data in small batches dependent data in nonuniformorder or mixed data with multiple corruptions.,2
Formulating Robustness Against Unforeseen Attacks Existing defenses against adversarial examples such as adversarial trainingtypically assume that the adversary will conform to a specific or known threatmodel such as ellp perturbations within a fixed budget. In this paper wefocus on the scenario where there is a mismatch in the threat model assumed bythe defense during training and the actual capabilities of the adversary attest time. We ask the question if the learner trains against a specificsource threat model when can we expect robustness to generalize to astronger unknown target threat model during testtime Our key contributionis to formally define the problem of learning and generalization with anunforeseen adversary which helps us reason about the increase in adversarialrisk from the conventional perspective of a known adversary. Applying ourframework we derive a generalization bound which relates the generalizationgap between source and target threat models to variation of the featureextractor which measures the expected maximum difference between extractedfeatures across a given threat model. Based on our generalization bound wepropose adversarial training with variation regularization ATVR whichreduces variation of the feature extractor across the source threat modelduring training. We empirically demonstrate that ATVR can lead to improvedgeneralization to unforeseen attacks during testtime compared to standardadversarial training on Gaussian and image datasets.,2
Adversarial NLI A New Benchmark for Natural Language Understanding We introduce a new largescale NLI benchmark dataset collected via aniterative adversarial humanandmodelintheloop procedure. We show thattraining models on this new dataset leads to stateoftheart performance on avariety of popular NLI benchmarks while posing a more difficult challenge withits new test set. Our analysis sheds light on the shortcomings of currentstateoftheart models and shows that nonexpert annotators are successful atfinding their weaknesses. The data collection method can be applied in aneverending learning scenario becoming a moving target for NLU rather than astatic benchmark that will quickly saturate.,2
Using PreTraining Can Improve Model Robustness and Uncertainty He et al.  have called into question the utility of pretraining byshowing that training from scratch can often yield similar performance topretraining. We show that although pretraining may not improve performance ontraditional classification metrics it improves model robustness anduncertainty estimates. Through extensive experiments on adversarial exampleslabel corruption class imbalance outofdistribution detection andconfidence calibration we demonstrate large gains from pretraining andcomplementary effects with taskspecific methods. We introduce adversarialpretraining and show approximately a  absolute improvement over theprevious stateoftheart in adversarial robustness. In some cases usingpretraining without taskspecific methods also surpasses the stateofthearthighlighting the need for pretraining when evaluating future methods onrobustness and uncertainty tasks.,2
Natural Adversarial Examples We introduce two challenging datasets that reliably cause machine learningmodel performance to substantially degrade. The datasets are collected with asimple adversarial filtration technique to create datasets with limitedspurious cues. Our datasets realworld unmodified examples transfer tovarious unseen models reliably demonstrating that computer vision models haveshared weaknesses. The first dataset is called ImageNetA and is like theImageNet test set but it is far more challenging for existing models. We alsocurate an adversarial outofdistribution detection dataset called ImageNetOwhich is the first outofdistribution detection dataset created for ImageNetmodels. On ImageNetA a DenseNet obtains around  accuracy an accuracydrop of approximately  and its outofdistribution detection performance onImageNetO is near random chance levels. We find that existing dataaugmentation techniques hardly boost performance and using other publictraining datasets provides improvements that are limited. However we find thatimprovements to computer vision architectures provide a promising path towardsrobust models.,2
On the Robustness of Safe Reinforcement Learning under Observational Perturbations Safe reinforcement learning RL trains a policy to maximize the task rewardwhile satisfying safety constraints. While prior works focus on the performanceoptimality we find that the optimal solutions of many safe RL problems are notrobust and safe against carefully designed observational perturbations. Weformally analyze the unique properties of designing effective state adversarialattackers in the safe RL setting. We show that baseline adversarial attacktechniques for standard RL tasks are not always effective for safe RL andproposed two new approaches  one maximizes the cost and the other maximizesthe reward. One interesting and counterintuitive finding is that the maximumreward attack is strong as it can both induce unsafe behaviors and make theattack stealthy by maintaining the reward. We further propose a more effectiveadversarial training framework for safe RL and evaluate it via comprehensiveexperiments. This work sheds light on the inherited connection betweenobservational robustness and safety in RL and provides a pioneer work forfuture safe RL studies.,2
A law of adversarial risk interpolation and label noise In supervised learning it has been shown that label noise in the data can beinterpolated without penalties on test accuracy under many circumstances. Weshow that interpolating label noise induces adversarial vulnerability andprove the first theorem showing the dependence of label noise and adversarialrisk in terms of the data distribution. Our results are almost sharp withoutaccounting for the inductive bias of the learning algorithm. We also show thatinductive bias makes the effect of label noise much stronger.,2
Demystifying the Adversarial Robustness of Random Transformation Defenses Neural networks lack of robustness against attacks raises concerns insecuritysensitive settings such as autonomous vehicles. While manycountermeasures may look promising only a few withstand rigorous evaluation.Defenses using random transformations RT have shown impressive resultsparticularly BaRT Raff et al.  on ImageNet. However this type ofdefense has not been rigorously evaluated leaving its robustness propertiespoorly understood. Their stochastic properties make evaluation more challengingand render many proposed attacks on deterministic models inapplicable. Firstwe show that the BPDA attack Athalye et al. a used in BaRTs evaluationis ineffective and likely overestimates its robustness. We then attempt toconstruct the strongest possible RT defense through the informed selection oftransformations and Bayesian optimization for tuning their parameters.Furthermore we create the strongest possible attack to evaluate our RTdefense. Our new attack vastly outperforms the baseline reducing the accuracyby  compared to the  reduction by the commonly used EoT attack.times improvement. Our result indicates that the RT defense on theImagenette dataset a tenclass subset of ImageNet is not robust againstadversarial examples. Extending the study further we use our new attack toadversarially train RT defense called AdvRT resulting in a large robustnessgain. Code is available at,2
Universal Adversarial Triggers for Attacking and Analyzing NLP Adversarial examples highlight model vulnerabilities and are useful forevaluation and interpretation. We define universal adversarial triggersinputagnostic sequences of tokens that trigger a model to produce a specificprediction when concatenated to any input from a dataset. We propose agradientguided search over tokens which finds short trigger sequences e.g.one word for classification and four words for language modeling thatsuccessfully trigger the target prediction. For example triggers cause SNLIentailment accuracy to drop from . to .  of why questions inSQuAD to be answered to kill american people and the GPT language model tospew racist output even when conditioned on nonracial contexts. Furthermorealthough the triggers are optimized using whitebox access to a specific modelthey transfer to other models for all tasks we consider. Finally sincetriggers are inputagnostic they provide an analysis of global model behavior.For instance they confirm that SNLI models exploit dataset biases and help todiagnose heuristics learned by reading comprehension models.,2
AgreementontheLine Predicting the Performance of Neural Networks under Distribution Shift Recently Miller et al. showed that a models indistribution ID accuracyhas a strong linear correlation with its outofdistribution OOD accuracy onseveral OOD benchmarks  a phenomenon they dubbed accuracyontheline.While a useful tool for model selection i.e. the model most likely to performthe best OOD is the one with highest ID accuracy this fact does not helpestimate the actual OOD performance of models without access to a labeled OODvalidation set. In this paper we show a similar but surprising phenomenon alsoholds for the agreement between pairs of neural network classifiers wheneveraccuracyontheline holds we observe that the OOD agreement between thepredictions of any two pairs of neural networks with potentially differentarchitectures also observes a strong linear correlation with their IDagreement. Furthermore we observe that the slope and bias of OOD vs IDagreement closely matches that of OOD vs ID accuracy. This phenomenon which wecall agreementontheline has important practical applications without anylabeled data we can predict the OOD accuracy of classifiers since OODagreement can be estimated with just unlabeled data. Our prediction algorithmoutperforms previous methods both in shifts where agreementontheline holdsand surprisingly when accuracy is not on the line. This phenomenon alsoprovides new insights into deep neural networks unlike accuracyonthelineagreementontheline appears to only hold for neural network classifiers.,2
Robustifying Vision Transformer without Retraining from Scratch by TestTime ClassConditional Feature Alignment Vision Transformer ViT is becoming more popular in image processing.Specifically we investigate the effectiveness of testtime adaptation TTA onViT a technique that has emerged to correct its prediction during testtime byitself. First we benchmark various testtime adaptation approaches on ViTBand ViTL. It is shown that the TTA is effective on ViT and thepriorconvention sensibly selecting modulation parameters is not necessarywhen using proper loss function. Based on the observation we propose a newtesttime adaptation method called classconditional feature alignment CFAwhich minimizes both the classconditional distribution differences and thewhole distribution differences of the hidden representation between the sourceand target in an online manner. Experiments of image classification tasks oncommon corruption CIFARC CIFARC and ImageNetC and domainadaptation digits datasets and ImageNetSketch show that CFA stablyoutperforms the existing baselines on various datasets. We also verify that CFAis model agnostic by experimenting on ResNet MLPMixer and several ViTvariants ViTAugReg DeiT and BeiT. Using BeiT backbone CFA achieves .top error rate on ImageNetC outperforming the existing testtime adaptationbaseline .. This is a stateoftheart result among TTA methods that do notneed to alter training phase.,2
Certified Defenses against Adversarial Examples While neural networks have achieved high accuracy on standard imageclassification benchmarks their accuracy drops to nearly zero in the presenceof small adversarial perturbations to test inputs. Defenses based onregularization and adversarial training have been proposed but often followedby new stronger attacks that defeat these defenses. Can we somehow end thisarms race In this work we study this problem for neural networks with onehidden layer. We first propose a method based on a semidefinite relaxation thatoutputs a certificate that for a given network and test input no attack canforce the error to exceed a certain value. Second as this certificate isdifferentiable we jointly optimize it with the network parameters providingan adaptive regularizer that encourages robustness against all attacks. OnMNIST our approach produces a network and a certificate that no attack thatperturbs each pixel by at most epsilon  . can cause more than  testerror.,2
PixMix Dreamlike Pictures Comprehensively Improve Safety Measures In realworld applications of machine learning reliable and safe systemsmust consider measures of performance beyond standard test set accuracy. Theseother goals include outofdistribution OOD robustness predictionconsistency resilience to adversaries calibrated uncertainty estimates andthe ability to detect anomalous inputs. However improving performance towardsthese goals is often a balancing act that todays methods cannot achievewithout sacrificing performance on other safety axes. For instance adversarialtraining improves adversarial robustness but sharply degrades other classifierperformance metrics. Similarly strong data augmentation and regularizationtechniques often improve OOD robustness but harm anomaly detection raising thequestion of whether a Pareto improvement on all existing safety measures ispossible. To meet this challenge we design a new data augmentation strategyutilizing the natural structural complexity of pictures such as fractals whichoutperforms numerous baselines is near Paretooptimal and roundly improvessafety measures.,2
Intrinsic dimension estimation for discrete metrics Real worlddatasets characterized by discrete features are ubiquitous fromcategorical surveys to clinical questionnaires from unweighted networks to DNAsequences. Nevertheless the most common unsupervised dimensional reductionmethods are designed for continuous spaces and their use for discrete spacescan lead to errors and biases. In this letter we introduce an algorithm toinfer the intrinsic dimension ID of datasets embedded in discrete spaces. Wedemonstrate its accuracy on benchmark datasets and we apply it to analyze ametagenomic dataset for species fingerprinting finding a surprisingly smallID of order . This suggests that evolutive pressure acts on a lowdimensionalmanifold despite the highdimensionality of sequences space.,2
Adversarial Text Normalization Textbased adversarial attacks are becoming more commonplace and accessibleto general internet users. As these attacks proliferate the need to addressthe gap in model robustness becomes imminent. While retraining on adversarialdata may increase performance there remains an additional class ofcharacterlevel attacks on which these models falter. Additionally the processto retrain a model is time and resource intensive creating a need for alightweight reusable defense. In this work we propose the Adversarial TextNormalizer a novel method that restores baseline performance on attackedcontent with low computational overhead. We evaluate the efficacy of thenormalizer on two problem areas prone to adversarial attacks i.e. Hate Speechand Natural Language Inference. We find that text normalization provides ataskagnostic defense against characterlevel attacks that can be implementedsupplementary to adversarial retraining solutions which are more suited forsemantic alterations.,2
GSmooth Certified Robustness against Semantic Transformations via Generalized Randomized Smoothing Certified defenses such as randomized smoothing have shown promise towardsbuilding reliable machine learning systems against ellpnorm boundedattacks. However existing methods are insufficient or unable to provablydefend against semantic transformations especially those without closedformexpressions such as defocus blur and pixelate which are more common inpractice and often unrestricted. To fill up this gap we propose generalizedrandomized smoothing GSmooth a unified theoretical framework for certifyingrobustness against general semantic transformations via a novel dimensionaugmentation strategy. Under the GSmooth framework we present a scalablealgorithm that uses a surrogate imagetoimage network to approximate thecomplex transformation. The surrogate model provides a powerful tool forstudying the properties of semantic transformations and certifying robustness.Experimental results on several datasets demonstrate the effectiveness of ourapproach for robustness certification against multiple kinds of semantictransformations and corruptions which is not achievable by the alternativebaselines.,2
Streambased active learning with linear models The proliferation of automated data collection schemes and the advances insensorics are increasing the amount of data we are able to monitor inrealtime. However given the high annotation costs and the time required byquality inspections data is often available in an unlabeled form. This isfostering the use of active learning for the development of soft sensors andpredictive models. In production instead of performing random inspections toobtain product information labels are collected by evaluating the informationcontent of the unlabeled data. Several query strategy frameworks for regressionhave been proposed in the literature but most of the focus has been dedicatedto the static poolbased scenario. In this work we propose a new strategy forthe streambased scenario where instances are sequentially offered to thelearner which must instantaneously decide whether to perform the quality checkto obtain the label or discard the instance. The approach is inspired by theoptimal experimental design theory and the iterative aspect of thedecisionmaking process is tackled by setting a threshold on theinformativeness of the unlabeled data points. The proposed approach isevaluated using numerical simulations and the Tennessee Eastman Processsimulator. The results confirm that selecting the examples suggested by theproposed algorithm allows for a faster reduction in the prediction error.,2
Smooth Adversarial Training It is commonly believed that networks cannot be both accurate and robustthat gaining robustness means losing accuracy. It is also generally believedthat unless making networks larger network architectural elements wouldotherwise matter little in improving adversarial robustness. Here we presentevidence to challenge these common beliefs by a careful study about adversarialtraining. Our key observation is that the widelyused ReLU activation functionsignificantly weakens adversarial training due to its nonsmooth nature. Hencewe propose smooth adversarial training SAT in which we replace ReLU with itssmooth approximations to strengthen adversarial training. The purpose of smoothactivation functions in SAT is to allow it to find harder adversarial examplesand compute better gradient updates during adversarial training.,2
ImageNettrained CNNs are biased towards texture increasing shape bias improves accuracy and robustness Convolutional Neural Networks CNNs are commonly thought to recogniseobjects by learning increasingly complex representations of object shapes. Somerecent studies suggest a more important role of image textures. We here putthese conflicting hypotheses to a quantitative test by evaluating CNNs andhuman observers on images with a textureshape cue conflict. We show thatImageNettrained CNNs are strongly biased towards recognising textures ratherthan shapes which is in stark contrast to human behavioural evidence andreveals fundamentally different classification strategies. We then demonstratethat the same standard architecture ResNet that learns a texturebasedrepresentation on ImageNet is able to learn a shapebased representationinstead when trained on StylizedImageNet a stylized version of ImageNet.This provides a much better fit for human behavioural performance in ourwellcontrolled psychophysical lab setting nine experiments totalling psychophysical trials across  observers and comes with a number ofunexpected emergent benefits such as improved object detection performance andpreviously unseen robustness towards a wide range of image distortionshighlighting advantages of a shapebased representation.,2
Obfuscated Gradients Give a False Sense of Security Circumventing Defenses to Adversarial Examples We identify obfuscated gradients a kind of gradient masking as a phenomenonthat leads to a false sense of security in defenses against adversarialexamples. While defenses that cause obfuscated gradients appear to defeatiterative optimizationbased attacks we find defenses relying on this effectcan be circumvented. We describe characteristic behaviors of defensesexhibiting the effect and for each of the three types of obfuscated gradientswe discover we develop attack techniques to overcome it. In a case studyexamining noncertified whiteboxsecure defenses at ICLR  we findobfuscated gradients are a common occurrence with  of  defenses relying onobfuscated gradients. Our new attacks successfully circumvent  completely and partially in the original threat model each paper considers.,2
Gradientbased Adversarial Attacks against Text Transformers We propose the first generalpurpose gradientbased attack againsttransformer models. Instead of searching for a single adversarial example wesearch for a distribution of adversarial examples parameterized by acontinuousvalued matrix hence enabling gradientbased optimization. Weempirically demonstrate that our whitebox attack attains stateoftheartattack performance on a variety of natural language tasks. Furthermore we showthat a powerful blackbox transfer attack enabled by sampling from theadversarial distribution matches or exceeds existing methods while onlyrequiring hardlabel outputs.,2
GSCLIP  A Framework for Explaining Distribution Shifts in Natural Language Helping end users comprehend the abstract distribution shifts can greatlyfacilitate AI deployment. Motivated by this we propose a novel task datasetexplanation. Given two image data sets dataset explanation aims toautomatically point out their datasetlevel distribution shifts with naturallanguage. Current techniques for monitoring distribution shifts provideinadequate information to understand datasets with the goal of improving dataquality. Therefore we introduce GSCLIP a trainingfree framework to solve thedataset explanation task. In GSCLIP we propose the selector as the firstquantitative evaluation method to identify explanations that are proper tosummarize dataset shifts. Furthermore we leverage this selector to demonstratethe superiority of a generator based on language model generation. Systematicevaluation on natural data shift verifies that GSCLIP a combined system of ahybrid generator group and an efficient selector is not only easytouse butalso powerful for dataset explanation at scale.,2
Can Rationalization Improve Robustness A growing line of work has investigated the development of neural NLP modelsthat can produce rationalessubsets of input that can explain their modelpredictions. In this paper we ask whether such rationale models can alsoprovide robustness to adversarial attacks in addition to their interpretablenature. Since these models need to first generate rationales rationalizerbefore making predictions predictor they have the potential to ignorenoise or adversarially added text by simply masking it out of the generatedrationale. To this end we systematically generate various types of AddTextattacks for both token and sentencelevel rationalization tasks and perform anextensive empirical evaluation of stateoftheart rationale models across fivedifferent tasks. Our experiments reveal that the rationale models show thepromise to improve robustness while they struggle in certain scenarioswhenthe rationalizer is sensitive to positional bias or lexical choices of attacktext. Further leveraging human rationale as supervision does not alwaystranslate to better performance. Our study is a first step towards exploringthe interplay between interpretability and robustness in therationalizethenpredict framework.,2
Models Out of Line A Fourier Lens on Distribution Shift Robustness Improving the accuracy of deep neural networks DNNs on outofdistributionOOD data is critical to an acceptance of deep learning DL in real worldapplications. It has been observed that accuracies on indistribution IDversus OOD data follow a linear trend and models that outperform this baselineare exceptionally rare and referred to as effectively robust. Recentlysome promising approaches have been developed to improve OOD robustness modelpruning data augmentation and ensembling or zeroshot evaluating largepretrained models. However there still is no clear understanding of theconditions on OOD data and model properties that are required to observeeffective robustness. We approach this issue by conducting a comprehensiveempirical study of diverse approaches that are known to impact OOD robustnesson a broad range of natural and synthetic distribution shifts of CIFAR andImageNet. In particular we view the effective robustness puzzle through aFourier lens and ask how spectral properties of both models and OOD datainfluence the corresponding effective robustness. We find this Fourier lensoffers some insight into why certain robust models particularly those from theCLIP family achieve OOD robustness. However our analysis also makes clearthat no known metric is consistently the best explanation or even a strongexplanation of OOD robustness. Thus to aid future research into the OODpuzzle we address the gap in publiclyavailable models with effectiverobustness by introducing a set of pretrained modelsRobustNetswith varyinglevels of OOD robustness.,2
Forecasting Future World Events with Neural Networks Forecasting future world events is a challenging but valuable task. Forecastsof climate geopolitical conflict pandemics and economic indicators help shapepolicy and decision making. In these domains the judgment of expert humanscontributes to the best forecasts. Given advances in language modeling canthese forecasts be automated To this end we introduce Autocast a datasetcontaining thousands of forecasting questions and an accompanying news corpus.Questions are taken from forecasting tournaments ensuring high qualityrealworld importance and diversity. The news corpus is organized by dateallowing us to precisely simulate the conditions under which humans made pastforecasts avoiding leakage from the future. Motivated by the difficulty offorecasting numbers across orders of magnitude e.g. global cases of COVIDin  we also curate IntervalQA a dataset of numerical questions andmetrics for calibration. We test language models on our forecasting task andfind that performance is far below a human expert baseline. Howeverperformance improves with increased model size and incorporation of relevantinformation from the news corpus. In sum Autocast poses a novel challenge forlarge language models and improved performance could bring large practicalbenefits.,3
Developing Optimal Causal CyberDefence Agents via Cyber Security Simulation In this paper we explore cyber security defence through the unification of anovel cyber security simulator with models for causal decisionmaking throughoptimisation. Particular attention is paid to a recently published approachdynamic causal Bayesian optimisation DCBO. We propose that DCBO can act as ablue agent when provided with a view of a simulated network and a causal modelof how a red agent spreads within that network. To investigate how DCBO canperform optimal interventions on host nodes in order to reduce the cost ofintrusions caused by the red agent. Through this we demonstrate a completecybersimulation system which we use to generate observational data for DCBOand provide numerical quantitative results which lay the foundations for futurework in this space.,3
Asleep at the Keyboard Assessing the Security of GitHub Copilots Code Contributions There is burgeoning interest in designing AIbased systems to assist humansin designing computing systems including tools that automatically generatecomputer code. The most notable of these comes in the form of the firstselfdescribed AI pair programmer GitHub Copilot a language model trainedover opensource GitHub code. However code often contains bugs  and so giventhe vast quantity of unvetted code that Copilot has processed it is certainthat the language model will have learned from exploitable buggy code. Thisraises concerns on the security of Copilots code contributions. In this workwe systematically investigate the prevalence and conditions that can causeGitHub Copilot to recommend insecure code. To perform this analysis we promptCopilot to generate code in scenarios relevant to highrisk CWEs e.g. thosefrom MITREs Top  list. We explore Copilots performance on three distinctcode generation axes  examining how it performs given diversity ofweaknesses diversity of prompts and diversity of domains. In total weproduce  different scenarios for Copilot to complete producing programs. Of these we found approximately  to be vulnerable.,3
AnoShift A Distribution Shift Benchmark for Unsupervised Anomaly Detection Analyzing the distribution shift of data is a growing research direction innowadays Machine Learning leading to emerging new benchmarks that focus onproviding a suitable scenario for studying the generalization properties of MLmodels. The existing benchmarks are focused on supervised learning and to thebest of our knowledge there is none for unsupervised learning. Therefore weintroduce an unsupervised anomaly detection benchmark with data that shiftsover time built over Kyoto a traffic dataset for network intrusiondetection. This kind of data meets the premise of shifting the inputdistribution it covers a large time span  years with naturallyoccurring changes over time eg users modifying their behavior patterns andsoftware updates. We first highlight the nonstationary nature of the datausing a basic perfeature analysis tSNE and an Optimal Transport approachfor measuring the overall distribution distances between years. Next wepropose AnoShift a protocol splitting the data in IID NEAR and FAR testingsplits. We validate the performance degradation over time with diverse modelsMLM to classical Isolation Forest. Finally we show that by acknowledging thedistribution shift problem and properly addressing it the performance can beimproved compared to the classical IID training by up to  on average.Dataset and code are available at,3
AnomalE A SelfSupervised Network Intrusion Detection System based on Graph Neural Networks This paper investigates Graph Neural Networks GNNs application forselfsupervised network intrusion and anomaly detection. GNNs are a deeplearning approach for graphbased data that incorporate graph structures intolearning to generalise graph representations and output embeddings. As networkflows are naturally graphbased GNNs are a suitable fit for analysing andlearning network behaviour. The majority of current implementations ofGNNbased Network Intrusion Detection Systems NIDSs rely heavily on labellednetwork traffic which can not only restrict the amount and structure of inputtraffic but also the NIDSs potential to adapt to unseen attacks. To overcomethese restrictions we present AnomalE a GNN approach to intrusion andanomaly detection that leverages edge features and graph topological structurein a selfsupervised process. This approach is to the best our knowledge thefirst successful and practical approach to network intrusion detection thatutilises network flows in a selfsupervised edge leveraging GNN. Experimentalresults on two modern benchmark NIDS datasets not only clearly display theimprovement of using AnomalE embeddings rather than raw features but also thepotential AnomalE has for detection on wild network traffic.,3
Forecasting Future World Events with Neural Networks Forecasting future world events is a challenging but valuable task. Forecastsof climate geopolitical conflict pandemics and economic indicators help shapepolicy and decision making. In these domains the judgment of expert humanscontributes to the best forecasts. Given advances in language modeling canthese forecasts be automated To this end we introduce Autocast a datasetcontaining thousands of forecasting questions and an accompanying news corpus.Questions are taken from forecasting tournaments ensuring high qualityrealworld importance and diversity. The news corpus is organized by dateallowing us to precisely simulate the conditions under which humans made pastforecasts avoiding leakage from the future. Motivated by the difficulty offorecasting numbers across orders of magnitude e.g. global cases of COVIDin  we also curate IntervalQA a dataset of numerical questions andmetrics for calibration. We test language models on our forecasting task andfind that performance is far below a human expert baseline. Howeverperformance improves with increased model size and incorporation of relevantinformation from the news corpus. In sum Autocast poses a novel challenge forlarge language models and improved performance could bring large practicalbenefits.,3
Robustness Evaluation of Deep Unsupervised Learning Algorithms for Intrusion Detection Systems Recently advances in deep learning have been observed in various fieldsincluding computer vision natural language processing and cybersecurity.Machine learning ML has demonstrated its ability as a potential tool foranomaly detectionbased intrusion detection systems to build secure computernetworks. Increasingly ML approaches are widely adopted than heuristicapproaches for cybersecurity because they learn directly from data. Data iscritical for the development of ML systems and becomes potential targets forattackers. Basically data poisoning or contamination is one of the most commontechniques used to fool ML models through data. This paper evaluates therobustness of six recent deep learning algorithms for intrusion detection oncontaminated data. Our experiments suggest that the stateoftheart algorithmsused in this study are sensitive to data contamination and reveal theimportance of selfdefense against data perturbation when developing novelmodels especially for intrusion detection systems.,3
On Single Point Forecasts for FatTailed Variables We discuss common errors and fallacies when using naive evidence basedempiricism and point forecasts for fattailed variables as well as theinsufficiency of using naive firstorder scientific methods for tail riskmanagement. We use the COVID pandemic as the background for the discussionand as an example of a phenomenon characterized by a multiplicative nature andwhat mitigating policies must result from the statistical properties andassociated risks. In doing so we also respond to the points raised byIoannidis et al. .,3
Open Problems in Cooperative AI Problems of cooperationin which agents seek ways to jointly improve theirwelfareare ubiquitous and important. They can be found at scales ranging fromour daily routinessuch as driving on highways scheduling meetings andworking collaborativelyto our global challengessuch as peace commerce andpandemic preparedness. Arguably the success of the human species is rooted inour ability to cooperate. Since machines powered by artificial intelligence areplaying an ever greater role in our lives it will be important to equip themwith the capabilities necessary to cooperate and to foster cooperation.,3
Bayesian Recurrent Units and the ForwardBackward Algorithm Using Bayess theorem we derive a unitwise recurrence as well as a backwardrecursion similar to the forwardbackward algorithm. The resulting Bayesianrecurrent units can be integrated as recurrent neural networks within deeplearning frameworks while retaining a probabilistic interpretation from thedirect correspondence with hidden Markov models. Whilst the contribution ismainly theoretical experiments on speech recognition indicate that adding thederived units at the end of stateoftheart recurrent architectures canimprove the performance at a very low cost in terms of trainable parameters.,4
Better Methods and Theory for Federated Learning Compression Client Selection and Heterogeneity Federated learning FL is an emerging machine learning paradigm involvingmultiple clients e.g. mobile phone devices with an incentive to collaboratein solving a machine learning problem coordinated by a central server. FL wasproposed in  by Konen et al. and McMahan et al. as a viableprivacypreserving alternative to traditional centralized machine learningsince by construction the training data points are decentralized and nevertransferred by the clients to a central server. Therefore to a certain degreeFL mitigates the privacy risks associated with centralized data collection.,4
Switching OneVersustheRest Loss to Increase the Margin of Logits for Adversarial Robustness Defending deep neural networks against adversarial examples is a keychallenge for AI safety. To improve the robustness effectively recent methodsfocus on important data points near the decision boundary in adversarialtraining. However these methods are vulnerable to AutoAttack which is anensemble of parameterfree attacks for reliable evaluation. In this paper weexperimentally investigate the causes of their vulnerability and find thatexisting methods reduce margins between logits for the true label and the otherlabels while keeping their gradient norms nonsmall values. Reduced margins andnonsmall gradient norms cause their vulnerability since the largest logit canbe easily flipped by the perturbation. Our experiments also show that thehistogram of the logit margins has two peaks i.e. small and large logitmargins. From the observations we propose switching oneversustherest lossSOVR which uses oneversustherest loss when data have small logit marginsso that it increases the margins. We find that SOVR increases logit marginsmore than existing methods while keeping gradient norms small and outperformsthem in terms of the robustness against AutoAttack.,4
Continuoustime Analysis for Variational Inequalities An Overview and Desiderata Algorithms that solve zerosum games multiobjective agent objectives ormore generally variational inequality VI problems are notoriously unstableon general problems. Owing to the increasing need for solving such problems inmachine learning this instability has been highlighted in recent years as asignificant research challenge. In this paper we provide an overview of recentprogress in the use of continuoustime perspectives in the analysis and designof methods targeting the broad VI problem class. Our presentation drawsparallels between singleobjective problems and multiobjective problemshighlighting the challenges of the latter. We also formulate various desideratafor algorithms that apply to general VIs and we argue that achieving thesedesiderata may profit from an understanding of the associated continuoustimedynamics.,4
Neural Posterior Estimation with Differentiable Simulators SimulationBased Inference SBI is a promising Bayesian inference frameworkthat alleviates the need for analytic likelihoods to estimate posteriordistributions. Recent advances using neural density estimators in SBIalgorithms have demonstrated the ability to achieve highfidelity posteriorsat the expense of a large number of simulations  which makes their applicationpotentially very timeconsuming when using complex physical simulations. Inthis work we focus on boosting the sampleefficiency of posterior densityestimation using the gradients of the simulator. We present a new method toperform Neural Posterior Estimation NPE with a differentiable simulator. Wedemonstrate how gradient information helps constrain the shape of the posteriorand improves sampleefficiency.,4
Stochastic Functional Analysis and Multilevel Vector Field Anomaly Detection Massive vector field datasets are common in multispectral optical and radarsensors and modern multimodal MRI data among many other areas of application.In this paper we develop a novel stochastic functional analysis approach fordetecting anomalies based on the covariance structure of nominal stochasticbehavior across a domain with multiband vector field data. An optimal vectorfield KarhunenLoeve KL expansion is applied to such random field data. Aseries of multilevel orthogonal functional subspaces is constructed from thegeometry of the domain adapted from the KL expansion. Detection is achieved byexamining the projection of the random field on the multilevel basis. Theanomalies can be quantified in suitable normed spaces based on local and globalinformation. In addition reliable hypothesis tests are formed withcontrollable distributions that do not require prior assumptions on probabilitydistributions of the data. Only the covariance function is needed which makesfor significantly simpler estimates. Furthermore this approach allowsstochastic vectorbased fusion of anomalies without any loss of information.The method is applied to the important problem of deforestation and degradationin the Amazon forest. This is a complex nonmonotonic process as forests candegrade and recover. This particular problem is further compounded by thepresence of clouds that are hard to remove with current masking algorithms.Using multispectral satellite data from Sentinel  the multilevel filter isconstructed and anomalies are treated as deviations from the initial state ofthe forest. Forest anomalies are quantified with robust hypothesis tests anddistinguished from false variations such as cloud cover. Our approach shows theadvantage of using multiple bands of data in a vectorized complex leading tobetter anomaly detection beyond the capabilities of scalarbased methods.,4
A Certifiable Security Patch for Object Tracking in SelfDriving Systems via Historical Deviation Modeling Selfdriving cars SDC commonly implement the perception pipeline to detectthe surrounding obstacles and track their moving trajectories which lays theground for the subsequent driving decision making process. Although thesecurity of obstacle detection in SDC is intensively studied not until veryrecently the attackers start to exploit the vulnerability of the trackingmodule. Compared with solely attacking the object detectors this new attackstrategy influences the driving decision more effectively with less attackbudgets. However little is known on whether the revealed vulnerability remainseffective in endtoend selfdriving systems and if so how to mitigate thethreat.,4
Jackknife Variability Estimation For Randomized Matrix Computations Randomized algorithms based on sketching have become a workhorse tool inlowrank matrix approximation. To use these algorithms safely in applicationsthey should be coupled with diagnostics to assess the quality of approximation.To meet this need this paper proposes a jackknife resampling method toestimate the variability of the output of a randomized matrix computation. Thevariability estimate can recognize that a computation requires additional dataor that the computation is intrinsically unstable. As examples the paperstudies jackknife estimates for two randomized lowrank matrix approximationalgorithms. In each case the operation count for the jackknife estimate isindependent of the dimensions of the target matrix. In numerical experimentsthe estimator accurately assesses variability and also provides anorderofmagnitude estimate of the meansquare error.,4
DeeplyLearned Generalized Linear Models with Missing Data Deep Learning DL methods have dramatically increased in popularity inrecent years with significant growth in their application to supervisedlearning problems in the biomedical sciences. However the greater prevalenceand complexity of missing data in modern biomedical datasets presentsignificant challenges for DL methods. Here we provide a formal treatment ofmissing data in the context of deeply learned generalized linear models asupervised DL architecture for regression and classification problems. Wepropose a new architecture textitdlglm that is one of the first to be ableto flexibly account for both ignorable and nonignorable patterns ofmissingness in input features and response at training time. We demonstratethrough statistical simulation that our method outperforms existing approachesfor supervised learning tasks in the presence of missing not at random MNARmissingness. We conclude with a case study of a Bank Marketing dataset from theUCI Machine Learning Repository in which we predict whether clients subscribedto a product based on phone survey data.,4
Information Processing Equalities and the InformationRisk Bridge We introduce two new classes of measures of information for statisticalexperiments which generalise and subsume phidivergences integralprobability metrics mathfrakNdistances MMD and fGammadivergences between two or more distributions. This enables us to derive asimple geometrical relationship between measures of information and the Bayesrisk of a statistical decision problem thus extending the variationalphidivergence representation to multiple distributions in an entirelysymmetric manner. The new families of divergence are closed under the action ofMarkov operators which yields an information processing equality which is arefinement and generalisation of the classical data processing inequality. Thisequality gives insight into the significance of the choice of the hypothesisclass in classical risk minimization.,4
Benign Tempered or Catastrophic A Taxonomy of Overfitting The practical success of overparameterized neural networks has motivated therecent scientific study of interpolating methods which perfectly fit theirtraining data. Certain interpolating methods including neural networks canfit noisy training data without catastrophically bad test performance indefiance of standard intuitions from statistical learning theory. Aiming toexplain this a body of recent work has studied textitbenign overfittinga phenomenon where some interpolating methods approach Bayes optimality evenin the presence of noise. In this work we argue that while benign overfittinghas been instructive and fruitful to study many real interpolating methodslike neural networks textitdo not fit benignly modest noise in thetraining set causes nonzero but noninfinite excess risk at test timeimplying these models are neither benign nor catastrophic but rather fall in anintermediate regime. We call this intermediate regime textittemperedoverfitting and we initiate its systematic study. We first explore thisphenomenon in the context of kernel ridge regression KR by obtainingconditions on the ridge parameter and kernel eigenspectrum under which KRexhibits each of the three behaviors. We find that kernels with powerlawspectra including Laplace kernels and ReLU neural tangent kernels exhibittempered overfitting. We then empirically study deep neural networks throughthe lens of our taxonomy and find that those trained to interpolation aretempered while those stopped early are benign. We hope our work leads to amore refined understanding of overfitting in modern learning.,4
Blessing of Nonconvexity in Deep Linear Models Depth Flattens the Optimization Landscape Around the True Solution This work characterizes the effect of depth on the optimization landscape oflinear regression showing that despite their nonconvexity deeper models havemore desirable optimization landscape. We consider a robust andoverparameterized setting where a subset of measurements are grosslycorrupted with noise and the true linear model is captured via an Nlayerlinear neural network. On the negative side we show that this problemtextitdoes not have a benign landscape given any Ngeq  with constantprobability there exists a solution corresponding to the ground truth that isneither local nor global minimum. However on the positive side we prove thatfor any Nlayer model with Ngeq  a simple subgradient method becomesoblivious to such problematic solutions instead it converges to abalanced solution that is not only close to the ground truth but also enjoys aflat local landscape thereby eschewing the need for early stopping. Lastlywe empirically verify that the desirable optimization landscape of deepermodels extends to other robust learning tasks including deep matrix recoveryand deep ReLU networks with ellloss.,4
Causal Fairness Analysis Decisionmaking systems based on AI and machine learning have been usedthroughout a wide range of realworld scenarios including healthcare lawenforcement education and finance. It is no longer farfetched to envision afuture where autonomous systems will be driving entire business decisions andmore broadly supporting largescale decisionmaking infrastructure to solvesocietys most challenging problems. Issues of unfairness and discriminationare pervasive when decisions are being made by humans and remain or arepotentially amplified when decisions are made using machines with littletransparency accountability and fairness. In this paper we introduce aframework for textitcausal fairness analysis with the intent of filling inthis gap i.e. understanding modeling and possibly solving issues offairness in decisionmaking settings. The main insight of our approach will beto link the quantification of the disparities present on the observed data withthe underlying and often unobserved collection of causal mechanisms thatgenerate the disparity in the first place challenge we call the FundamentalProblem of Causal Fairness Analysis FPCFA. In order to solve the FPCFA westudy the problem of decomposing variations and empirical measures of fairnessthat attribute such variations to structural mechanisms and different units ofthe population. Our effort culminates in the Fairness Map which is the firstsystematic attempt to organize and explain the relationship between differentcriteria found in the literature. Finally we study which causal assumptionsare minimally needed for performing causal fairness analysis and propose aFairness Cookbook which allows data scientists to assess the existence ofdisparate impact and disparate treatment.,4
Neural Stein critics with staged Lregularization Learning to differentiate model distributions from observed data is afundamental problem in statistics and machine learning and highdimensionaldata remains a challenging setting for such problems. Metrics that quantify thedisparity in probability distributions such as the Stein discrepancy play animportant role in statistical testing in high dimensions. In this paper weconsider the setting where one wishes to distinguish between data sampled froman unknown probability distribution and a nominal model distribution. Whilerecent studies revealed that the optimal Lregularized Stein critic equalsthe difference of the score functions of two probability distributions up to amultiplicative constant we investigate the role of L regularization whentraining a neural network Stein discrepancy critic function. Motivated by theNeural Tangent Kernel theory of training neural networks we develop a novelstaging procedure for the weight of regularization over training time. Thisleverages the advantages of highlyregularized training at early times whilealso empirically delaying overfitting. Theoretically we relate the trainingdynamic with large regularization weight to the kernel regression optimizationof lazy training regime in early training times. The benefit of the stagedL regularization is demonstrated on simulated high dimensional distributiondrift data and an application to evaluating generative models of image data.,4
Comparing Feature Importance and Rule Extraction for Interpretability on Text Data Complex machine learning algorithms are used more and more often in criticaltasks involving text data leading to the development of interpretabilitymethods. Among local methods two families have emerged those computingimportance scores for each feature and those extracting simple logical rules.In this paper we show that using different methods can lead to unexpectedlydifferent explanations even when applied to simple models for which we wouldexpect qualitative coincidence. To quantify this effect we propose a newapproach to compare explanations produced by different methods.,4
A clinically motivated selfsupervised approach for contentbased image retrieval of CT liver images Deep learningbased approaches for contentbased image retrieval CBIR of CTliver images is an active field of research but suffers from some criticallimitations. First they are heavily reliant on labeled data which can bechallenging and costly to acquire. Second they lack transparency andexplainability which limits the trustworthiness of deep CBIR systems. Weaddress these limitations by  proposing a selfsupervised learning frameworkthat incorporates domainknowledge into the training procedure and providing the first representation learning explainability analysis in thecontext of CBIR of CT liver images. Results demonstrate improved performancecompared to the standard selfsupervised approach across several metrics aswell as improved generalisation across datasets. Further we conduct the firstrepresentation learning explainability analysis in the context of CBIR whichreveals new insights into the feature extraction process. Lastly we perform acase study with crossexamination CBIR that demonstrates the usability of ourproposed framework. We believe that our proposed framework could play a vitalrole in creating trustworthy deep CBIR systems that can successfully takeadvantage of unlabeled data.,4
Alternating minimization for generalized rank one matrix sensing Sharp predictions from a random initialization We consider the problem of estimating the factors of a rank matrix withi.i.d. Gaussian rank measurements that are nonlinearly transformed andcorrupted by noise. Considering two prototypical choices for the nonlinearitywe study the convergence properties of a natural alternating update rule forthis nonconvex optimization problem starting from a random initialization. Weshow sharp convergence guarantees for a samplesplit version of the algorithmby deriving a deterministic recursion that is accurate even in highdimensionalproblems. Notably while the infinitesample population update is uninformativeand suggests exact recovery in a single step the algorithm  and ourdeterministic prediction  converges geometrically fast from a randominitialization. Our sharp nonasymptotic analysis also exposes several otherfinegrained properties of this problem including how the nonlinearity andnoise level affect convergence behavior.,4
PRoA A Probabilistic Robustness Assessment against Functional Perturbations In safetycritical deep learning applications robustness measurement is avital predeployment phase. However existing robustness verification methodsare not sufficiently practical for deploying machine learning systems in thereal world. On the one hand these methods attempt to claim that noperturbations can fool deep neural networks DNNs which may be toostringent in practice. On the other hand existing works rigorously considerLp bounded additive perturbations on the pixel space althoughperturbations such as colour shifting and geometric transformations are morepractically and frequently occurring in the real world. Thus from thepractical standpoint we present a novel and general it probabilisticrobustness assessment method PRoA based on the adaptive concentration andit can measure the robustness of deep learning models against functionalperturbations. PRoA can provide statistical guarantees on the probabilisticrobustness of a model textiti.e. the probability of failure encountered bythe trained model after deployment. Our experiments demonstrate theeffectiveness and flexibility of PRoA in terms of evaluating the probabilisticrobustness against a broad range of functional perturbations and PRoA canscale well to various largescale deep neural networks compared to existingstateoftheart baselines. For the purpose of reproducibility we release ourtool on GitHub url,4
BiTAT Neural Network Binarization with Taskdependent Aggregated Transformation Neural network quantization aims to transform highprecision weights andactivations of a given neural network into lowprecision weightsactivationsfor reduced memory usage and computation while preserving the performance ofthe original model. However extreme quantization bit weightbitactivations of compactlydesigned backbone architectures e.g. MobileNetsoften used for edgedevice deployments results in severe performancedegeneration. This paper proposes a novel QuantizationAware Training QATmethod that can effectively alleviate performance degeneration even withextreme quantization by focusing on the interweight dependencies between theweights within each layer and across consecutive layers. To minimize thequantization impact of each weight on others we perform an orthonormaltransformation of the weights at each layer by training an inputdependentcorrelation matrix and importance vector such that each weight is disentangledfrom the others. Then we quantize the weights based on their importance tominimize the loss of the information from the original weightsactivations. Wefurther perform progressive layerwise quantization from the bottom layer tothe top so that quantization at each layer reflects the quantizeddistributions of weights and activations at previous layers. We validate theeffectiveness of our method on various benchmark datasets against strong neuralquantization baselines demonstrating that it alleviates the performancedegeneration on ImageNet and successfully preserves the fullprecision modelperformance on CIFAR with compact backbone networks.,4
Exploration in Linear Bandits with Rich Action Sets and its Implications for Inference We present a nonasymptotic lower bound on the eigenspectrum of the designmatrix generated by any linear bandit algorithm with sublinear regret when theaction set has wellbehaved curvature. Specifically we show that the minimumeigenvalue of the expected design matrix grows as Omegasqrtn wheneverthe expected cumulative regret of the algorithm is Osqrtn where n isthe learning horizon and the actionspace has a constant Hessian around theoptimal arm. This shows that such actionspaces force a polynomial lower boundrather than a logarithmic lower bound as shown by citelattimoreend indiscrete i.e. wellseparated action spaces. Furthermore while the previousresult is shown to hold only in the asymptotic regime as n to infty ourresult for these locally rich action spaces is anytime. Additionally undera mild technical assumption we obtain a similar lower bound on the minimumeigen value holding with high probability.,4
Single Model Uncertainty Estimation via Stochastic Data Centering We are interested in estimating the uncertainties of deep neural networkswhich play an important role in many scientific and engineering problems. Inthis paper we present a striking new finding that an ensemble of neuralnetworks with the same weight initialization trained on datasets that areshifted by a constant bias gives rise to slightly inconsistent trained modelswhere the differences in predictions are a strong indicator of epistemicuncertainties. Using the neural tangent kernel NTK we demonstrate that thisphenomena occurs in part because the NTK is not shiftinvariant. Since this isachieved via a trivial input transformation we show that it can therefore beapproximated using just a single neural network  using a technique that wecall DeltaUQ  that estimates uncertainty around prediction bymarginalizing out the effect of the biases. We show that DeltaUQsuncertainty estimates are superior to many of the current methods on a varietyof benchmarks  outlier rejection calibration under distribution shift andsequential design optimization of black box functions.,4
A Supervised Tensor Dimension ReductionBased Prognostics Model for Applications with Incomplete Imaging Data This paper proposes a supervised dimension reduction methodology for tensordata which has two advantages over most imagebased prognostic models. Firstthe model does not require tensor data to be complete which expands itsapplication to incomplete data. Second it utilizes timetofailure TTF tosupervise the extraction of lowdimensional features which makes the extractedfeatures more effective for the subsequent prognostic. Besides an optimizationalgorithm is proposed for parameter estimation and closedform solutions arederived under certain distributions.,4
Graph Neural Network Bandits We consider the bandit optimization problem with the reward function definedover graphstructured data.,4
On uniformintime diffusion approximation for stochastic gradient descent The diffusion approximation of stochastic gradient descent SGD in currentliterature is only valid on a finite time interval. In this paper we establishthe uniformintime diffusion approximation of SGD by only assuming that theexpected loss is strongly convex and some other mild conditions withoutassuming the convexity of each random loss function. The main technique is toestablish the exponential decay rates of the derivatives of the solution to thebackward Kolmogorov equation. The uniformintime approximation allows us tostudy asymptotic behaviors of SGD via the continuous stochastic differentialequation SDE even when the random objective function fcdotxi is notstrongly convex.,4
Breaking Feedback Loops in Recommender Systems with Causal Inference Recommender systems play a key role in shaping modern web ecosystems. Thesesystems alternate between  making recommendations  collecting userresponses to these recommendations and  retraining the recommendationalgorithm based on this feedback. During this process the recommender systeminfluences the user behavioral data that is subsequently used to update itthus creating a feedback loop. Recent work has shown that feedback loops maycompromise recommendation quality and homogenize user behavior raising ethicaland performance concerns when deploying recommender systems. To address theseissues we propose the Causal Adjustment for Feedback Loops CAFL analgorithm that provably breaks feedback loops using causal inference and can beapplied to any recommendation algorithm that optimizes a training loss. Ourmain observation is that a recommender system does not suffer from feedbackloops if it reasons about causal quantities namely the interventiondistributions of recommendations on user ratings. Moreover we can calculatethis intervention distribution from observational data by adjusting for therecommender systems predictions of user preferences. Using simulatedenvironments we demonstrate that CAFL improves recommendation quality whencompared to prior correction methods.,4
Quantum Advantage in Variational Bayes Inference Variational Bayes VB inference algorithm is used widely to estimate boththe parameters and the unobserved hidden variables in generative statisticalmodels. The algorithm  inspired by variational methods used in computationalphysics  is iterative and can get easily stuck in local minima even whenclassical techniques such as deterministic annealing DA are used. We studya variational Bayes VB inference algorithm based on a nontraditional quantumannealing approach  referred to as quantum annealing variational Bayes QAVBinference  and show that there is indeed a quantum advantage to QAVB over itsclassical counterparts. In particular we show that such better performance isrooted in key concepts from quantum mechanics i the ground state of theHamiltonian of a quantum system  defined from the given variational BayesVB problem  corresponds to an optimal solution for the minimization problemof the variational free energy at very low temperatures ii such a groundstate can be achieved by a technique paralleling the quantum annealing processand iii starting from this ground state the optimal solution to the VBproblem can be achieved by increasing the heat bath temperature to unity andthereby avoiding local minima introduced by spontaneous symmetry breakingobserved in classical physics based VB algorithms. We also show that the updateequations of QAVB can be potentially implemented using lceil log K rceilqubits and mathcalO K operations per step. Thus QAVB can match the timecomplexity of existing VB algorithms while delivering higher performance.,4
Generalized Identifiability Bounds for Mixture Models with Grouped Samples Recent work has shown that finite mixture models with m components areidentifiable while making no assumptions on the mixture components so long asone has access to groups of samples of size m which are known to come fromthe same mixture component. In this work we generalize that result and showthat if every subset of k mixture components of a mixture model are linearlyindependent then that mixture model is identifiable with only mksamples per group. We further show that this value cannot be improved. We provean analogous result for a stronger form of identifiability known asdeterminedness along with a corresponding lower bound. This independenceassumption almost surely holds if mixture components are chosen randomly from akdimensional space. We describe some implications of our results formultinomial mixture models and topic modeling.,4
Efficient One Sided Kolmogorov Approximation We present an efficient algorithm that given a discrete random variable Xand a number m computes a random variable whose support is of size at mostm and whose Kolmogorov distance from X is minimal also for the onesidedKolmogorov approximation. We present some variants of the algorithm analysetheir correctness and computational complexity and present a detailedempirical evaluation that shows how they performs in practice. The mainapplication that we examine which is our motivation for this work isestimation of the probability missing deadlines in seriesparallel schedules.Since exact computation of these probabilities is NPhard we propose to usethe algorithms described in this paper to obtain an approximation.,4
The Mean Dimension of Neural Networks  What causes the interaction effects Owen and Hoyt recently showed that the effective dimension offers keystructural information about the inputoutput mapping underlying an artificialneural network. Along this line of research this work proposes an estimationprocedure that allows the calculation of the mean dimension from a givendataset without resampling from external distributions. The design yieldstotal indices when features are independent and a variant of total indices whenfeatures are correlated. We show that this variant possesses the zeroindependence property. With synthetic datasets we analyse how the meandimension evolves layer by layer and how the activation function impacts themagnitude of interactions. We then use the mean dimension to study some of themost widely employed convolutional architectures for image recognition LeNetResNet DenseNet. To account for pixel correlations we propose calculatingthe mean dimension after the addition of an inverse PCA layer that allows oneto work on uncorrelated PCAtransformed features without the need to retrainthe neural network. We use the generalized total indices to produce heatmapsfor posthoc explanations and we employ the mean dimension on thePCAtransformed features for cross comparisons of the artificial neuralnetworks structures. Results provide several insights on the difference inmagnitude of interactions across the architectures as well as indications onhow the mean dimension evolves during training.,4
Nonparametric regression with modified ReLU networks We consider regression estimation with modified ReLU neural networks in whichnetwork weight matrices are first modified by a function alpha before beingmultiplied by input vectors. We give an example of continuous piecewise linearfunction alpha for which the empirical risk minimizers over the classes ofmodified ReLU networks with l and squared l penalties attain up to alogarithmic factor the minimax rate of prediction of unknown betasmoothfunction.,4
Uncertainty quantification for predictions of atomistic neural networks The value of uncertainty quantification on predictions for trained neuralnetworks NNs on quantum chemical reference data is quantitatively explored.For this the architecture of the PhysNet NN was suitably modified and theresulting model was evaluated with different metrics to quantify calibrationquality of predictions and whether prediction error and the predicteduncertainty can be correlated. The results from training on the QM databaseand evaluating data from the test set within and outside the distributionindicate that error and uncertainty are not linearly related. The resultsclarify that noise and redundancy complicate property prediction for moleculeseven in cases for which changes  e.g. double bond migration in two otherwiseidentical molecules  are small. The model was then applied to a real databaseof tautomerization reactions. Analysis of the distance between members infeature space combined with other parameters shows that redundant informationin the training dataset can lead to large variances and small errors whereasthe presence of similar but unspecific information returns large errors butsmall variances. This was e.g. observed for nitrocontaining aliphatic chainsfor which predictions were difficult although the training set containedseveral examples for nitro groups bound to aromatic molecules. This underlinesthe importance of the composition of the training data and provides chemicalinsight into how this affects the prediction capabilities of a ML model.Finally the approach put forward can be used for informationbased improvementof chemical databases for target applications through active learningoptimization.,4
Inference of Regulatory Networks Through Temporally Sparse Data A major goal in genomics is to properly capture the complex dynamicalbehaviors of gene regulatory networks GRNs. This includes inferring thecomplex interactions between genes which can be used for a wide range ofgenomics analyses including diagnosis or prognosis of diseases and findingeffective treatments for chronic diseases such as cancer. Boolean networks haveemerged as a successful class of models for capturing the behavior of GRNs. Inmost practical settings inference of GRNs should be achieved through limitedand temporally sparse genomics data. A large number of genes in GRNs leads to alarge possible topology candidate space which often cannot be exhaustivelysearched due to the limitation in computational resources. This paper developsa scalable and efficient topology inference for GRNs using Bayesianoptimization and kernelbased methods. Rather than an exhaustive search overpossible topologies the proposed method constructs a Gaussian Process GPwith a topologyinspired kernel function to account for correlation in thelikelihood function. Then using the posterior distribution of the GP modelthe Bayesian optimization efficiently searches for the topology with thehighest likelihood value by optimally balancing between exploration andexploitation. The performance of the proposed method is demonstrated throughcomprehensive numerical experiments using a wellknown mammalian cellcyclenetwork.,4
Deep Hedging Continuous Reinforcement Learning for Hedging of General Portfolios across Multiple Risk Aversions We present a method for finding optimal hedging policies for arbitraryinitial portfolios and market states. We develop a novel actorcritic algorithmfor solving general riskaverse stochastic control problems and use it to learnhedging strategies across multiple risk aversion levels simultaneously. Wedemonstrate the effectiveness of the approach with a numerical example in astochastic volatility environment.,4
AGBoost Attentionbased Modification of Gradient Boosting Machine A new attentionbased model for the gradient boosting machine GBM calledAGBoost the attentionbased gradient boosting is proposed for solvingregression problems. The main idea behind the proposed AGBoost model is toassign attention weights with trainable parameters to iterations of GBM undercondition that decision trees are base learners in GBM. Attention weights aredetermined by applying properties of decision trees and by using the Huberscontamination model which provides an interesting linear dependence betweentrainable parameters of the attention and the attention weights. Thispeculiarity allows us to train the attention weights by solving the standardquadratic optimization problem with linear constraints. The attention weightsalso depend on the discount factor as a tuning parameter which determines howmuch the impact of the weight is decreased with the number of iterations.Numerical experiments performed for two types of base learners originaldecision trees and extremely randomized trees with various regression datasetsillustrate the proposed model.,4
Optimal precision for GANs When learning disconnected distributions Generative adversarial networksGANs are known to face model misspecification. Indeed a continuous mappingfrom a unimodal latent distribution to a disconnected one is impossible soGANs necessarily generate samples outside of the support of the targetdistribution. This raises a fundamental question what is the latent spacepartition that minimizes the measure of these areas Building on a recentresult of geometric measure theory we prove that an optimal GANs muststructure its latent space as a simplicial cluster  a Voronoi partitionwhere cells are convex cones  when the dimension of the latent space is largerthan the number of modes. In this configuration each Voronoi cell maps to adistinct mode of the data. We derive both an upper and a lower bound on theoptimal precision of GANs learning disconnected manifolds. Interestingly thesetwo bounds have the same order of decrease sqrtlog m m being thenumber of modes. Finally we perform several experiments to exhibit thegeometry of the latent space and experimentally show that GANs have a geometrywith similar properties to the theoretical one.,4
The derivatives of SinkhornKnopp converge We show that the derivatives of the SinkhornKnopp algorithm or iterativeproportional fitting procedure converge towards the derivatives of theentropic regularization of the optimal transport problem with a locally uniformlinear convergence rate.,4
Offthegrid learning of sparse mixtures from a continuous dictionary We consider a general nonlinear model where the signal is a finite mixtureof an unknown possibly increasing number of features issued from a continuousdictionary parameterized by a real nonlinear parameter. The signal is observedwith Gaussian possibly correlated noise in either a continuous or a discretesetup. We propose an offthegrid optimization method that is a method whichdoes not use any discretization scheme on the parameter space to estimate boththe nonlinear parameters of the features and the linear parameters of themixture. We use recent results on the geometry of offthegrid methods to giveminimal separation on the true underlying nonlinear parameters such thatinterpolating certificate functions can be constructed. Using also tail boundsfor suprema of Gaussian processes we bound the prediction error with highprobability. Assuming that the certificate functions can be constructed ourprediction error bound is up to log factors similar to the rates attained bythe Lasso predictor in the linear regression model. We also establishconvergence rates that quantify with high probability the quality of estimationfor both the linear and the nonlinear parameters.,4
Intrinsic dimension estimation for discrete metrics Real worlddatasets characterized by discrete features are ubiquitous fromcategorical surveys to clinical questionnaires from unweighted networks to DNAsequences. Nevertheless the most common unsupervised dimensional reductionmethods are designed for continuous spaces and their use for discrete spacescan lead to errors and biases. In this letter we introduce an algorithm toinfer the intrinsic dimension ID of datasets embedded in discrete spaces. Wedemonstrate its accuracy on benchmark datasets and we apply it to analyze ametagenomic dataset for species fingerprinting finding a surprisingly smallID of order . This suggests that evolutive pressure acts on a lowdimensionalmanifold despite the highdimensionality of sequences space.,4
SlicedWasserstein normalizing flows beyond maximum likelihood training Despite their advantages normalizing flows generally suffer from severalshortcomings including their tendency to generate unrealistic data e.g.images and their failing to detect outofdistribution data. One reason forthese deficiencies lies in the training strategy which traditionally exploits amaximum likelihood principle only. This paper proposes a new training paradigmbased on a hybrid objective function combining the maximum likelihood principleMLE and a slicedWasserstein distance. Results obtained on synthetic toyexamples and real image data sets show better generative abilities in terms ofboth likelihood and visual aspects of the generated samples. Reciprocally theproposed approach leads to a lower likelihood of outofdistribution datademonstrating a greater data fidelity of the resulting flows.,4
A New Index for Clustering Evaluation Based on Density Estimation A new index for internal evaluation of clustering is introduced. The index isdefined as a mixture of two subindices. The first subindex  Ia  is calledthe Ambiguous Index the second subindex  Is  is called the SimilarityIndex. Calculation of the two subindices is based on density estimation toeach cluster of a partition of the data. An experiment is conducted to test theperformance of the new index and compared with three popular internalclustering evaluation indices  CalinskiHarabasz index Silhouettecoefficient and DaviesBouldin index on a set of  datasets. The resultshows the new index improves the three popular indices by   and correspondingly.,4
Jackknife Variability Estimation For Randomized Matrix Computations Randomized algorithms based on sketching have become a workhorse tool inlowrank matrix approximation. To use these algorithms safely in applicationsthey should be coupled with diagnostics to assess the quality of approximation.To meet this need this paper proposes a jackknife resampling method toestimate the variability of the output of a randomized matrix computation. Thevariability estimate can recognize that a computation requires additional dataor that the computation is intrinsically unstable. As examples the paperstudies jackknife estimates for two randomized lowrank matrix approximationalgorithms. In each case the operation count for the jackknife estimate isindependent of the dimensions of the target matrix. In numerical experimentsthe estimator accurately assesses variability and also provides anorderofmagnitude estimate of the meansquare error.,4
Estimation of NonCrossing Quantile Regression Process with Deep ReQU Neural Networks We propose a penalized nonparametric approach to estimating the quantileregression process QRP in a nonseparable model using rectifier quadratic unitReQU activated deep neural networks and introduce a novel penalty function toenforce noncrossing of quantile regression curves. We establish thenonasymptotic excess risk bounds for the estimated QRP and derive the meanintegrated squared error for the estimated QRP under mild smoothness andregularity conditions. To establish these nonasymptotic risk and estimationerror bounds we also develop a new error bound for approximating Cs smoothfunctions with s  and their derivatives using ReQU activated neuralnetworks. This is a new approximation result for ReQU networks and is ofindependent interest and may be useful in other problems. Our numericalexperiments demonstrate that the proposed method is competitive with oroutperforms two existing methods including methods using reproducing kernelsand random forests for nonparametric quantile regression.,4
Semantic uncertainty intervals for disentangled latent spaces Meaningful uncertainty quantification in computer vision requires reasoningabout semantic information  say the hair color of the person in a photo orthe location of a car on the street. To this end recent breakthroughs ingenerative modeling allow us to represent semantic information in disentangledlatent spaces but providing uncertainties on the semantic latent variables hasremained challenging. In this work we provide principled uncertainty intervalsthat are guaranteed to contain the true semantic factors for any underlyinggenerative model. The method does the following  it uses quantileregression to output a heuristic uncertainty interval for each element in thelatent space  calibrates these uncertainties such that they contain the truevalue of the latent for a new unseen input. The endpoints of these calibratedintervals can then be propagated through the generator to produce interpretableuncertainty visualizations for each semantic factor. This technique reliablycommunicates semantically meaningful principled and instanceadaptiveuncertainty in inverse problems like image superresolution and imagecompletion.,4
DCBRS Accounting For IntraClass Diversity in Continual Learning Continual learning  accumulating knowledge from a sequence of learningexperiences  is an important yet challenging problem. In this paradigm themodels performance for previously encountered instances may substantially dropas additional data are seen. When dealing with classimbalanced dataforgetting is further exacerbated. Prior work has proposed replaybasedapproaches which aim at reducing forgetting by intelligently storing instancesfor future replay. Although ClassBalancing Reservoir Sampling CBRS has beensuccessful in dealing with imbalanced data the intraclass diversity has notbeen accounted for implicitly assuming that each instance of a class isequally informative. We present DiverseCBRS DCBRS an algorithm that allowsus to consider within class diversity when storing instances in the memory. Ourresults show that DCBRS outperforms stateoftheart memory managementcontinual learning algorithms on data sets with considerable intraclassdiversity.,4
Collaborative Uncertainty Benefits MultiAgent MultiModal Trajectory Forecasting In multimodal multiagent trajectory forecasting two major challenges havenot been fully tackled  how to measure the uncertainty brought by theinteraction module that causes correlations among the predicted trajectories ofmultiple agents  how to rank the multiple predictions and select the optimalpredicted trajectory. In order to handle these challenges this work firstproposes a novel concept collaborative uncertainty CU which models theuncertainty resulting from interaction modules. Then we build a generalCUaware regression framework with an original permutationequivariantuncertainty estimator to do both tasks of regression and uncertaintyestimation. Further we apply the proposed framework to current SOTAmultiagent multimodal forecasting systems as a plugin module which enablesthe SOTA systems to  estimate the uncertainty in the multiagent multimodaltrajectory forecasting task  rank the multiple predictions and select theoptimal one based on the estimated uncertainty. We conduct extensiveexperiments on a synthetic dataset and two public largescale multiagenttrajectory forecasting benchmarks. Experiments show that  on the syntheticdataset the CUaware regression framework allows the model to appropriatelyapproximate the groundtruth Laplace distribution  on the multiagenttrajectory forecasting benchmarks the CUaware regression framework steadilyhelps SOTA systems improve their performances. Specially the proposedframework helps VectorNet improve by  cm regarding the Final DisplacementError of the chosen optimal prediction on the nuScenes dataset  formultiagent multimodal trajectory forecasting systems prediction uncertaintyis positively correlated with future stochasticity and  the estimated CUvalues are highly related to the interactive information among agents.,4
Latent Variable Models for Bayesian Causal Discovery Learning predictors that do not rely on spurious correlations involvesbuilding causal representations. However learning such a representation isvery challenging. We therefore formulate the problem of learning a causalrepresentation from high dimensional data and study causal recovery withsynthetic data. This work introduces a latent variable decoder model DecoderBCD for Bayesian causal discovery and performs experiments in mildlysupervised and unsupervised settings. We present a series of syntheticexperiments to characterize important factors for causal discovery and showthat using known intervention targets as labels helps in unsupervised Bayesianinference over structure and parameters of linear Gaussian additive noiselatent structural causal models.,4
Volatility Based Kernels and Moving Average Means for Accurate Forecasting with Gaussian Processes A broad class of stochastic volatility models are defined by systems ofstochastic differential equations. While these models have seen widespreadsuccess in domains such as finance and statistical climatology they typicallylack an ability to condition on historical data to produce a true posteriordistribution. To address this fundamental limitation we show how to recast aclass of stochastic volatility models as a hierarchical Gaussian process GPmodel with specialized covariance functions. This GP model retains theinductive biases of the stochastic volatility model while providing theposterior predictive distribution given by GP inference. Within this frameworkwe take inspiration from well studied domains to introduce a new class ofmodels Volt and Magpie that significantly outperform baselines in stock andwind speed forecasting and naturally extend to the multitask setting.,4
Riemannian Diffusion Schrdinger Bridge Scorebased generative models exhibit state of the art performance on densityestimation and generative modeling tasks. These models typically assume thatthe data geometry is flat yet recent extensions have been developed tosynthesize data living on Riemannian manifolds. Existing methods to acceleratesampling of diffusion models are typically not applicable in the Riemanniansetting and Riemannian scorebased methods have not yet been adapted to theimportant task of interpolation of datasets. To overcome these issues weintroduce emphRiemannian Diffusion Schrdinger Bridge. Our proposed methodgeneralizes Diffusion Schrdinger Bridge introduced incitedebortolineurips to the nonEuclidean setting and extends Riemannianscorebased models beyond the first time reversal. We validate our proposedmethod on synthetic data and real Earth and climate data.,4
Uncertaintyaware Mixedvariable Machine Learning for Materials Design Datadriven design shows the promise of accelerating materials discovery butis challenging due to the prohibitive cost of searching the vast design spaceof chemistry structure and synthesis methods. Bayesian Optimization BOemploys uncertaintyaware machine learning models to select promising designsto evaluate hence reducing the cost. However BO with mixed numerical andcategorical variables which is of particular interest in materials design hasnot been well studied. In this work we survey frequentist and Bayesianapproaches to uncertainty quantification of machine learning with mixedvariables. We then conduct a systematic comparative study of their performancesin BO using a popular representative model from each group the randomforestbased Lolo model frequentist and the latent variable Gaussian processmodel Bayesian. We examine the efficacy of the two models in the optimizationof mathematical functions as well as properties of structural and functionalmaterials where we observe performance differences as related to problemdimensionality and complexity. By investigating the machine learning modelspredictive and uncertainty estimation capabilities we provide interpretationsof the observed performance differences. Our results provide practical guidanceon choosing between frequentist and Bayesian uncertaintyaware machine learningmodels for mixedvariable BO in materials design.,4
A Universal Tradeoff Between the Model Size Test Loss and Training Loss of Linear Predictors In this work we establish an algorithm and distribution independentnonasymptotic tradeoff between the model size excess test loss and trainingloss of linear predictors. Specifically we show that models that perform wellon the test data have low excess loss are either classical  have trainingloss close to the noise level or are modern  have a much larger number ofparameters compared to the minimum needed to fit the training data exactly.,4
Tree ensemble kernels for Bayesian optimization with known constraints over mixedfeature spaces Tree ensembles can be wellsuited for blackbox optimization tasks such asalgorithm tuning and neural architecture search as they achieve goodpredictive performance with little to no manual tuning naturally handlediscrete feature spaces and are relatively insensitive to outliers in thetraining data. Two wellknown challenges in using tree ensembles for blackboxoptimization are i effectively quantifying model uncertainty for explorationand ii optimizing over the piecewise constant acquisition function. Toaddress both points simultaneously we propose using the kernel interpretationof tree ensembles as a Gaussian Process prior to obtain model varianceestimates and we develop a compatible optimization formulation for theacquisition function. The latter further allows us to seamlessly integrateknown constraints to improve sampling efficiency by consideringdomainknowledge in engineering settings and modeling search space symmetriese.g. hierarchical relationships in neural architecture search. Our frameworkperforms as well as stateoftheart methods for unconstrained blackboxoptimization over continuousdiscrete features and outperforms competingmethods for problems combining mixedvariable feature spaces and known inputconstraints.,4
Efficient Search of Multiple Neural Architectures with Different Complexities via Importance Sampling Neural architecture search NAS aims to automate architecture designprocesses and improve the performance of deep neural networks. PlatformawareNAS methods consider both performance and complexity and can findwellperforming architectures with low computational resources. Althoughordinary NAS methods result in tremendous computational costs owing to therepetition of model training oneshot NAS which trains the weights of asupernetwork containing all candidate architectures only once during the searchprocess has been reported to result in a lower search cost. This study focuseson the architecture complexityaware oneshot NAS that optimizes the objectivefunction composed of the weighted sum of two metrics such as the predictiveperformance and number of parameters. In existing methods the architecturesearch process must be run multiple times with different coefficients of theweighted sum to obtain multiple architectures with different complexities. Thisstudy aims at reducing the search cost associated with finding multiplearchitectures. The proposed method uses multiple distributions to generatearchitectures with different complexities and updates each distribution usingthe samples obtained from multiple distributions based on importance sampling.The proposed method allows us to obtain multiple architectures with differentcomplexities in a single architecture search resulting in reducing the searchcost. The proposed method is applied to the architecture search ofconvolutional neural networks on the CIAFR and ImageNet datasets.Consequently compared with baseline methods the proposed method findsmultiple architectures with varying complexities while requiring lesscomputational effort.,4
A Generative Framework for Personalized Learning and Estimation Theory Algorithms and Privacy A distinguishing characteristic of federated learning is that the localclient data could have statistical heterogeneity. This heterogeneity hasmotivated the design of personalized learning where individual personalizedmodels are trained through collaboration. There have been variouspersonalization methods proposed in literature with seemingly very differentforms and methods ranging from use of a single global model for localregularization and model interpolation to use of multiple global models forpersonalized clustering etc. In this work we begin with a generativeframework that could potentially unify several different algorithms as well assuggest new algorithms. We apply our generative framework to personalizedestimation and connect it to the classical empirical Bayes methodology. Wedevelop private personalized estimation under this framework. We then use ourgenerative framework for learning which unifies several known personalized FLalgorithms and also suggests new ones we propose and study a new algorithmAdaPeD based on a Knowledge Distillation which numerically outperforms severalknown algorithms. We also develop privacy for personalized learning methodswith guarantees for userlevel privacy and composition. We numerically evaluatethe performance as well as the privacy for both the estimation and learningproblems demonstrating the advantages of our proposed methods.,4
Randomly pivoted Cholesky Practical approximation of a kernel matrix with few entry evaluations Randomly pivoted Cholesky RPCholesky is a natural algorithm for computing arankk approximation of an N x N positive semidefinite psd matrix. RPCholeskycan be implemented with just a few lines of code. It requires only kN entryevaluations and Ok N additional arithmetic operations. This paper offersthe first serious investigation of its experimental and theoretical behavior.Empirically RPCholesky matches or improves on the performance of alternativealgorithms for lowrank psd approximation. Furthermore RPCholesky provablyachieves nearoptimal approximation guarantees. The simplicity effectivenessand robustness of this algorithm strongly support its use in scientificcomputing and machine learning applications.,4
Discover Life Skills for Planning with Bandits via Observing and Learning How the World Works We propose a novel approach for planning agents to compose abstract skillsvia observing and learning from historical interactions with the world. Ourframework operates in a Markov statespace model via a set of actions underunknown preconditions. We formulate skills as highlevel abstract policiesthat propose action plans based on the current state. Each policy learns newplans by observing the states transitions while the agent interacts with theworld. Such an approach automatically learns new plans to achieve specificintended effects but the success of such plans is often dependent on thestates in which they are applicable. Therefore we formulate the evaluation ofsuch plans as infinitely many multiarmed bandit problems where we balance theallocation of resources on evaluating the success probability of existing armsand exploring new options. The result is a planner capable of automaticallylearning robust highlevel skills under a noisy environment such skillsimplicitly learn the action precondition without explicit knowledge. We showthat this planning approach is experimentally very competitive inhighdimensional state space domains.,4
Minimax Rates for Robust Community Detection In this work we study the problem of community detection in the stochasticblock model with adversarial node corruptions. Our main result is an efficientalgorithm that can tolerate an epsilonfraction of corruptions and achieveserror Oepsilon  efracC  pm o where C  sqrta sqrtb is the signaltonoise ratio and an and bn are theintercommunity and intracommunity connection probabilities respectively.These bounds essentially match the minimax rates for the SBM withoutcorruptions. We also give robust algorithms for mathbbZsynchronization.At the heart of our algorithm is a new semidefinite program that uses globalinformation to robustly boost the accuracy of a rough clustering. Moreover weshow that our algorithms are doublyrobust in the sense that they work in aneven more challenging noise model that mixes adversarial corruptions withunbounded monotone changes from the semirandom model.,4
Seeking the Truth Beyond the Data. An Unsupervised Machine Learning Approach Clustering is an unsupervised machine learning methodology where unlabeledelementsobjects are grouped together aiming to the construction ofwellestablished clusters that their elements are classified according to theirsimilarity. The goal of this process is to provide a useful aid to theresearcher that will help herhim to identify patterns among the data. Dealingwith large databases such patterns may not be easily detectable without thecontribution of a clustering algorithm. This article provides a deepdescription of the most widely used clustering methodologies accompanied byuseful presentations concerning suitable parameter selection andinitializations. Simultaneously this article not only represents a reviewhighlighting the major elements of examined clustering techniques butemphasizes the comparison of these algorithms clustering efficiency based on datasets revealing their existing weaknesses and capabilities through accuracyand complexity during the confrontation of discrete and continuousobservations. The produced results help us extract valuable conclusions aboutthe appropriateness of the examined clustering techniques in accordance withthe datasets size.,4
Functional Generalized Empirical Likelihood Estimation for Conditional Moment Restrictions Important problems in causal inference economics and more generallyrobust machine learning can be expressed as conditional moment restrictionsbut estimation becomes challenging as it requires solving a continuum ofunconditional moment restrictions. Previous works addressed this problem byextending the generalized method of moments GMM to continuum momentrestrictions. In contrast generalized empirical likelihood GEL provides amore general framework and has been shown to enjoy favorable smallsampleproperties compared to GMMbased estimators. To benefit from recentdevelopments in machine learning we provide a functional reformulation of GELin which arbitrary models can be leveraged. Motivated by a dual formulation ofthe resulting infinite dimensional optimization problem we devise a practicalmethod and explore its asymptotic properties. Finally we provide kernel andneural networkbased implementations of the estimator which achievestateoftheart empirical performance on two conditional moment restrictionproblems.,4
Probabilistic Reconciliation of Count Time Series We propose a principled method for the reconciliation of any probabilisticbase forecasts. We show how probabilistic reconciliation can be obtained bymerging via Bayes rule the information contained in the base forecast forthe bottom and the upper time series. We illustrate our method on a toyhierarchy showing how our framework allows the probabilistic reconciliation ofany base forecast. We perform experiment in the reconciliation of temporalhierarchies of count time series obtaining major improvements compared toprobabilistic reconciliation based on the Gaussian or the truncated Gaussiandistribution.,4
Variance estimation in graphs with the fused lasso We study the problem of variance estimation in general graphstructuredproblems. First we develop a linear time estimator for the homoscedastic casethat can consistently estimate the variance in general graphs. We show that ourestimator attains minimax rates for the chain and D grid graphs when the meansignal has a total variation with canonical scaling. Furthermore we providegeneral upper bounds on the mean squared error performance of the fused lassoestimator in general graphs under a moment condition and a bound on the tailbehavior of the errors. These upper bounds allow us to generalize for broaderclasses of distributions such as subExponential many existing results on thefused lasso that are only known to hold with the assumption that errors aresubGaussian random variables. Exploiting our upper bounds we then study asimple total variation regularization estimator for estimating the signal ofvariances in the heteroscedastic case. Our results show that the varianceestimator attains minimax rates for estimating signals of bounded variation ingrid graphs Knearest neighbor graphs with very mild assumptions and it isconsistent for estimating the variances in any connected graph. In additionextensive numerical results show that our proposed estimators performreasonably well in a variety of graphstructured models.,4
On minimax density estimation via measure transport We study the convergence properties in Hellinger and related distances ofnonparametric density estimators based on measure transport. These estimatorsrepresent the measure of interest as the pushforward of a chosen referencedistribution under a transport map where the map is chosen via a maximumlikelihood objective equivalently minimizing an empirical KullbackLeiblerloss or a penalized version thereof. We establish concentration inequalitiesfor a general class of penalized measure transport estimators by combiningtechniques from Mestimation with analytical properties of the transportbaseddensity representation. We then demonstrate the implications of our theory forthe case of triangular KnotheRosenblatt KR transports on the ddimensionalunit cube and show that both penalized and unpenalized versions of suchestimators achieve minimax optimal convergence rates over Hlder classes ofdensities. Specifically we establish optimal rates for unpenalizednonparametric maximum likelihood estimation over bounded Hldertype ballsand then for certain Sobolevpenalized estimators and sieved waveletestimators.,4
Fuzzy Clustering by Hyperbolic Smoothing We propose a novel method for building fuzzy clusters of large data setsusing a smoothing numerical approach. The usual sumofsquares criterion isrelaxed so the search for good fuzzy partitions is made on a continuous spacerather than a combinatorial space as in classical methods citeHartigan. Thesmoothing allows a conversion from a strongly nondifferentiable problem intodifferentiable subproblems of optimization without constraints of lowdimension by using a differentiable function of infinite class. For theimplementation of the algorithm we used the statistical software R and theresults obtained were compared to the traditional fuzzy Cmeans methodproposed by Bezdek.,4
Grounding Aleatoric Uncertainty in Unsupervised Environment Design Adaptive curricula in reinforcement learning RL have proven effective forproducing policies robust to discrepancies between the train and testenvironment. Recently the Unsupervised Environment Design UED frameworkgeneralized RL curricula to generating sequences of entire environmentsleading to new methods with robust minimax regret properties. Problematicallyin partiallyobservable or stochastic settings optimal policies may depend onthe groundtruth distribution over aleatoric parameters of the environment inthe intended deployment setting while curriculum learning necessarily shiftsthe training distribution. We formalize this phenomenon as curriculuminducedcovariate shift CICS and describe how its occurrence in aleatoric parameterscan lead to suboptimal policies. Directly sampling these parameters from thegroundtruth distribution avoids the issue but thwarts curriculum learning. Wepropose SAMPLR a minimax regret UED method that optimizes the groundtruthutility function even when the underlying training data is biased due to CICS.We prove and validate on challenging domains that our approach preservesoptimality under the groundtruth distribution while promoting robustnessacross the full range of environment settings.,4
Size and depth of monotone neural networks interpolation and approximation Monotone functions and data sets arise in a variety of applications. We studythe interpolation problem for monotone data sets The input is a monotone dataset with n points and the goal is to find a size and depth efficientmonotone neural network with non negative parameters and threshold units thatinterpolates the data set. We show that there are monotone data sets thatcannot be interpolated by a monotone network of depth . On the other handwe prove that for every monotone data set with n points in mathbbRdthere exists an interpolating monotone network of depth  and size Ond.Our interpolation result implies that every monotone function over dcan be approximated arbitrarily well by a depth monotone network improvingthe previous bestknown construction of depth d. Finally building onresults from Boolean circuit complexity we show that the inductive bias ofhaving positive parameters can lead to a superpolynomial blowup in the numberof neurons when approximating monotone functions.,4
Learning Bellman Complete Representations for Offline Policy Evaluation We study representation learning for Offline Reinforcement Learning RLfocusing on the important task of Offline Policy Evaluation OPE. Recent workshows that in contrast to supervised learning realizability of the Qfunctionis not enough for learning it. Two sufficient conditions for sampleefficientOPE are Bellman completeness and coverage. Prior work often assumes thatrepresentations satisfying these conditions are given with results beingmostly theoretical in nature. In this work we propose BCRL which directlylearns from data an approximately linear Bellman complete representation withgood coverage. With this learned representation we perform OPE using LeastSquare Policy Evaluation LSPE with linear functions in our learnedrepresentation. We present an endtoend theoretical analysis showing that ourtwostage algorithm enjoys polynomial sample complexity provided somerepresentation in the rich class considered is linear Bellman complete.Empirically we extensively evaluate our algorithm on challenging imagebasedcontinuous control tasks from the Deepmind Control Suite. We show ourrepresentation enables better OPE compared to previous representation learningmethods developed for offpolicy RL e.g. CURL SPR. BCRL achieve competitiveOPE error with the stateoftheart method Fitted QEvaluation FQE and beatsFQE when evaluating beyond the initial state distribution. Our ablations showthat both linear Bellman complete and coverage components of our method arecrucial.,4
MetaLearning a RealTime Tabular AutoML Method For Small Data We present TabPFN an AutoML method that is competitive with the state of theart on small tabular datasets while being over times faster. Our methodis very simple it is fully entailed in the weights of a single neural networkand a single forward pass directly yields predictions for a new dataset. OurAutoML method is metalearned using the Transformerbased PriorData FittedNetwork PFN architecture and approximates Bayesian inference with a priorthat is based on assumptions of simplicity and causal structures. The priorcontains a large space of structural causal models and Bayesian neural networkswith a bias for small architectures and thus low complexity. Furthermore weextend the PFN approach to differentiably calibrate the priors hyperparameterson real data. By doing so we separate our abstract prior assumptions fromtheir heuristic calibration on real data. Afterwards the calibratedhyperparameters are fixed and TabPFN can be applied to any new tabular datasetat the push of a button. Finally on  datasets from the OpenMLCC suite weshow that our method outperforms boosted trees and performs on par with complexstateoftheart AutoML systems with predictions produced in less than asecond. We provide all our code and our final trained TabPFN in thesupplementary materials.,4
Nonlinear Sufficient Dimension Reduction for DistributiononDistribution Regression We introduce a novel framework for nonlinear sufficient dimension reductionwhere both the predictor and the response are distributional data which aremodeled as members of a metric space. Our key step to achieving the nonlinearsufficient dimension reduction is to build universal kernels on the metricspaces which results in reproducing kernel Hilbert spaces for the predictorand response that are rich enough to characterize the conditional independencethat determines sufficient dimension reduction. For univariate distributionswe use the wellknown quantile representation of the Wasserstein distance toconstruct the universal kernel for multivariate distributions we resort tothe recently developed sliced Wasserstein distance to achieve this purpose.Since the sliced Wasserstein distance can be computed by aggregation ofquantile representation of the univariate Wasserstein distance the computationof multivariate Wasserstein distance is kept at a manageable level. The methodis applied to several data sets including fertility and mortality distributiondata and Calgary temperature data.,4
Rewiring Networks for Graph Neural Network Training Using Discrete Geometry Information oversquashing is a phenomenon of inefficient informationpropagation between distant nodes on networks. It is an important problem thatis known to significantly impact the training of graph neural networks GNNsas the receptive field of a node grows exponentially. To mitigate this problema preprocessing procedure known as rewiring is often applied to the inputnetwork. In this paper we investigate the use of discrete analogues ofclassical geometric notions of curvature to model information flow on networksand rewire them. We show that these classical notions achieve stateoftheartperformance in GNN training accuracy on a variety of realworld networkdatasets. Moreover compared to the current stateoftheart these classicalnotions exhibit a clear advantage in computational runtime by several orders ofmagnitude.,4
High dimensional stochastic linear contextual bandit with missing covariates Recent works in bandit problems adopted lasso convergence theory in thesequential decisionmaking setting. Even with fully observed contexts thereare technical challenges that hinder the application of existing lassoconvergence theory  proving the restricted eigenvalue condition underconditionally subGaussian noise and  accounting for the dependence betweenthe context variables and the chosen actions. This paper studies the effect ofmissing covariates on regret for stochastic linear bandit algorithms. Our workprovides a highprobability upper bound on the regret incurred by the proposedalgorithm in terms of covariate sampling probabilities showing that the regretdegrades due to missingness by at most zetamin where zetamin isthe minimum probability of observing covariates in the context vector. Weillustrate our algorithm for the practical application of experimental designfor collecting gene expression data by a sequential selection of classdiscriminating DNA probes.,4
Fairnessaware Network Revenue Management with Demand Learning In addition to maximizing the total revenue decisionmakers in lots ofindustries would like to guarantee fair consumption across different resourcesand avoid saturating certain resources. Motivated by these practical needsthis paper studies the pricebased network revenue management problem with bothdemand learning and fairness concern about the consumption across differentresources. We introduce the regularized revenue i.e. the total revenue with afairness regularization as our objective to incorporate fairness into therevenue maximization goal. We propose a primaldualtype online policy with theUpperConfidenceBound UCB demand learning method to maximize the regularizedrevenue. We adopt several innovative techniques to make our algorithm a unifiedand computationally efficient framework for the continuous price set and a wideclass of fairness regularizers. Our algorithm achieves a worstcase regret oftilde ONsqrtT where N denotes the number of products and Tdenotes the number of time periods. Numerical experiments in a few NRM examplesdemonstrate the effectiveness of our algorithm for balancing revenue andfairness.,4
Flowsheet synthesis through hierarchical reinforcement learning and graph neural networks Process synthesis experiences a disruptive transformation accelerated bydigitization and artificial intelligence. We propose a reinforcement learningalgorithm for chemical process design based on a stateoftheart actorcriticlogic. Our proposed algorithm represents chemical processes as graphs and usesgraph convolutional neural networks to learn from process graphs. Inparticular the graph neural networks are implemented within the agentarchitecture to process the states and make decisions. Moreover we implement ahierarchical and hybrid decisionmaking process to generate flowsheets whereunit operations are placed iteratively as discrete decisions and correspondingdesign variables are selected as continuous decisions. We demonstrate thepotential of our method to design economically viable flowsheets in anillustrative case study comprising equilibrium reactions azeotropicseparation and recycles. The results show quick learning in discretecontinuous and hybrid action spaces. Due to the flexible architecture of theproposed reinforcement learning agent the method is predestined to includelarge actionstate spaces and an interface to process simulators in futureresearch.,4
Selection of the Most Probable Best We consider an expectedvalue ranking and selection problem where all ksolutions simulation outputs depend on a common uncertain input model. Giventhat the uncertainty of the input model is captured by a probability simplex ona finite support we define the most probable best MPB to be the solutionwhose probability of being optimal is the largest. To devise an efficientsampling algorithm to find the MPB we first derive a lower bound to the largedeviation rate of the probability of falsely selecting the MPB then formulatean optimal computing budget allocation OCBA problem to find the optimalstatic sampling ratios for all solutioninput model pairs that maximize thelower bound. We devise a series of sequential algorithms that applyinterpretable and computationally efficient sampling rules and prove theirsampling ratios achieve the optimality conditions for the OCBA problem as thesimulation budget increases. The algorithms are benchmarked against astateoftheart sequential sampling algorithm designed for contextual rankingand selection problems and demonstrated to have superior empirical performancesat finding the MPB.,4
Approximation Power of Deep Neural Networks an explanatory mathematical survey The goal of this survey is to present an explanatory review of theapproximation properties of deep neural networks. Specifically we aim atunderstanding how and why deep neural networks outperform other classicallinear and nonlinear approximation methods. This survey consists of threechapters. In Chapter  we review the key ideas and concepts underlying deepnetworks and their compositional nonlinear structure. We formalize the neuralnetwork problem by formulating it as an optimization problem when solvingregression and classification problems. We briefly discuss the stochasticgradient descent algorithm and the backpropagation formulas used in solvingthe optimization problem and address a few issues related to the performance ofneural networks including the choice of activation functions cost functionsoverfitting issues and regularization. In Chapter  we shift our focus to theapproximation theory of neural networks. We start with an introduction to theconcept of density in polynomial approximation and in particular study theStoneWeierstrass theorem for realvalued continuous functions. Then withinthe framework of linear approximation we review a few classical results on thedensity and convergence rate of feedforward networks followed by more recentdevelopments on the complexity of deep networks in approximating Sobolevfunctions. In Chapter  utilizing nonlinear approximation theory we furtherelaborate on the power of depth and approximation superiority of deep ReLUnetworks over other classical methods of nonlinear approximation.,4
Model Selection in Reinforcement Learning with General Function Approximations We consider model selection for classic Reinforcement Learning RLenvironments  Multi Armed Bandits MABs and Markov Decision Processes MDPs under general function approximations. In the model selection framework wedo not know the function classes denoted by mathcalF and mathcalMwhere the true models  reward generating function for MABs and and transitionkernel for MDPs  lie respectively. Instead we are given M nested functionhypothesis classes such that true models are contained in atleast one suchclass. In this paper we propose and analyze efficient model selectionalgorithms for MABs and MDPs that emphadapt to the smallest function classamong the nested M classes containing the true underlying model. Under aseparability assumption on the nested hypothesis classes we show that thecumulative regret of our adaptive algorithms match to that of an oracle whichknows the correct function classes i.e. cF and cM a priori.Furthermore for both the settings we show that the cost of model selection isan additive term in the regret having weak logarithmic dependence on thelearning horizon T.,4
Mean field Variational Inference via Wasserstein Gradient Flow Variational inference VI provides an appealing alternative to traditionalsamplingbased approaches for implementing Bayesian inference due to itsconceptual simplicity statistical accuracy and computational scalability.However common variational approximation schemes such as the meanfield MFapproximation require certain conjugacy structure to facilitate efficientcomputation which may add unnecessary restrictions to the viable priordistribution family and impose further constraints on the variationalapproximation family. In this work we develop a general computationalframework for implementing MFVI via Wasserstein gradient flow WGF agradient flow over the space of probability measures. When specialized toBayesian latent variable models we analyze the algorithmic convergence of analternating minimization scheme based on a timediscretized WGF forimplementing the MF approximation. In particular the proposed algorithmresembles a distributional version of EM algorithm consisting of an Estep ofupdating the latent variable variational distribution and an Mstep ofconducting steepest descent over the variational distribution of parameters.Our theoretical analysis relies on optimal transport theory and subdifferentialcalculus in the space of probability measures. We prove the exponentialconvergence of the timediscretized WGF for minimizing a generic objectivefunctional given strict convexity along generalized geodesics. We also providea new proof of the exponential contraction of the variational distributionobtained from the MF approximation by using the fixedpoint equation of thetimediscretized WGF. We apply our method and theory to two classic Bayesianlatent variable models the Gaussian mixture model and the mixture ofregression model. Numerical experiments are also conducted to compliment thetheoretical findings under these two models.,4
DataDriven Stochastic ACOPF using Gaussian Processes In recent years electricity generation has been responsible for more than aquarter of the greenhouse gas emissions in the US. Integrating a significantamount of renewables into a power grid is probably the most accessible way toreduce carbon emissions from power grids and slow down climate change.Unfortunately the most accessible renewable power sources such as wind andsolar are highly fluctuating and thus bring a lot of uncertainty to power gridoperations and challenge existing optimization and control policies. Thechanceconstrained alternating current AC optimal power flow OPF frameworkfinds the minimum cost generation dispatch maintaining the power gridoperations within security limits with a prescribed probability. Unfortunatelythe ACOPF problems chanceconstrained extension is nonconvexcomputationally challenging and requires knowledge of system parameters andadditional assumptions on the behavior of renewable distribution. Known linearand convex approximations to the above problems though tractable are tooconservative for operational practice and do not consider uncertainty in systemparameters. This paper presents an alternative datadriven approach based onGaussian process GP regression to close this gap. The GP approach learns asimple yet nonconvex datadriven approximation to the AC power flow equationsthat can incorporate uncertainty inputs. The latter is then used to determinethe solution of CCOPF efficiently by accounting for both input and parameteruncertainty. The practical efficiency of the proposed approach using differentapproximations for GPuncertainty propagation is illustrated over numerous IEEEtest cases.,4
Guaranteed Discovery of Controllable Latent States with MultiStep Inverse Models A person walking along a city street who tries to model all aspects of theworld would quickly be overwhelmed by a multitude of shops cars and peoplemoving in and out of view following their own complex and inscrutabledynamics. Exploration and navigation in such an environment is an everydaytask requiring no vast exertion of mental resources. Is it possible to turnthis fire hose of sensory information into a minimal latent state which isnecessary and sufficient for an agent to successfully act in the world Weformulate this question concretely and propose the AgentControllable StateDiscovery algorithm ACState which has theoretical guarantees and ispractically demonstrated to discover the textitminimal controllable latentstate which contains all of the information necessary for controlling theagent while fully discarding all irrelevant information. This algorithmconsists of a multistep inverse model predicting actions from distantobservations with an information bottleneck. ACState enables localizationexploration and navigation without reward or demonstrations. We demonstratethe discovery of controllable latent state in three domains localizing a robotarm with distractions e.g. changing lighting conditions and backgroundexploring in a maze alongside other agents and navigating in the Matterporthouse simulator.,4
Improving the Accuracy of Marginal Approximations in LikelihoodFree Inference via Localisation Likelihoodfree methods are an essential tool for performing inference forimplicit models which can be simulated from but for which the correspondinglikelihood is intractable. However common likelihoodfree methods do not scalewell to a large number of model parameters. A promising approach tohighdimensional likelihoodfree inference involves estimating lowdimensionalmarginal posteriors by conditioning only on summary statistics believed to beinformative for the lowdimensional component and then combining thelowdimensional approximations in some way. In this paper we demonstrate thatsuch lowdimensional approximations can be surprisingly poor in practice forseemingly intuitive summary statistic choices. We describe an idealizedlowdimensional summary statistic that is in principle suitable for marginalestimation. However a direct approximation of the idealized choice isdifficult in practice. We thus suggest an alternative approach to marginalestimation which is easier to implement and automate. Given an initial choiceof lowdimensional summary statistic that might only be informative about amarginal posterior location the new method improves performance by firstcrudely localising the posterior approximation using all the summary statisticsto ensure global identifiability followed by a second step that hones in on anaccurate lowdimensional approximation using the lowdimensional summarystatistic. We show that the posterior this approach targets can be representedas a logarithmic pool of posterior distributions based on the lowdimensionaland full summary statistics respectively. The good performance of our methodis illustrated in several examples.,4
Finitetime Highprobability Bounds for PolyakRuppert Averaged Iterates of Linear Stochastic Approximation This paper provides a finitetime analysis of linear stochastic approximationLSA algorithms with fixed step size a core method in statistics and machinelearning. LSA is used to compute approximate solutions of a ddimensionallinear system barmathbfA theta  barmathbfb for whichbarmathbfA barmathbfb can only be estimated throughasymptotically unbiased observationsmathbfAZnmathbfbZnn in mathbbN. We consider herethe case where Znn in mathbbN is an i.i.d. sequence or auniformly geometrically ergodic Markov chain and derive pmoments inequalityand high probability bounds for the iterates defined by LSA and itsPolyakRuppert averaged version. More precisely we establish bounds of orderp alpha toperatornamemixdp on the pth moment of thelast iterate of LSA. In this formula alpha is the step size of the procedureand toperatornamemix is the mixing time of the underlying chaintoperatornamemix in the i.i.d. setting. We then prove finitetimeinstancedependent bounds on the PolyakRuppert averaged sequence of iterates.These results are sharp in the sense that the leading term we obtain matchesthe local asymptotic minimax limit including tight dependence on theparameters dtoperatornamemix in the higher order terms.,4
General Policy Evaluation and Improvement by Learning to Identify Few But Crucial States Learning to evaluate and improve policies is a core problem of ReinforcementLearning RL. Traditional RL algorithms learn a value function defined for asingle policy. A recently explored competitive alternative is to learn a singlevalue function for many policies. Here we combine the actorcritic architectureof ParameterBased Value Functions and the policy embedding of PolicyEvaluation Networks to learn a single value function for evaluating and thushelping to improve any policy represented by a deep neural network NN. Themethod yields competitive experimental results. In continuous control problemswith infinitely many states our value function minimizes its prediction errorby simultaneously learning a small set of probing states and a mapping fromactions produced in probing states to the policys return. The method extractscrucial abstract knowledge about the environment in form of very few statessufficient to fully specify the behavior of many policies. A policy improvessolely by changing actions in probing states following the gradient of thevalue functions predictions. Surprisingly it is possible to clone thebehavior of a nearoptimal policy in Swimmerv and Hopperv environments onlyby knowing how to act in  and  such learned states respectively. Remarkablyour value function trained to evaluate NN policies is also invariant to changesof the policy architecture we show that it allows for zeroshot learning oflinear policies competitive with the best policy seen during training. Our codeis public.,4
Differentially Private Graph Learning via SensitivityBounded Personalized PageRank Personalized PageRank PPR is a fundamental tool in unsupervised learning ofgraph representations such as node ranking labeling and graph embedding.However while data privacy is one of the most important recent concernsexisting PPR algorithms are not designed to protect user privacy. PPR is highlysensitive to the input graph edges the difference of only one edge may cause abig change in the PPR vector potentially leaking private user data.,4
When Does Differentially Private Learning Not Suffer in High Dimensions Large pretrained models can be privately finetuned to achieve performanceapproaching that of nonprivate models. A common theme in these results is thesurprising observation that highdimensional models can achieve favorableprivacyutility tradeoffs. This seemingly contradicts known results on themodelsize dependence of differentially private convex learning and raises thefollowing research question When does the performance of differentiallyprivate learning not degrade with increasing model size We identify that themagnitudes of gradients projected onto subspaces is a key factor thatdetermines performance. To precisely characterize this for private convexlearning we introduce a condition on the objective that we term restrictedLipschitz continuity and derive improved bounds for the excess empirical andpopulation risks that are dimensionindependent under additional conditions. Weempirically show that in private finetuning of large language modelsgradients evaluated near a local optimum are mostly controlled by a fewprincipal components. This behavior is similar to conditions under which weobtain dimensionindependent bounds in convex settings. Our theoretical andempirical results together provide a possible explanation for recent successesin largescale private finetuning.,4
Finitetime Highprobability Bounds for PolyakRuppert Averaged Iterates of Linear Stochastic Approximation This paper provides a finitetime analysis of linear stochastic approximationLSA algorithms with fixed step size a core method in statistics and machinelearning. LSA is used to compute approximate solutions of a ddimensionallinear system barmathbfA theta  barmathbfb for whichbarmathbfA barmathbfb can only be estimated throughasymptotically unbiased observationsmathbfAZnmathbfbZnn in mathbbN. We consider herethe case where Znn in mathbbN is an i.i.d. sequence or auniformly geometrically ergodic Markov chain and derive pmoments inequalityand high probability bounds for the iterates defined by LSA and itsPolyakRuppert averaged version. More precisely we establish bounds of orderp alpha toperatornamemixdp on the pth moment of thelast iterate of LSA. In this formula alpha is the step size of the procedureand toperatornamemix is the mixing time of the underlying chaintoperatornamemix in the i.i.d. setting. We then prove finitetimeinstancedependent bounds on the PolyakRuppert averaged sequence of iterates.These results are sharp in the sense that the leading term we obtain matchesthe local asymptotic minimax limit including tight dependence on theparameters dtoperatornamemix in the higher order terms.,4
Multiscale Causal Structure Learning The inference of causal structures from observed data plays a key role inunveiling the underlying dynamics of the system. This paper exposes a novelmethod named MultiscaleCausal Structure Learning MSCASTLE to estimate thestructure of linear causal relationships occurring at different time scales.Differently from existing approaches MSCASTLE takes explicitly into accountinstantaneous and lagged interrelations between multiple time seriesrepresented at different scales hinging on stationary wavelet transform andnonconvex optimization. MSCASTLE incorporates as a special case asinglescale version named SSCASTLE which compares favorably in terms ofcomputational efficiency performance and robustness with respect to the stateof the art onto synthetic data. We used MSCASTLE to study the multiscalecausal structure of the risk of  global equity markets during covidpandemic illustrating how MSCASTLE can extract meaningful information thanksto its multiscale analysis outperforming SSCASTLE. We found that the mostpersistent and strongest interactions occur at midterm time resolutions.Moreover we identified the stock markets that drive the risk during theconsidered period Brazil Canada and Italy. The proposed approach can beexploited by financial investors who depending to their investment horizoncan manage the risk within equity portfolios from a causal perspective.,4
Learning Counterfactually Invariant Predictors We propose a method to learn predictors that are invariant undercounterfactual changes of certain covariates. This method is useful when theprediction target is causally influenced by covariates that should not affectthe predictor output. For instance an object recognition model may beinfluenced by position orientation or scale of the object itself. We addressthe problem of training predictors that are explicitly counterfactuallyinvariant to changes of such covariates. We propose a modelagnosticregularization term based on conditional kernel mean embeddings to enforcecounterfactual invariance during training. We prove the soundness of ourmethod which can handle mixed categorical and continuous multivariateattributes. Empirical results on synthetic and realworld data demonstrate theefficacy of our method in a variety of settings.,4
Repairing Systematic Outliers by Learning Clean Subspaces in VAEs Data cleaning often comprises outlier detection and data repair. Systematicerrors result from nearly deterministic transformations that occur repeatedlyin the data e.g. specific image pixels being set to default values orwatermarks. Consequently models with enough capacity easily overfit to theseerrors making detection and repair difficult. Seeing as a systematic outlieris a combination of patterns of a clean instance and systematic error patternsour main insight is that inliers can be modelled by a smaller representationsubspace in a model than outliers. By exploiting this we propose CleanSubspace Variational Autoencoder CLSVAE a novel semisupervised model fordetection and automated repair of systematic errors. The main idea is topartition the latent space and model inlier and outlier patterns separately.CLSVAE is effective with much less labelled data compared to previous relatedmodels often with less than  of the data. We provide experiments using threeimage datasets in scenarios with different levels of corruption and labelledset sizes comparing to relevant baselines. CLSVAE provides superior repairswithout human intervention e.g. with just . of labelled data we see arelative error decrease of  compared to the closest baseline.,4
Lagrangian Density SpaceTime Deep Neural Network Topology As a networkbased functional approximator we have proposed a LagrangianDensity SpaceTime Deep Neural Networks LDDNN topology. It is qualified forunsupervised training and learning to predict the dynamics of underlyingphysical science governed phenomena. The prototypical network respects thefundamental conservation laws of nature through the succinctly describedLagrangian and Hamiltonian density of the system by a given dataset ofgeneralized nonlinear partial differential equations. The objective is toparameterize the Lagrangian density over a neural network and directly learnfrom it through data instead of handcrafting an exact timedependent Actionsolution of Lagrangian density for the physical system. With this novelapproach can understand and open up the information inference aspect of theBlackbox deep machine learning representation for the physical dynamics ofnature by constructing customtailored network interconnect topologiesactivation and losscost functions based on the underlying physicaldifferential operators. This article will discuss statistical physicsinterpretation of neural networks in the Lagrangian and Hamiltonian domains.,4
Scalable Bayesian Inference for Detection and Deblending in Astronomical Images We present a new probabilistic method for detecting deblending andcataloging astronomical sources called the Bayesian Light Source SeparatorBLISS. BLISS is based on deep generative models which embed neural networkswithin a Bayesian model. For posterior inference BLISS uses a new form ofvariational inference known as Forward Amortized Variational Inference. TheBLISS inference routine is fast requiring a single forward pass of the encodernetworks on a GPU once the encoder networks are trained. BLISS can performfully Bayesian inference on megapixel images in seconds and produces highlyaccurate catalogs. BLISS is highly extensible and has the potential todirectly answer downstream scientific questions in addition to producingprobabilistic catalogs.,4
Learning Optimal Transport Between two Empirical Distributions with Normalizing Flows Optimal transport OT provides effective tools for comparing and mappingprobability measures. We propose to leverage the flexibility of neural networksto learn an approximate optimal transport map. More precisely we present a newand original method to address the problem of transporting a finite set ofsamples associated with a first underlying unknown distribution towards anotherfinite set of samples drawn from another unknown distribution. We show that aparticular instance of invertible neural networks namely the normalizingflows can be used to approximate the solution of this OT problem between apair of empirical distributions. To this aim we propose to relax the Mongeformulation of OT by replacing the equality constraint on the pushforwardmeasure by the minimization of the corresponding Wasserstein distance. Thepushforward operator to be retrieved is then restricted to be a normalizingflow which is trained by optimizing the resulting cost function. This approachallows the transport map to be discretized as a composition of functions. Eachof these functions is associated to one subflow of the network whose outputprovides intermediate steps of the transport between the original and targetmeasures. This discretization yields also a set of intermediate barycentersbetween the two measures of interest. Experiments conducted on toy examples aswell as a challenging task of unsupervised translation demonstrate the interestof the proposed method. Finally some experiments show that the proposedapproach leads to a good approximation of the true OT.,4
How do tuna schools associate to dFADs A study using echosounder buoys to identify global patterns Based on the data gathered by echosounder buoys attached to drifting FishAggregating Devices dFADs across tropical oceans the current study applies aMachine Learning protocol to examine the temporal trends of tuna schoolsassociation to drifting objects. Using a binary output metrics typically usedin the literature were adapted to account for the fact that the entire tunaaggregation under the dFAD was considered. The median time it took tuna tocolonize the dFADs for the first time varied between  and  days dependingon the ocean and the longest soak and colonization times were registered inthe Pacific Ocean. The tuna schools Continuous Residence Times were generallyshorter than Continuous Absence Times median values between  and  days and and  days respectively in line with the results found by previousstudies. Using a regression output two novel metrics namely aggregation timeand disaggregation time were estimated to obtain further insight into thesymmetry of the aggregation process. Across all oceans the time it took forthe tuna aggregation to depart from the dFADs was not significantly longer thanthe time it took for the aggregation to form. The value of these results in thecontext of the ecological trap hypothesis is discussed and further analysesto enrich and make use of this data source are proposed.,4
Long Term Fairness for Minority Groups via Performative Distributionally Robust Optimization Fairness researchers in machine learning ML have coalesced around severalfairness criteria which provide formal definitions of what it means for an MLmodel to be fair. However these criteria have some serious limitations. Weidentify four key shortcomings of these formal fairness criteria and aim tohelp to address them by extending performative prediction to include adistributionally robust objective.,4
POET Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging Finetuning models on edge devices like mobile phones would enableprivacypreserving personalization over sensitive data. However edge traininghas historically been limited to relatively small models with simplearchitectures because training is both memory and energy intensive. We presentPOET an algorithm to enable training large neural networks on memoryscarcebatteryoperated edge devices. POET jointly optimizes the integrated searchsearch spaces of rematerialization and paging two algorithms to reduce thememory consumption of backpropagation. Given a memory budget and a runtimeconstraint we formulate a mixedinteger linear program MILP forenergyoptimal training. Our approach enables training significantly largermodels on embedded devices while reducing energy consumption while notmodifying mathematical correctness of backpropagation. We demonstrate that itis possible to finetune both ResNet and BERT within the memory constraintsof a CortexM class embedded device while outperforming current edge trainingmethods in energy efficiency. POET is an opensource project available at,4
Wasserstein multivariate autoregressive models for modeling distributional time series and its application in graph learning We propose a new autoregressive model for the statistical analysis ofmultivariate distributional time series. The data of interest consist of acollection of multiple series of probability measures supported over a boundedinterval of the real line and that are indexed by distinct time instants. Theprobability measures are modelled as random objects in the Wasserstein space.We establish the autoregressive model in the tangent space at the Lebesguemeasure by first centering all the raw measures so that their Frchet meansturn to be the Lebesgue measure. Using the theory of iterated random functionsystems results on the existence uniqueness and stationarity of the solutionof such a model are provided. We also propose a consistent estimator for themodel coefficient. In addition to the analysis of simulated data the proposedmodel is illustrated with two real data sets made of observations from agedistribution in different countries and bike sharing network in Paris. Finallydue to the positive and boundedness constraints that we impose on the modelcoefficients the proposed estimator that is learned under these constraintsnaturally has a sparse structure. The sparsity allows furthermore theapplication of the proposed model in learning a graph of temporal dependencyfrom the multivariate distributional time series.,4
Estimating value at risk LSTM vs. GARCH Estimating valueatrisk on time series data with possibly heteroscedasticdynamics is a highly challenging task. Typically we face a small data problemin combination with a high degree of nonlinearity causing difficulties forboth classical and machinelearning estimation algorithms. In this paper wepropose a novel valueatrisk estimator using a long shortterm memory LSTMneural network and compare its performance to benchmark GARCH estimators.,4
Private Convex Optimization in General Norms We propose a new framework for differentially private optimization of convexfunctions which are Lipschitz in an arbitrary norm normxcdot. Ouralgorithms are based on a regularized exponential mechanism which samples fromthe density propto expkFmu r where F is the empirical loss and ris a regularizer which is strongly convex with respect to normxcdotgeneralizing a recent work of citeGLL to nonEuclidean settings. We showthat this mechanism satisfies Gaussian differential privacy and solves bothDPERM empirical risk minimization and DPSCO stochastic convexoptimization by using localization tools from convex geometry. Our frameworkis the first to apply to private convex optimization in general normed spacesand directly recovers nonprivate SCO rates achieved by mirror descent as theprivacy parameter eps to infty. As applications for Lipschitzoptimization in ellp norms for all p in   we obtain the firstoptimal privacyutility tradeoffs for p   we improve tradeoffs obtainedby the recent works citeAsiFKT BassilyGN by at least a logarithmicfactor. Our ellp norm and Schattenp norm optimization frameworks arecomplemented with polynomialtime samplers whose query complexity we explicitlybound.,4
Contextual Bandits with Large Action Spaces Made Practical A central problem in sequential decision making is to develop algorithms thatare practical and computationally efficient yet support the use of flexiblegeneralpurpose models. Focusing on the contextual bandit problem recentprogress provides provably efficient algorithms with strong empiricalperformance when the number of possible alternatives actions is small butguarantees for decision making in large continuous action spaces have remainedelusive leading to a significant gap between theory and practice. We presentthe first efficient generalpurpose algorithm for contextual bandits withcontinuous linearly structured action spaces. Our algorithm makes use ofcomputational oracles for i supervised learning and ii optimization overthe action space and achieves sample complexity runtime and memoryindependent of the size of the action space. In addition it is simple andpractical. We perform a largescale empirical evaluation and show that ourapproach typically enjoys superior performance and efficiency compared tostandard baselines.,4
Online Lewis Weight Sampling The seminal work of Cohen and Peng introduced Lewis weight sampling to thetheoretical computer science community yielding fast row sampling algorithmsfor approximating ddimensional subspaces of ellp up to epsilonerror. Several works have extended this important primitive to other settingsincluding the online coreset sliding window and adversarial streaming models.However these results are only for pin and results for prequire a suboptimal tilde Odepsilon samples.,4
Predicting OutofDomain Generalization with Local Manifold Smoothness Understanding how machine learning models generalize to new environments is acritical part of their safe deployment. Recent work has proposed a variety ofcomplexity measures that directly predict or theoretically bound thegeneralization capacity of a model. However these methods rely on a strong setof assumptions that in practice are not always satisfied. Motivated by thelimited settings in which existing measures can be applied we propose a novelcomplexity measure based on the local manifold smoothness of a classifier. Wedefine local manifold smoothness as a classifiers output sensitivity toperturbations in the manifold neighborhood around a given test point.Intuitively a classifier that is less sensitive to these perturbations shouldgeneralize better. To estimate smoothness we sample points using dataaugmentation and measure the fraction of these points classified into themajority class. Our method only requires selecting a data augmentation methodand makes no other assumptions about the model or data distributions meaningit can be applied even in outofdomain OOD settings where existing methodscannot. In experiments on robustness benchmarks in image classificationsentiment analysis and natural language inference we demonstrate a strong androbust correlation between our manifold smoothness measure and actual OODgeneralization on over  models evaluated on over  traintest domainpairs.,4
Analysis of Catastrophic Forgetting for Random Orthogonal Transformation Tasks in the Overparameterized Regime Overparameterization is known to permit strong generalization performance inneural networks. In this work we provide an initial theoretical analysis ofits effect on catastrophic forgetting in a continual learning setup. We showexperimentally that in permuted MNIST image classification tasks thegeneralization performance of multilayer perceptrons trained by vanillastochastic gradient descent can be improved by overparameterization and theextent of the performance increase achieved by overparameterization iscomparable to that of stateoftheart continual learning algorithms. Weprovide a theoretical explanation of this effect by studying a qualitativelysimilar twotask linear regression problem where each task is related by arandom orthogonal transformation. We show that when a model is trained on thetwo tasks in sequence without any additional regularization the risk gain onthe first task is small if the model is sufficiently overparameterized.,4
Learning Mutual Fund Categorization using Natural Language Processing Categorization of mutual funds or ExchangeTradedfunds ETFs have longserved the financial analysts to perform peer analysis for various purposesstarting from competitor analysis to quantifying portfolio diversification.The categorization methodology usually relies on fund composition data in thestructured format extracted from the Form NA. Here we initiate a study tolearn the categorization system directly from the unstructured data as depictedin the forms using natural language processing NLP. Positing as a multiclassclassification problem with the input data being only the investment strategydescription as reported in the form and the target variable being the LipperGlobal categories and using various NLP models we show that thecategorization system can indeed be learned with high accuracy. We discussimplications and applications of our findings as well as limitations ofexisting pretrained architectures in applying them to learn fundcategorization.,4
A State Transition Model for Mobile Notifications via Survival Analysis Mobile notifications have become a major communication channel for socialnetworking services to keep users informed and engaged. As more mobileapplications push notifications to users they constantly face decisions onwhat to send when and how. A lack of research and methodology commonly leadsto heuristic decision making. Many notifications arrive at an inappropriatemoment or introduce too many interruptions failing to provide value to usersand spurring users complaints. In this paper we explore unique features ofinteractions between mobile notifications and user engagement. We propose astate transition framework to quantitatively evaluate the effectiveness ofnotifications. Within this framework we develop a survival model for badgingnotifications assuming a loglinear structure and a Weibull distribution. Ourresults show that this model achieves more flexibility for applications andsuperior prediction accuracy than a logistic regression model. In particularwe provide an online use case on notification delivery time optimization toshow how we make better decisions drive more user engagement and provide morevalue to users.,4
Probing the Robustness of Independent Mechanism Analysis for Representation Learning One aim of representation learning is to recover the original latent codethat generated the data a task which requires additional information orinductive biases. A recently proposed approach termed Independent MechanismAnalysis IMA postulates that each latent source should influence the observedmixtures independently complementing standard nonlinear independent componentanalysis and taking inspiration from the principle of independent causalmechanisms. While it was shown in theory and experiments that IMA helpsrecovering the true latents the methods performance was so far onlycharacterized when the modeling assumptions are exactly satisfied. Here wetest the methods robustness to violations of the underlying assumptions. Wefind that the benefits of IMAbased regularization for recovering the truesources extend to mixing functions with various degrees of violation of the IMAprinciple while standard regularizers do not provide the same merits.Moreover we show that unregularized maximum likelihood recovers mixingfunctions which systematically deviate from the IMA principle and provide anargument elucidating the benefits of IMAbased regularization.,4
Deep Sufficient Representation Learning via Mutual Information We propose a mutual informationbased sufficient representation learningMSRL approach which uses the variational formulation of the mutualinformation and leverages the approximation power of deep neural networks. MSRLlearns a sufficient representation with the maximum mutual information with theresponse and a userselected distribution. It can easily handlemultidimensional continuous or categorical response variables. MSRL is shownto be consistent in the sense that the conditional probability density functionof the response variable given the learned representation converges to theconditional probability density function of the response variable given thepredictor. Nonasymptotic error bounds for MSRL are also established undersuitable conditions. To establish the error bounds we derive a generalizedDudleys inequality for an ordertwo Uprocess indexed by deep neural networkswhich may be of independent interest. We discuss how to determine the intrinsicdimension of the underlying data distribution. Moreover we evaluate theperformance of MSRL via extensive numerical experiments and real data analysisand demonstrate that MSRL outperforms some existing nonlinear sufficientdimension reduction methods.,4
Reliable amortized variational inference with physicsbased latent distribution correction Bayesian inference for highdimensional inverse problems is challenged by thecomputational costs of the forward operator and the selection of an appropriateprior distribution. Amortized variational inference addresses these challengeswhere a neural network is trained to approximate the posterior distributionover existing pairs of model and data. When fed previously unseen data andnormally distributed latent samples as input the pretrained deep neuralnetwork  in our case a conditional normalizing flow  provides posteriorsamples with virtually no cost. However the accuracy of this approach relieson the availability of highfidelity training data which seldom exists ingeophysical inverse problems due to the heterogeneous structure of the Earth.In addition accurate amortized variational inference requires the observeddata to be drawn from the training data distribution. As such we propose toincrease the resilience of amortized variational inference when faced with datadistribution shift via a physicsbased correction to the conditionalnormalizing flow latent distribution. To accomplish this instead of a standardGaussian latent distribution we parameterize the latent distribution by aGaussian distribution with an unknown mean and diagonal covariance. Theseunknown quantities are then estimated by minimizing the KullbackLeiblerdivergence between the corrected and true posterior distributions. Whilegeneric and applicable to other inverse problems by means of a seismic imagingexample we show that our correction step improves the robustness of amortizedvariational inference with respect to changes in number of source experimentsnoise variance and shifts in the prior distribution. This approach provides aseismic image with limited artifacts and an assessment of its uncertainty withapproximately the same cost as five reversetime migrations.,4
GoalOriented Sensitivity Analysis of Hyperparameters in Deep Learning Tackling new machine learning problems with neural networks always meansoptimizing numerous hyperparameters that define their structure and stronglyimpact their performances. In this work we study the use of goalorientedsensitivity analysis based on the HilbertSchmidt Independence CriterionHSIC for hyperparameter analysis and optimization. Hyperparameters live inspaces that are often complex and awkward. They can be of different naturescategorical discrete boolean continuous interact and haveinterdependencies. All this makes it nontrivial to perform classicalsensitivity analysis. We alleviate these difficulties to obtain a robustanalysis index that is able to quantify hyperparameters relative impact on aneural networks final error. This valuable tool allows us to better understandhyperparameters and to make hyperparameter optimization more interpretable. Weillustrate the benefits of this knowledge in the context of hyperparameteroptimization and derive an HSICbased optimization algorithm that we apply onMNIST and Cifar classical machine learning data sets but also on theapproximation of Runge function and Bateman equations solution of interest forscientific machine learning. This method yields neural networks that are bothcompetitive and costeffective.,4
Efficient Realworld Testing of Causal Decision Making via Bayesian Experimental Design for Contextual Optimisation The realworld testing of decisions made using causal machine learning modelsis an essential prerequisite for their successful application. We focus onevaluating and improving contextual treatment assignment decisions these arepersonalised treatments applied to e.g. customers each with their owncontextual information with the aim of maximising a reward. In this paper weintroduce a modelagnostic framework for gathering data to evaluate and improvecontextual decision making through Bayesian Experimental Design. Specificallyour method is used for the dataefficient evaluation of the regret of pasttreatment assignments. Unlike approaches such as AB testing our method avoidsassigning treatments that are known to be highly suboptimal whilst engagingin some exploration to gather pertinent information. We achieve this byintroducing an informationbased design objective which we optimiseendtoend. Our method applies to discrete and continuous treatments. Comparingour informationtheoretic approach to baselines in several simulation studiesdemonstrates the superior performance of our proposed approach.,4
FACT HighDimensional Random Forests Inference Random forests is one of the most widely used machine learning methods overthe past decade thanks to its outstanding empirical performance. Yet becauseof its blackbox nature the results by random forests can be hard to interpretin many big data applications. Quantifying the usefulness of individualfeatures in random forests learning can greatly enhance its interpretability.Existing studies have shown that some popularly used feature importancemeasures for random forests suffer from the bias issue. In addition there lackcomprehensive size and power analyses for most of these existing methods. Inthis paper we approach the problem via hypothesis testing and suggest aframework of the selfnormalized featureresidual correlation test FACT forevaluating the significance of a given feature in the random forests model withbiasresistance property where our null hypothesis concerns whether thefeature is conditionally independent of the response given all other features.Such an endeavor on random forests inference is empowered by some recentdevelopments on highdimensional random forests consistency. The vanillaversion of our FACT test can suffer from the bias issue in the presence offeature dependency. We exploit the techniques of imbalancing and conditioningfor bias correction. We further incorporate the ensemble idea into the FACTstatistic through feature transformations for the enhanced power. Under afairly general highdimensional nonparametric model setting with dependentfeatures we formally establish that FACT can provide theoretically justifiedrandom forests feature pvalues and enjoy appealing power through nonasymptoticanalyses. The theoretical results and finitesample advantages of the newlysuggested method are illustrated with several simulation examples and aneconomic forecasting application in relation to COVID.,4
A NearOptimal PrimalDual Method for OffPolicy Learning in CMDP As an important framework for safe Reinforcement Learning the ConstrainedMarkov Decision Process CMDP has been extensively studied in the recentliterature. However despite the rich results under various onpolicy learningsettings there still lacks some essential understanding of the offline CMDPproblems in terms of both the algorithm design and the information theoreticsample complexity lower bound. In this paper we focus on solving the CMDPproblems where only offline data are available. By adopting the concept of thesinglepolicy concentrability coefficient C we establish anOmegaleftfracminleftmathcalSmathcalAmathcalSIrightCgammaepsilonright sample complexity lower bound for theoffline CMDP problem where I stands for the number of constraints. Byintroducing a simple but novel deviation control mechanism we propose anearoptimal primaldual learning algorithm called DPDL. This algorithmprovably guarantees zero constraint violation and its sample complexity matchesthe above lower bound except for an tildemathcalOgammafactor. Comprehensive discussion on how to deal with the unknown constant Cand the potential asynchronous structure on the offline dataset are alsoincluded.,4
Multiple Robust Learning for Recommendation In recommender systems a common problem is the presence of various biases inthe collected data which deteriorates the generalization ability of therecommendation models and leads to inaccurate predictions. Doubly robust DRlearning has been studied in many tasks in RS with the advantage that unbiasedlearning can be achieved when either a single imputation or a single propensitymodel is accurate. In this paper we propose a multiple robust MR estimatorthat can take the advantage of multiple candidate imputation and propensitymodels to achieve unbiasedness. Specifically the MR estimator is unbiased whenany of the imputation or propensity models or a linear combination of thesemodels is accurate. Theoretical analysis shows that the proposed MR is anenhanced version of DR when only having a single imputation and propensitymodel and has a smaller bias. Inspired by the generalization error bound ofMR we further propose a novel multiple robust learning approach withstabilization. We conduct extensive experiments on realworld andsemisynthetic datasets which demonstrates the superiority of the proposedapproach over stateoftheart methods.,4
Using ModelBased Trees with Boosting to Fit LowOrder Functional ANOVA Models Loworder functional ANOVA fANOVA models have been rediscovered in themachine learning ML community under the guise of inherently interpretablemachine learning. Explainable Boosting Machines or EBM Lou et al.  andGAMINet Yang et al.  are two recently proposed ML algorithms for fittingfunctional main effects and secondorder interactions. We propose a newalgorithm called GAMITree that is similar to EBM but has a number offeatures that lead to better performance. It uses modelbased trees as baselearners and incorporates a new interaction filtering method that is better atcapturing the underlying interactions. In addition our iterative trainingmethod converges to a model with better predictive performance and theembedded purification ensures that interactions are hierarchically orthogonalto main effects. The algorithm does not need extensive tuning and ourimplementation is fast and efficient. We use simulated and real datasets tocompare the performance and interpretability of GAMITree with EBM andGAMINet.,4
A Forward Propagation Algorithm for Online Optimization of Nonlinear Stochastic Differential Equations Optimizing over the stationary distribution of stochastic differentialequations SDEs is computationally challenging. A new forward propagationalgorithm has been recently proposed for the online optimization of SDEs. Thealgorithm solves an SDE derived using forward differentiation which providesa stochastic estimate for the gradient. The algorithm continuously updates theSDE models parameters and the gradient estimate simultaneously. This paperstudies the convergence of the forward propagation algorithm for nonlineardissipative SDEs. We leverage the ergodicity of this class of nonlinear SDEs tocharacterize the convergence rate of the transition semigroup and itsderivatives. Then we prove bounds on the solution of a Poisson partialdifferential equation PDE for the expected time integral of the algorithmsstochastic fluctuations around the direction of steepest descent. We thenrewrite the algorithm using the PDE solution which allows us to characterizethe parameter evolution around the direction of steepest descent. Our mainresult is a convergence theorem for the forward propagation algorithm fornonlinear dissipative SDEs.,4
Unsupervised learning of observation functions in statespace models by nonparametric moment methods We investigate the unsupervised learning of noninvertible observationfunctions in nonlinear statespace models. Assuming abundant data of theobservation process along with the distribution of the state process weintroduce a nonparametric generalized moment method to estimate the observationfunction via constrained regression. The major challenge comes from thenoninvertibility of the observation function and the lack of data pairsbetween the state and observation. We address the fundamental issue ofidentifiability from quadratic loss functionals and show that the functionspace of identifiability is the closure of a RKHS that is intrinsic to thestate process. Numerical results show that the first two moments and temporalcorrelations along with upper and lower bounds can identify functions rangingfrom piecewise polynomials to smooth functions leading to convergentestimators. The limitations of this method such as nonidentifiability due tosymmetry and stationarity are also discussed.,4
Parallel APSM for Fast and Adaptive Digital SIC in FullDuplex Transceivers with Nonlinearity This paper presents a kernelbased adaptive filter that is applied for thedigital domain selfinterference cancellation SIC in a transceiver operatingin fullduplex FD mode. In FD the benefit of simultaneous transmission andreceiving of signals comes at the price of strong selfinterference SI. Inthis work we are primarily interested in suppressing the SI using an adaptivefilter namely adaptive projected subgradient method APSM in a reproducingkernel Hilbert space RKHS of functions. Using the projection concept as apowerful tool APSM is used to model and consequently remove the SI. Alowcomplexity and fasttracking algorithm is provided taking advantage ofparallel projections as well as the kernel trick in RKHS. The performance ofthe proposed method is evaluated on real measurement data. The methodillustrates the good performance of the proposed adaptive filter compared tothe known popular benchmarks. They demonstrate that the kernelbased algorithmachieves a favorable level of digital SIC while enabling parallelcomputationbased implementation within a rich and nonlinear function spacethanks to the employed adaptive filtering method.,4
Black and Gray Box Learning of Amplitude Equations Application to Phase Field Systems We present a datadriven approach to learning surrogate models for amplitudeequations and illustrate its application to interfacial dynamics of phasefield systems. In particular we demonstrate learning effective partialdifferential equations describing the evolution of phase field interfaces fromfull phase field data. We illustrate this on a model phase field system whereanalytical approximate equations for the dynamics of the phase field interfacea higher order eikonal equation and its approximation the KardarParisiZhangKPZ equation are known. For this system we discuss datadriven approachesfor the identification of equations that accurately describe the frontinterface dynamics. When the analytical approximate models mentioned abovebecome inaccurate as we move beyond the region of validity of the underlyingassumptions the datadriven equations outperform them. In these regimes goingbeyond blackbox identification we explore different approaches to learndatadriven corrections to the analytically approximate models leading toeffective gray box partial differential equations.,4
Statistical and Computational Tradeoffs in Variational Inference A Case Study in Inferential Model Selection Variational inference has recently emerged as a popular alternative to theclassical Markov chain Monte Carlo MCMC in largescale Bayesian inference.The core idea of variational inference is to trade statistical accuracy forcomputational efficiency. It aims to approximate the posterior reducingcomputation costs but potentially compromising its statistical accuracy. Inthis work we study this statistical and computational tradeoff in variationalinference via a case study in inferential model selection. Focusing on Gaussianinferential models a.k.a. variational approximating families with diagonalplus lowrank precision matrices we initiate a theoretical study of thetradeoffs in two aspects Bayesian posterior inference error and frequentistuncertainty quantification error. From the Bayesian posterior inferenceperspective we characterize the error of the variational posterior relative tothe exact posterior. We prove that given a fixed computation budget alowerrank inferential model produces variational posteriors with a higherstatistical approximation error but a lower computational error it reducesvariances in stochastic optimization and in turn accelerates convergence.From the frequentist uncertainty quantification perspective we consider theprecision matrix of the variational posterior as an uncertainty estimate. Wefind that relative to the true asymptotic precision the variationalapproximation suffers from an additional statistical error originating from thesampling uncertainty of the data. Moreover this statistical error becomes thedominant factor as the computation budget increases. As a consequence forsmall datasets the inferential model need not be fullrank to achieve optimalestimation error. We finally demonstrate these statistical and computationaltradeoffs inference across empirical studies corroborating the theoreticalfindings.,4
Local manifold learning and its link to domainbased physics knowledge In many reacting flow systems the thermochemical statespace is known orassumed to evolve close to a lowdimensional manifold LDM. Various approachesare available to obtain those manifolds and subsequently express the originalhighdimensional space with fewer parameterizing variables. Principal componentanalysis PCA is one of the dimensionality reduction methods that can be usedto obtain LDMs. PCA does not make prior assumptions about the parameterizingvariables and retrieves them empirically from the training data. In this paperwe show that PCA applied in local clusters of data local PCA is capable ofdetecting the intrinsic parameterization of the thermochemical statespace. Wefirst demonstrate that utilizing three common combustion models of varyingcomplexity the BurkeSchumann model the chemical equilibrium model and thehomogeneous reactor. Parameterization of these models is known a priori whichallows for benchmarking with the local PCA approach. We further extend theapplication of local PCA to a more challenging case of a turbulent nonpremixednheptaneair jet flame for which the parameterization is no longer obvious.Our results suggest that meaningful parameterization can be obtained also formore complex datasets. We show that local PCA finds variables that can belinked to local stoichiometry reaction progress and soot formation processes.,4
A NewtonCG based barrier method for finding a secondorder stationary point of nonconvex conic optimization with complexity guarantees In this paper we consider finding an approximate secondorder stationarypoint SOSP of nonconvex conic optimization that minimizes a twicedifferentiable function over the intersection of an affine subspace and aconvex cone. In particular we propose a Newtonconjugate gradient NewtonCGbased barrier method for finding an epsilonsqrtepsilonSOSP of thisproblem. Our method is not only implementable but also achieves an iterationcomplexity of cal Oepsilon which matches the best knowniteration complexity of secondorder methods for finding anepsilonsqrtepsilonSOSP of unconstrained nonconvex optimization. Theoperation complexity of widetildecalOepsilonminnepsilon measured by the amount offundamental operations is also established for our method.,4
Variational Flow Graphical Model This paper introduces a novel approach to embed flowbased models withhierarchical structures. The proposed framework is named Variational FlowGraphical VFG Model. VFGs learn the representation of high dimensional datavia a messagepassing scheme by integrating flowbased functions throughvariational inference. By leveraging the expressive power of neural networksVFGs produce a representation of the data using a lower dimension thusovercoming the drawbacks of many flowbased models usually requiring a highdimensional latent space involving many trivial variables. Aggregation nodesare introduced in the VFG models to integrate forwardbackward hierarchicalinformation via a message passing scheme. Maximizing the evidence lower boundELBO of data likelihood aligns the forward and backward messages in eachaggregation node achieving a consistency node state. Algorithms have beendeveloped to learn model parameters through gradient updating regarding theELBO objective.,4
FutureDependent ValueBased OffPolicy Evaluation in POMDPs We study offpolicy evaluation OPE for partially observable MDPs POMDPswith general function approximation. Existing methods such as sequentialimportance sampling estimators and fittedQ evaluation suffer from the curse ofhorizon in POMDPs. To circumvent this problem we develop a novel modelfreeOPE method by introducing futuredependent value functions that take futureproxies as inputs. Futuredependent value functions play similar roles asclassical value functions in fullyobservable MDPs. We derive a new Bellmanequation for futuredependent value functions as conditional moment equationsthat use history proxies as instrumental variables. We further propose aminimax learning method to learn futuredependent value functions using the newBellman equation. We obtain the PAC result which implies our OPE estimator isconsistent as long as futures and histories contain sufficient informationabout latent states and the Bellman completeness. Finally we extend ourmethods to learning of dynamics and establish the connection between ourapproach and the wellknown spectral learning methods in POMDPs.,4
Fully Decentralized Modelbased Policy Optimization for Networked Systems Reinforcement learning algorithms require a large amount of samples thisoften limits their realworld applications on even simple tasks. Such achallenge is more outstanding in multiagent tasks as each step of operationis more costly requiring communications or shifting or resources. This workaims to improve data efficiency of multiagent control by modelbased learning.We consider networked systems where agents are cooperative and communicate onlylocally with their neighbors and propose the decentralized modelbased policyoptimization framework DMPO. In our method each agent learns a dynamic modelto predict future states and broadcast their predictions by communication andthen the policies are trained under the model rollouts. To alleviate the biasof modelgenerated data we restrain the model usage for generating myopicrollouts thus reducing the compounding error of model generation. To pertainthe independence of policy update we introduce extended value function andtheoretically prove that the resulting policy gradient is a close approximationto true policy gradients. We evaluate our algorithm on several benchmarks forintelligent transportation systems which are connected autonomous vehiclecontrol tasks Flow and CACC and adaptive traffic signal control ATSC.Empirically results show that our method achieves superior data efficiency andmatches the performance of modelfree methods using true models.,4
Adversarial SignCorrupted Isotonic Regression Classical univariate isotonic regression involves nonparametric estimationunder a monotonicity constraint of the true signal. We consider a variation ofthis generating process which we term adversarial signcorrupted isotonictextttASCI regression. Under this textttASCI setting the adversary hasfull access to the true isotonic responses and is free to signcorrupt them.Estimating the true monotonic signal given these signcorrupted responses is ahighly challenging task. Notably the signcorruptions are designed to violatemonotonicity and possibly induce heavy dependence between the corruptedresponse terms. In this sense textttASCI regression may be viewed as anadversarial stress test for isotonic regression. Our motivation is driven byunderstanding whether efficient robust estimation of the monotone signal isfeasible under this adversarial setting. We develop textttASCIFIT athreestep estimation procedure under the textttASCI setting. ThetextttASCIFIT procedure is conceptually simple easy to implement withexisting software and consists of applying the textttPAVA with crucial preand postprocessing corrections. We formalize this procedure and demonstrateits theoretical guarantees in the form of sharp high probability upper boundsand minimax lower bounds. We illustrate our findings with detailed simulations.,4
An Asymmetric Contrastive Loss for Handling Imbalanced Datasets Contrastive learning is a representation learning method performed bycontrasting a sample to other similar samples so that they are brought closelytogether forming clusters in the feature space. The learning process istypically conducted using a twostage training architecture and it utilizesthe contrastive loss CL for its feature learning. Contrastive learning hasbeen shown to be quite successful in handling imbalanced datasets in whichsome classes are overrepresented while some others are underrepresented.However previous studies have not specifically modified CL for imbalanceddatasets. In this work we introduce an asymmetric version of CL referred toas ACL in order to directly address the problem of class imbalance. Inaddition we propose the asymmetric focal contrastive loss AFCL as a furthergeneralization of both ACL and focal contrastive loss FCL. Results on theFMNIST and ISIC  imbalanced datasets show that AFCL is capable ofoutperforming CL and FCL in terms of both weighted and unweightedclassification accuracies. In the appendix we provide a full axiomatictreatment on entropy along with complete proofs.,4
Ultralow latency recurrent neural network inference on FPGAs for physics applications with hlsml Recurrent neural networks have been shown to be effective architectures formany tasks in high energy physics and thus have been widely adopted. Their usein lowlatency environments has however been limited as a result of thedifficulties of implementing recurrent architectures on fieldprogrammable gatearrays FPGAs. In this paper we present an implementation of two types ofrecurrent neural network layers  long shortterm memory and gated recurrentunit  within the hlsml framework. We demonstrate that our implementation iscapable of producing effective designs for both small and large models and canbe customized to meet specific design requirements for inference latencies andFPGA resources. We show the performance and synthesized designs for multipleneural networks many of which are trained specifically for jet identificationtasks at the CERN Large Hadron Collider.,4
Improved conformalized quantile regression Conformalized quantile regression is a procedure that inherits the advantagesof conformal prediction and quantile regression. That is we use quantileregression to estimate the true conditional quantile and then apply a conformalstep on a calibration set to ensure marginal coverage. In this way we getadaptive prediction intervals that account for heteroscedasticity. However theaforementioned conformal step lacks adaptiveness as described in Romano etal. . To overcome this limitation instead of applying a single conformalstep after estimating conditional quantiles with quantile regression wepropose to cluster the explanatory variables weighted by their permutationimportance with an optimized kmeans and apply k conformal steps. To show thatthis improved version outperforms the classic version of conformalized quantileregression and is more adaptive to heteroscedasticity we extensively comparethe prediction intervals of both in open datasets.,4
Hindsight Learning for MDPs with Exogenous Inputs We develop a reinforcement learning RL framework for applications that dealwith sequential decisions and exogenous uncertainty such as resourceallocation and inventory management. In these applications the uncertainty isonly due to exogenous variables like future demands. A popular approach is topredict the exogenous variables using historical data and then plan with thepredictions. However this indirect approach requires highfidelity modeling ofthe exogenous process to guarantee good downstream decisionmaking which canbe impractical when the exogenous process is complex. In this work we proposean alternative approach based on hindsight learning which sidesteps modelingthe exogenous process. Our key insight is that unlike SimReal RL we canrevisit past decisions in the historical data and derive counterfactualconsequences for other actions in these applications. Our framework useshindsightoptimal actions as the policy training signal and has strongtheoretical guarantees on decisionmaking performance. We develop an algorithmusing our framework to allocate compute resources for realworld MicrosoftAzure workloads. The results show our approach learns better policies thandomainspecific heuristics and SimReal RL baselines.,4
Estimating Classification Confidence Using Kernel Densities This paper investigates the posthoc calibration of confidence forexploratory machine learning classification problems. The difficulty in theseproblems stems from the continuing desire to push the boundaries of whichcategories have enough examples to generalize from when curating datasets andconfusion regarding the validity of those categories. We argue that for suchproblems the oneversusall approach toplabel calibration must be usedrather than the calibratethefullresponsematrix approach advocatedelsewhere in the literature. We introduce and test four new algorithms designedto handle the idiosyncrasies of categoryspecific confidence estimation. Chiefamong these methods is the use of kernel density ratios for confidencecalibration including a novel bulletproof algorithm for choosing thebandwidth. We test our claims and explore the limits of calibration on abioinformatics application PhANNs as well as the classic MNIST benchmark.Finally our analysis argues that posthoc calibration should always beperformed should be based only on the test dataset and should besanitychecked visually.,4
BRSNIS Bias Reduced SelfNormalized Importance Sampling Importance Sampling IS is a method for approximating expectations under atarget distribution using independent samples from a proposal distribution andthe associated importance weights. In many applications the targetdistribution is known only up to a normalization constant in which caseselfnormalized IS SNIS can be used. While the use of selfnormalization canhave a positive effect on the dispersion of the estimator it introduces bias.In this work we propose a new method BRSNIS whose complexity is essentiallythe same as that of SNIS and which significantly reduces bias withoutincreasing the variance. This method is a wrapper in the sense that it uses thesame proposal samples and importance weights as SNIS but makes clever use ofiterated samplingimportance resampling ISIR to form a biasreduced versionof the estimator. We furnish the proposed algorithm with rigorous theoreticalresults including new bias variance and highprobability bounds and theseare illustrated by numerical examples.,4
Instanceoptimal PAC Algorithms for Contextual Bandits In the stochastic contextual bandit setting regretminimizing algorithmshave been extensively researched but their instanceminimizing bestarmidentification counterparts remain seldom studied. In this work we focus onthe stochastic bandit problem in the epsilondeltatextitPACsetting given a policy class Pi the goal of the learner is to return apolicy piin Pi whose expected reward is within epsilon of the optimalpolicy with probability greater than delta. We characterize the firsttextitinstancedependent PAC sample complexity of contextual banditsthrough a quantity rhoPi and provide matching upper and lower bounds interms of rhoPi for the agnostic and linear contextual bestarmidentification settings. We show that no algorithm can be simultaneouslyminimaxoptimal for regret minimization and instancedependent PAC for bestarmidentification. Our main result is a new instanceoptimal and computationallyefficient algorithm that relies on a polynomial number of calls to an argmaxoracle.,4
Modeling Randomly Walking Volatility with Chained Gamma Distributions Volatility clustering is a common phenomenon in financial time series.Typically linear models can be used to describe the temporal autocorrelationof the logarithmic variance of returns. Considering the difficulty inestimating this model we construct a Dynamic Bayesian Network which utilizesthe conjugate prior relation of normalgamma and gammagamma so that itsposterior form locally remains unchanged at each node. This makes it possibleto find approximate solutions using variational methods quickly. Furthermorewe ensure that the volatility expressed by the model is an independentincremental process after inserting dummy gamma nodes between adjacent timesteps. We have found that this model has two advantages  It can be provedthat it can express heavier tails than Gaussians i.e. have positive excesskurtosis compared to popular linear models.  If the variationalinferenceVI is used for state estimation it runs much faster than MonteCarloMC methods since the calculation of the posterior uses only basicarithmetic operations. And its convergence process is deterministic.,4
Twitmo A Twitter Data Topic Modeling and Visualization Package for R We present Twitmo a package that provides a broad range of methods tocollect preprocess analyze and visualize geotagged Twitter data. Twitmoenables the user to collect geotagged Tweets from Twitter and and provides acomprehensive and userfriendly toolbox to generate topic distributions fromLatent Dirichlet Allocations LDA correlated topic models CTM andstructural topic models STM. Functions are included for preprocessing oftext model building and prediction. In addition one of the innovations of thepackage is the automatic pooling of Tweets into longer pseudodocuments usinghashtags and cosine similarities for better topic coherence. The packageadditionally comes with functionality to visualize collected data sets andfitted models in static as well as interactive ways and offers builtin supportfor model visualizations via LDAvis providing great convenience for researchersin this area. The Twitmo package is an innovative toolbox that can be used toanalyze public discourse of various topics political parties or persons ofinterest in space and time.,4
Subgraph Frequency Distribution Estimation using Graph Neural Networks Small subgraphs graphlets are important features to describe fundamentalunits of a large network. The calculation of the subgraph frequencydistributions has a wide application in multiple domains including biology andengineering. Unfortunately due to the inherent complexity of this task most ofthe existing methods are computationally intensive and inefficient. In thiswork we propose GNNS a novel representational learning framework thatutilizes graph neural networks to sample subgraphs efficiently for estimatingtheir frequency distribution. Our framework includes an inference model and agenerative model that learns hierarchical embeddings of nodes subgraphs andgraph types. With the learned model and embeddings subgraphs are sampled in ahighly scalable and parallel way and the frequency distribution estimation isthen performed based on these sampled subgraphs. Eventually our methodsachieve comparable accuracy and a significant speedup by three orders ofmagnitude compared to existing methods.,4
Matching Normalizing Flows and Probability Paths on Manifolds Continuous Normalizing Flows CNFs are a class of generative models thattransform a prior distribution to a model distribution by solving an ordinarydifferential equation ODE. We propose to train CNFs on manifolds byminimizing probability path divergence PPD a novel family of divergencesbetween the probability density path generated by the CNF and a targetprobability density path. PPD is formulated using a logarithmic massconservation formula which is a linear first order partial differentialequation relating the log target probabilities and the CNFs defining vectorfield. PPD has several key benefits over existing methods it sidesteps theneed to solve an ODE per iteration readily applies to manifold data scales tohigh dimensions and is compatible with a large family of target pathsinterpolating pure noise and data in finite time. Theoretically PPD is shownto bound classical probability divergences. Empirically we show that CNFslearned by minimizing PPD achieve stateoftheart results in likelihoods andsample quality on existing lowdimensional manifold benchmarks and is thefirst example of a generative model to scale to moderately high dimensionalmanifolds.,4
Making Linear MDPs Practical via Contrastive Representation Learning It is common to address the curse of dimensionality in Markov decisionprocesses MDPs by exploiting lowrank representations. This motivates much ofthe recent theoretical study on linear MDPs. However most approaches require agiven representation under unrealistic assumptions about the normalization ofthe decomposition or introduce unresolved computational challenges in practice.Instead we consider an alternative definition of linear MDPs thatautomatically ensures normalization while allowing efficient representationlearning via contrastive estimation. The framework also admitsconfidenceadjusted index algorithms enabling an efficient and principledapproach to incorporating optimism or pessimism in the face of uncertainty. Tothe best of our knowledge this provides the first practical representationlearning method for linear MDPs that achieves both strong theoreticalguarantees and empirical performance. Theoretically we prove that the proposedalgorithm is sample efficient in both the online and offline settings.Empirically we demonstrate superior performance over existing stateoftheartmodelbased and modelfree algorithms on several benchmarks.,4
A Federated Cox Model with NonProportional Hazards Recent research has shown the potential for neural networks to improve uponclassical survival models such as the Cox model which is widely used inclinical practice. Neural networks however typically rely on data that arecentrally available whereas healthcare data are frequently held in securesilos. We present a federated Cox model that accommodates this data setting andalso relaxes the proportional hazards assumption allowing timevaryingcovariate effects. In this latter respect our model does not require explicitspecification of the timevarying effects reducing upfront organisationalcosts compared to previous works. We experiment with publicly availableclinical datasets and demonstrate that the federated model is able to performas well as a standard model.,4
Characterizing the Effect of Class Imbalance on the Learning Dynamics Data imbalance is a common problem in the machine learning literature thatcan have a critical effect on the performance of a model. Various solutionsexist  such as the ones that focus on resampling or data generation  buttheir impact on the convergence of gradientbased optimizers used in deeplearning is not understood. We here elucidate the significant negative impactof data imbalance on learning showing that the learning curves for minorityand majority classes follow suboptimal trajectories when training with agradientbased optimizer. The reason is not only that the gradient signalneglects the minority classes but also that the minority classes are subjectto a larger directional noise which slows their learning by an amount relatedto the imbalance ratio. To address this problem we propose a new algorithmicsolution for which we provide a detailed analysis of its convergence behavior.We show both theoretically and empirically that this new algorithm exhibits abetter behavior with more stable learning curves for each class as well as abetter generalization performance.,4
Look beyond labels Incorporating functional summary information in Bayesian neural networks Bayesian deep learning offers a principled approach to train neural networksthat accounts for both aleatoric and epistemic uncertainty. In variationalinference priors are often specified over the weight parameters but they donot capture the true prior knowledge in large and complex neural networkarchitectures. We present a simple approach to incorporate summary informationabout the predicted probability such as sigmoid or softmax score outputs inBayesian neural networks BNNs. The available summary information isincorporated as augmented data and modeled with a Dirichlet process and wederive the corresponding emphSummary Evidence Lower BOund. We show how themethod can inform the model about task difficulty or class imbalance. Extensiveempirical experiments show that with negligible computational overhead theproposed method yields a BNN with a better calibration of uncertainty.,4
FeedForward SourceFree Latent Domain Adaptation via CrossAttention We study the highly practical but comparatively understudied problem oflatentdomain adaptation where a source model should be adapted to a targetdataset that contains a mixture of unlabelled domainrelevant anddomainirrelevant examples. Furthermore motivated by the requirements for dataprivacy and the need for embedded and resourceconstrained devices of all kindsto adapt to local data distributions we focus on the setting of feedforwardsourcefree domain adaptation where adaptation should not require access tothe source dataset and also be back propagationfree. Our solution is tometalearn a network capable of embedding the mixedrelevance target datasetand dynamically adapting inference for target examples using crossattention.The resulting framework leads to consistent improvement on strong ERMbaselines. We also show that our framework sometimes even improves on the upperbound of domainsupervised adaptation where only domainrelevant instances areprovided for adaptation. This suggests that human annotated domain labels maynot always be optimal and raises the possibility of doing better throughautomated instance selection.,4
VTrackIt A Synthetic SelfDriving Dataset with Infrastructure and Pooled Vehicle Information Artificial intelligence solutions for Autonomous Vehicles AVs have beendeveloped using publicly available datasets such as Argoverse ApolloScapeLevel and NuScenes. One major limitation of these datasets is the absence ofinfrastructure andor pooled vehicle information like lane line type vehiclespeed traffic signs and intersections. Such information is necessary and notcomplementary to eliminating highrisk edge cases. The rapid advancements inVehicletoInfrastructure and VehicletoVehicle technologies show promise thatinfrastructure and pooled vehicle information will soon be accessible in nearrealtime. Taking a leap in the future we introduce the first comprehensivesynthetic dataset with intelligent infrastructure and pooled vehicleinformation for advancing the next generation of AVs named VTrackIt. We alsointroduce the first deep learning model InfraGAN for trajectory predictionsthat considers such information. Our experiments with InfraGAN show that thecomprehensive information offered by VTrackIt reduces the number of highriskedge cases. The VTrackIt dataset is available upon request under the CreativeCommons CC BYNCSA . license at httpvtrackit.irda.club.,4
When does SGD favor flat minima A quantitative characterization via linear stability The observation that stochastic gradient descent SGD favors flat minima hasplayed a fundamental role in understanding implicit regularization of SGD andguiding the tuning of hyperparameters. In this paper we provide a quantitativeexplanation of this striking phenomenon by relating the particular noisestructure of SGD to its emphlinear stability Wu et al. .Specifically we consider training overparameterized models with square loss.We prove that if a global minimum theta is linearly stable for SGD thenit must satisfy HthetaFleq OsqrtBeta whereHthetaF Beta denote the Frobenius norm of Hessian at thetabatch size and learning rate respectively. Otherwise SGD will escape fromthat minimum emphexponentially fast. Hence for minima accessible to SGDthe flatness  as measured by the Frobenius norm of the Hessian  is boundedindependently of the model size and sample size. The key to obtaining theseresults is exploiting the particular geometry awareness of SGD noise  thenoise magnitude is proportional to loss value  the noise directionsconcentrate in the sharp directions of local landscape. This property of SGDnoise provably holds for linear networks and random feature models RFMs andis empirically verified for nonlinear networks. Moreover the validity andpractical relevance of our theoretical findings are justified by extensivenumerical experiments.,4
KullbackLeibler and Renyi divergences in reproducing kernel Hilbert space and Gaussian process settings In this work we present formulations for regularized KullbackLeibler andRnyi divergences via the Alpha LogDeterminant LogDet divergences betweenpositive HilbertSchmidt operators on Hilbert spaces in two different settingsnamely i covariance operators and Gaussian measures defined on reproducingkernel Hilbert spaces RKHS and ii Gaussian processes with squaredintegrable sample paths. For characteristic kernels the first setting leads todivergences between arbitrary Borel probability measures on a completeseparable metric space. We show that the Alpha LogDet divergences arecontinuous in the HilbertSchmidt norm which enables us to apply laws of largenumbers for Hilbert spacevalued random variables. As a consequence of this weshow that in both settings the infinitedimensional divergences can beconsistently and efficiently estimated from their finitedimensional versionsusing finitedimensional Gram matricesGaussian measures and finite sampledata with it dimensionindependent sample complexities in all cases. RKHSmethodology plays a central role in the theoretical analysis in both settings.The mathematical formulation is illustrated by numerical experiments.,4
The Cosmic Graph Optimal Information Extraction from LargeScale Structure using Catalogues We present an implicit likelihood approach to quantifying cosmologicalinformation over discrete catalogue data assembled as graphs. To do so weexplore cosmological inference using mock dark matter halo catalogues. Weemploy Information Maximising Neural Networks IMNNs to quantify Fisherinformation extraction as a function of graph representation. We a demonstratethe high sensitivity of modular graph structure to the underlying cosmology inthe noisefree limit b show that networks automatically combine mass andclustering information through comparisons to traditional statistics cdemonstrate that graph neural networks can still extract information whencatalogues are subject to noisy survey cuts and d illustrate how nonlinearIMNN summaries can be used as asymptotically optimal compressed statistics forBayesian implicit likelihood inference. We reduce the area of joint Omegamsigma parameter constraints with small sim object halo cataloguesby a factor of  over the twopoint correlation function and demonstrate thatthe networks automatically combine mass and clustering information. This workutilises a new IMNN implementation over graph data in Jax which can takeadvantage of either numerical or autodifferentiability. We also show thatgraph IMNNs successfully compress simulations far from the fiducial model atwhich the network is fitted indicating a promising alternative to npointstatistics in cataloguebased analyses.,4
The Union of Manifolds Hypothesis and its Implications for Deep Generative Modelling Deep learning has had tremendous success at learning lowdimensionalrepresentations of highdimensional data. This success would be impossible ifthere was no hidden lowdimensional structure in data of interest thisexistence is posited by the manifold hypothesis which states that the datalies on an unknown manifold of low intrinsic dimension. In this paper we arguethat this hypothesis does not properly capture the lowdimensional structuretypically present in data. Assuming the data lies on a single manifold impliesintrinsic dimension is identical across the entire data space and does notallow for subregions of this space to have a different number of factors ofvariation. To address this deficiency we put forth the union of manifoldshypothesis which accommodates the existence of nonconstant intrinsicdimensions. We empirically verify this hypothesis on commonlyused imagedatasets finding that indeed intrinsic dimension should be allowed to vary.We also show that classes with higher intrinsic dimensions are harder toclassify and how this insight can be used to improve classification accuracy.We then turn our attention to the impact of this hypothesis in the context ofdeep generative models DGMs. Most current DGMs struggle to model datasetswith several connected components andor varying intrinsic dimensions. Totackle these shortcomings we propose clustered DGMs where we first clusterthe data and then train a DGM on each cluster. We show that clustered DGMs canmodel multiple connected components with different intrinsic dimensions andempirically outperform their nonclustered counterparts without increasingcomputational requirements.,4
Measuring and signing fairness as performance under multiple stakeholder distributions As learning machines increase their influence on decisions concerning humanlives analyzing their fairness properties becomes a subject of centralimportance. Yet our best tools for measuring the fairness of learning systemsare rigid fairness metrics encapsulated as mathematical oneliners offerlimited power to the stakeholders involved in the prediction task and are easyto manipulate when we exhort excessive pressure to optimize them. To advancethese issues we propose to shift focus from shaping fairness metrics tocurating the distributions of examples under which these are computed. Inparticular we posit that every claim about fairness should be immediatelyfollowed by the tagline Fair under what examples and collected by whom. Byhighlighting connections to the literature in domain generalization we proposeto measure fairness as the ability of the system to generalize under multiplestress tests  distributions of examples with social relevance. We encourageeach stakeholder to curate one or multiple stress tests containing examplesreflecting their possibly conflicting interests. The machine passes or failseach stress test by falling short of or exceeding a predefined metric value.The test results involve all stakeholders in a discussion about how to improvethe learning system and provide flexible assessments of fairness dependent oncontext and based on interpretable data. We provide full implementationguidelines for stress testing illustrate both the benefits and shortcomings ofthis framework and introduce a cryptographic scheme to enable a degree ofprediction accountability from system providers.,4
Pavlov Learning Machines As well known Hebbs learning traces its origin in Pavlovs ClassicalConditioning however while the former has been extensively modelled in thepast decades e.g. by Hopfield model and countless variations on theme asfor the latter modelling has remained largely unaddressed so far further abridge between these two pillars is totally lacking. The main difficultytowards this goal lays in the intrinsically different scales of the informationinvolved Pavlovs theory is about correlations among emphconcepts that aredynamically stored in the synaptic matrix as exemplified by the celebratedexperiment starring a dog and a ring bell conversely Hebbs theory is aboutcorrelations among pairs of adjacent neurons as summarized by the famousstatement em neurons that fire together wire together. In this paper we relyon stochasticprocess theory and model neural and synaptic dynamics viaLangevin equations to prove that  as long as we keep neurons and synapsestimescales largely split  Pavlov mechanism spontaneously takes place andultimately gives rise to synaptic weights that recover the Hebbian kernel.,4
Edge Augmentation on Disconnected Graphs via Eigenvalue Elevation The graphtheoretical task of determining most likely intercommunity edgesbased on disconnected subgraphs intracommunity connectivity is proposed. Analgorithm is developed for this edge augmentation task based on elevating thezero eigenvalues of graphs spectrum. Upper bounds for eigenvalue elevationamplitude and for the corresponding augmented edge density are derived and areauthenticated with simulation on random graphs. The algorithm worksconsistently across synthetic and real networks yielding desirable performanceat connecting graph components. Edge augmentation reverseengineers graphpartition under different community detection methods GirvanNewman methodgreedy modularity maximization label propagation Louvain method and fluidcommunity in most cases producing intercommunity edges at  frequency.,4
PASHA Efficient HPO with Progressive Resource Allocation Hyperparameter optimization HPO and neural architecture search NAS aremethods of choice to obtain the bestinclass machine learning models but inpractice they can be costly to run. When models are trained on large datasetstuning them with HPO or NAS rapidly becomes prohibitively expensive forpractitioners even when efficient multifidelity methods are employed. Wepropose an approach to tackle the challenge of tuning machine learning modelstrained on large datasets with limited computational resources. Our approachnamed PASHA is able to dynamically allocate maximum resources for the tuningprocedure depending on the need. The experimental comparison shows that PASHAidentifies wellperforming hyperparameter configurations and architectureswhile consuming significantly fewer computational resources than solutions likeASHA.,4
Discrimination in machine learning algorithms Machine learning algorithms are routinely used for business decisions thatmay directly affect individuals for example because a credit scoringalgorithm refuses them a loan. It is then relevant from an ethical and legalpoint of view to ensure that these algorithms do not discriminate based onsensitive attributes like sex or race which may occur unwittingly andunknowingly by the operator and the management. Statistical tools and methodsare then required to detect and eliminate such potential biases.,4
LETSGZSL A Latent Embedding Model for Time Series Generalized Zero Shot Learning One of the recent developments in deep learning is generalized zeroshotlearning GZSL which aims to recognize objects from both seen and unseenclasses when only the labeled examples from seen classes are provided. Overthe past couple of years GZSL has picked up traction and several models havebeen proposed to solve this problem. Whereas an extensive amount of research onGZSL has been carried out in fields such as computer vision and naturallanguage processing no such research has been carried out to deal with timeseries data. GZSL is used for applications such as detecting abnormalities fromECG and EEG data and identifying unseen classes from sensor spectrograph andother devices data. In this regard we propose a Latent Embedding for TimeSeries  GZSL LETSGZSL model that can solve the problem of GZSL for timeseries classification TSC. We utilize an embeddingbased approach and combineit with attribute vectors to predict the final class labels. We report ourresults on the widely popular UCR archive datasets. Our framework is able toachieve a harmonic mean value of at least  on most of the datasets exceptwhen the number of unseen classes is greater than  or the amount of data isvery low less than  training examples.,4
Markovian Gaussian Process Variational Autoencoders Deep generative models are widely used for modelling highdimensional timeseries such as video animations audio and climate data. Sequentialvariational autoencoders have been successfully considered for manyapplications with many variant models relying on discretetime methods andrecurrent neural networks RNNs. On the other hand continuoustime methodshave recently gained attraction especially in the context ofirregularlysampled time series where they can better handle the data thandiscretetime methods. One such class are Gaussian process variationalautoencoders GPVAEs where the VAE prior is set as a Gaussian process GPsallowing inductive biases to be explicitly encoded via the kernel function andinterpretability of the latent space. However a major limitation of GPVAEs isthat it inherits the same cubic computational cost as GPs. In this work weleverage the equivalent discrete state space representation of Markovian GPs toenable a lineartime GP solver via Kalman filtering and smoothing. We show viacorrupt and missing frames tasks that our method performs favourablyespecially on the latter where it outperforms RNNbased models.,4
Journal Impact Factor and Peer Review Thoroughness and Helpfulness A Supervised Machine Learning Study The journal impact factor JIF is often equated with journal quality and thequality of the peer review of the papers submitted to the journal. We examinedthe association between the content of peer review and JIF by analysing peer review reports submitted to  medical and life sciences journals. Tworesearchers handcoded a random sample of  sentences. We then trainedmachine learning models to classify all  sentences as contributing ornot contributing to content categories. We examined the association between tengroups of journals defined by JIF deciles and the content of peer reviews usinglinear mixedeffects models adjusting for the length of the review. The JIFranged from . to .. The length of peer reviews increased from the lowestmedian number of words  to the JIF group  words. The proportion ofsentences allocated to different content categories varied widely even withinJIF groups. For thoroughness sentences on Materials and Methods were morecommon in the highest JIF journals than in the lowest JIF group difference of. percentage points  CI . to .. The trend for Presentation andReporting went in the opposite direction with the highest JIF journals givingless emphasis to such content difference .  CI . to .. Forhelpfulness reviews for higher JIF journals devoted less attention toSuggestion and Solution and provided fewer Examples than lower impact factorjournals. No or only small differences were evident for other contentcategories. In conclusion peer review in journals with higher JIF tends to bemore thorough in discussing the methods used but less helpful in terms ofsuggesting solutions and providing examples. Differences were modest andvariability high indicating that the JIF is a bad predictor for the quality ofpeer review of an individual manuscript.,4
Learning structures of the French clinical languagedevelopment and validation of word embedding models using  million clinical reports from electronic health records Background,4
MultiModel Federated Learning with Provable Guarantees Federated Learning FL is a variant of distributed learning where edgedevices collaborate to learn a model without sharing their data with thecentral server or each other. We refer to the process of training multipleindependent models simultaneously in a federated setting using a common pool ofclients as multimodel FL. In this work we propose two variants of the popularFedAvg algorithm for multimodel FL with provable convergence guarantees. Wefurther show that for the same amount of computation multimodel FL can havebetter performance than training each model separately. We supplement ourtheoretical results with experiments in strongly convex convex and nonconvexsettings.,4
Generalized Identifiability Bounds for Mixture Models with Grouped Samples Recent work has shown that finite mixture models with m components areidentifiable while making no assumptions on the mixture components so long asone has access to groups of samples of size m which are known to come fromthe same mixture component. In this work we generalize that result and showthat if every subset of k mixture components of a mixture model are linearlyindependent then that mixture model is identifiable with only mksamples per group. We further show that this value cannot be improved. We provean analogous result for a stronger form of identifiability known asdeterminedness along with a corresponding lower bound. This independenceassumption almost surely holds if mixture components are chosen randomly from akdimensional space. We describe some implications of our results formultinomial mixture models and topic modeling.,4
Shrinkage Estimation of Higher Order Bochner Integrals We consider shrinkage estimation of higher order Hilbert space valued Bochnerintegrals in a nonparametric setting. We propose estimators that shrink theUstatistic estimator of the Bochner integral towards a prespecified targetelement in the Hilbert space. Depending on the degeneracy of the kernel of theUstatistic we construct consistent shrinkage estimators with fast rates ofconvergence and develop oracle inequalities comparing the risks of the theUstatistic estimator and its shrinkage version. Surprisingly we show thatthe shrinkage estimator designed by assuming complete degeneracy of the kernelof the Ustatistic is a consistent estimator even when the kernel is notcomplete degenerate. This work subsumes and improves upon Krikamol et al. JMLR and Zhou et al.  JMVA which only handle mean element andcovariance operator estimation in a reproducing kernel Hilbert space. We alsospecialize our results to normal mean estimation and show that for dge the proposed estimator strictly improves upon the sample mean in terms of themean squared error.,4
Rethinking Optimization with Differentiable Simulation from a Global Perspective Differentiable simulation is a promising toolkit for fast gradientbasedpolicy optimization and system identification. However existing approaches todifferentiable simulation have largely tackled scenarios where obtaining smoothgradients has been relatively easy such as systems with mostly smoothdynamics. In this work we study the challenges that differentiable simulationpresents when it is not feasible to expect that a single descent reaches aglobal optimum which is often a problem in contactrich scenarios. We analyzethe optimization landscapes of diverse scenarios that contain both rigid bodiesand deformable objects. In dynamic environments with highly deformable objectsand fluids differentiable simulators produce rugged landscapes withnonetheless useful gradients in some parts of the space. We propose a methodthat combines Bayesian optimization with semilocal leaps to obtain a globalsearch method that can use gradients effectively while also maintaining robustperformance in regions with noisy gradients. We show that our approachoutperforms several gradientbased and gradientfree baselines on an extensiveset of experiments in simulation and also validate the method usingexperiments with a real robot and deformables. Videos and supplementarymaterials are available at,4
SPRTbased Efficient Best Arm Identification in Stochastic Bandits This paper investigates the best arm identification BAI problem instochastic multiarmed bandits in the fixed confidence setting. The generalclass of the exponential family of bandits is considered. The stateoftheartalgorithms for the exponential family of bandits face computational challenges.To mitigate these challenges a novel framework is proposed which views theBAI problem as sequential hypothesis testing and is amenable to tractableanalysis for the exponential family of bandits. Based on this framework a BAIalgorithm is designed that leverages the canonical sequential probability ratiotests. This algorithm has three features for both settings  its samplecomplexity is asymptotically optimal  it is guaranteed to be deltaPACand  it addresses the computational challenge of the stateoftheartapproaches. Specifically these approaches which are focused only on theGaussian setting require Thompson sampling from the arm that is deemed thebest and a challenger arm. This paper analytically shows that identifying thechallenger is computationally expensive and that the proposed algorithmcircumvents it. Finally numerical experiments are provided to support theanalysis.,4
Classifying Crop Types using Gaussian Bayesian Models and Neural Networks on GHISACONUS USGS data from NASA Hyperspectral Satellite Imagery Hyperspectral Imagining is a type of digital imaging in which each pixelcontains typically hundreds of wavelengths of light providing spectroscopicinformation about the materials present in the pixel. In this paper we provideclassification methods for determining crop type in the USGS GHISACONUS datawhich contains around  pixel spectra from the five major U.S. agriculturalcrops winter wheat rice corn soybeans and cotton collected by the NASAHyperion satellite and includes the spectrum geolocation crop type andstage of growth for each pixel. We apply standard LDA and QDA as well asBayesian custom versions that compute the joint probability of crop type andstage and then the marginal probability for crop type outperforming thenonBayesian methods. We also test a single layer neural network with dropouton the data which performs comparable to LDA and QDA but not as well as theBayesian methods.,4
Homomorphism Autoencoder  Learning Group Structured Representations from Observed Transitions How can we acquire world models that veridically represent the outside worldboth in terms of what is there and in terms of how our actions affect it Canwe acquire such models by interacting with the world and can we statemathematical desiderata for their relationship with a hypothetical realityexisting outside our heads As machine learning is moving towardsrepresentations containing not just observational but also interventionalknowledge we study these problems using tools from representation learning andgroup theory. Under the assumption that our actuators act upon the world wepropose methods to learn internal representations of not just sensoryinformation but also of actions that modify our sensory representations in away that is consistent with the actions and transitions in the world. We use anautoencoder equipped with a group representation linearly acting on its latentspace trained on step reconstruction such as to enforce a suitablehomomorphism property on the group representation. Compared to existing workour approach makes fewer assumptions on the group representation and on whichtransformations the agent can sample from the group. We motivate our methodtheoretically and demonstrate empirically that it can learn the correctrepresentation of the groups and the topology of the environment. We alsocompare its performance in trajectory prediction with previous methods.,4
Contextual Decision Trees Focusing on Random Forests we propose a multiarmed contextual banditrecommendation framework for featurebased selection of a single shallow treeof the learned ensemble. The trained system which works on top of the RandomForest dynamically identifies a base predictor that is responsible forproviding the final output. In this way we obtain local interpretations byobserving the rules of the recommended tree. The carried out experiments revealthat our dynamic method is superior to an independent fitted CART decision treeand comparable to the whole blackbox Random Forest in terms of predictiveperformances.,4
ASR Error Detection via AudioTranscript entailment Despite improved performances of the latest Automatic Speech RecognitionASR systems transcription errors are still unavoidable. These errors canhave a considerable impact in critical domains such as healthcare when used tohelp with clinical documentation. Therefore detecting ASR errors is a criticalfirst step in preventing further error propagation to downstream applications.To this end we propose a novel endtoend approach for ASR error detectionusing audiotranscript entailment. To the best of our knowledge we are thefirst to frame this problem as an endtoend entailment task between the audiosegment and its corresponding transcript segment. Our intuition is that thereshould be a bidirectional entailment between audio and transcript when there isno recognition error and vice versa. The proposed model utilizes an acousticencoder and a linguistic encoder to model the speech and transcriptrespectively. The encoded representations of both modalities are fused topredict the entailment. Since doctorpatient conversations are used in ourexperiments a particular emphasis is placed on medical terms. Our proposedmodel achieves classification error rates CER of . on all transcriptionerrors and  on medical errors specifically leading to improvements upon astrong baseline by  and . respectively.,4
Video Coding Using Learned Latent GAN Compression We propose in this paper a new paradigm for facial video compression. Weleverage the generative capacity of GANs such as StyleGAN to represent andcompress a video including intra and inter compression. Each frame is invertedin the latent space of StyleGAN from which the optimal compression is learned.To do so a diffeomorphic latent representation is learned using a normalizingflows model where an entropy model can be optimized for image coding. Inaddition we propose a new perceptual loss that is more efficient than othercounterparts. Finally an entropy model for video inter coding with residual isalso learned in the previously constructed latent representation. Our methodSGANC is simple faster to train and achieves better results for image andvideo coding compared to stateoftheart codecs such as VTM AV and recentdeep learning techniques. In particular it drastically minimizes perceptualdistortion at low bit rates.,4
MAPIE an opensource library for distributionfree uncertainty quantification Estimating uncertainties associated with the predictions of Machine LearningML models is of crucial importance to assess their robustness and predictivepower. In this submission we introduce MAPIE Model Agnostic PredictionInterval Estimator an opensource Python library that quantifies theuncertainties of ML models for singleoutput regression and multiclassclassification tasks. MAPIE implements conformal prediction methods allowingthe user to easily compute uncertainties with strong theoretical guarantees onthe marginal coverages and with mild assumptions on the model or on theunderlying data distribution. MAPIE is hosted on scikitlearncontrib and isfully scikitlearncompatible. As such it accepts any type of regressor orclassifier coming with a scikitlearn API. The library is available at,4
JAWS Predictive Inference Under Covariate Shift We propose textbfJAWS a series of wrapper methods for distributionfreeuncertainty quantification tasks under covariate shift centered on our coremethod textbfJAW the textbfJAckknife textbfWeighted withlikelihoodratio weights. JAWS also includes computationally efficienttextbfApproximations of JAW using higherorder influence functionstextbfJAWA. Theoretically we show that JAW relaxes the jackknifesassumption of data exchangeability to achieve the same finitesample coverageguarantee even under covariate shift. JAWA further approaches the JAW guaranteein the limit of either the sample size or the influence function order undermild assumptions. Moreover we propose a general approach to repurposing anydistributionfree uncertainty quantification method and its guarantees to thetask of risk assessment a task that generates the estimated probability thatthe true label lies within a userspecified interval. We then proposetextbfJAWR and textbfJAWAR as the repurposed versions of proposedmethods for textbfRisk assessment. Practically JAWS outperform thestateoftheart predictive inference baselines in a variety of biased realworld data sets for both intervalgeneration and riskassessment auditingtasks.,4
ManiFeSt Manifoldbased Feature Selection for Small Data Sets In this paper we present a new method for fewsample supervised featureselection FS. Our method first learns the manifold of the feature space ofeach class using kernels capturing multifeature associations. Then based onRiemannian geometry a composite kernel is computed extracting the differencesbetween the learned feature associations. Finally a FS score based on spectralanalysis is proposed. Considering multifeature associations makes our methodmultivariate by design. This in turn allows for the extraction of the hiddenmanifold underlying the features and avoids overfitting facilitatingfewsample FS. We showcase the efficacy of our method on illustrative examplesand several benchmarks where our method demonstrates higher accuracy inselecting the informative features compared to competing methods. In additionwe show that our FS leads to improved classification and better generalizationwhen applied to test data.,4
Representing Random Utility Choice Models with Neural Networks Motivated by the successes of deep learning we propose a class of neuralnetworkbased discrete choice models called RUMnets which is inspired by therandom utility maximization RUM framework. This model formulates the agentsrandom utility function using the sample average approximation SAA method. Weshow that RUMnets sharply approximate the class of RUM discrete choice modelsany model derived from random utility maximization has choice probabilitiesthat can be approximated arbitrarily closely by a RUMnet. Reciprocally anyRUMnet is consistent with the RUM principle. We derive an upper bound on thegeneralization error of RUMnets fitted on choice data and gain theoreticalinsights on their ability to predict choices on new unseen data depending oncritical parameters of the dataset and architecture. By leveraging opensourcelibraries for neural networks we find that RUMnets outperform otherstateoftheart choice modeling and machine learning methods by a significantmargin on two realworld datasets.,4
Improved Global Guarantees for the Nonconvex BurerMonteiro Factorization via Rank Overparameterization We consider minimizing a twicedifferentiable Lsmooth and mustronglyconvex objective phi over an ntimes n positive semidefinite matrixMsucceq under the assumption that the minimizer Mstar has low rankrstarll n. Following the BurerMonteiro approach we instead minimizethe nonconvex objective fXphiXXT over a factor matrix X of sizentimes r. This substantially reduces the number of variables from Onto as few as On and also enforces positive semidefiniteness for free butat the cost of giving up the convexity of the original problem. In this paperwe prove that if the search rank rge rstar is overparameterized by aconstant factor with respect to the true rank rstar namely as inrfracLmurstar then despite nonconvexity localoptimization is guaranteed to globally converge from any initial point to theglobal optimum. This significantly improves upon a previous rankoverparameterization threshold of rge n which is known to be sharp ifphi is allowed to be nonsmooth andor nonstrongly convex but wouldincrease the number of variables back up to On. Conversely withoutrank overparameterization we prove that such a global guarantee is possible ifand only if phi is almost perfectly conditioned with a condition number ofLmu. Therefore we conclude that a small amount of overparameterizationcan lead to large improvements in theoretical guarantees for the nonconvexBurerMonteiro factorization.,4
Recommendation Systems with DistributionFree Reliability Guarantees When building recommendation systems we seek to output a helpful set ofitems to the user. Under the hood a ranking model predicts which of twocandidate items is better and we must distill these pairwise comparisons intothe userfacing output. However a learned ranking model is never perfect sotaking its predictions at face value gives no guarantee that the userfacingoutput is reliable. Building from a pretrained ranking model we show how toreturn a set of items that is rigorously guaranteed to contain mostly gooditems. Our procedure endows any ranking model with rigorous finitesamplecontrol of the false discovery rate FDR regardless of the unknown datadistribution. Moreover our calibration algorithm enables the easy andprincipled integration of multiple objectives in recommender systems. As anexample we show how to optimize for recommendation diversity subject to auserspecified level of FDR control circumventing the need to specify ad hocweights of a diversity loss against an accuracy loss. Throughout we focus onthe problem of learning to rank a set of possible recommendations evaluatingour methods on the Yahoo Learning to Rank and MSMarco datasets.,4
The Poisson binomial mechanism for secure and private federated learning We introduce the Poisson Binomial mechanism PBM a discrete differentialprivacy mechanism for distributed mean estimation DME with applications tofederated learning and analytics. We provide a tight analysis of its privacyguarantees showing that it achieves the same privacyaccuracy tradeoffs asthe continuous Gaussian mechanism. Our analysis is based on a novel bound onthe Rnyi divergence of two Poisson binomial distributions that may be ofindependent interest.,4
Differentially Private Estimation via Statistical Depth Constructing a differentially private DP estimator requires deriving themaximum influence of an observation which can be difficult in the absence ofexogenous bounds on the input data or the estimator especially in highdimensional settings. This paper shows that standard notions of statisticaldepth i.e. halfspace depth and regression depth are particularlyadvantageous in this regard both in the sense that the maximum influence of asingle observation is easy to analyze and that this value is typically low.This is used to motivate new approximate DP location and regression estimatorsusing the maximizers of these two notions of statistical depth. A morecomputationally efficient variant of the approximate DP regression estimator isalso provided. Also to avoid requiring that users specify a priori bounds onthe estimates andor the observations variants of these DP mechanisms aredescribed that satisfy random differential privacy RDP which is a relaxationof differential privacy provided by Hall Wasserman and Rinaldo . Wealso provide simulations of the two DP regression methods proposed here. Theproposed estimators appear to perform favorably relative to the existing DPregression methods we consider in these simulations when either the sample sizeis at least  or the privacyloss budget is sufficiently high.,4
Energy Trees Regression and Classification With Structured and MixedType Covariates The continuous growth of data complexity requires methods and models thatadequately account for nontrivial structures as any simplification may induceloss of information. Many analytical tools have been introduced to work withcomplex data objects in their original form but such tools can typically dealwith singletype variables only. In this work we propose Energy Trees as amodel for regression and classification tasks where covariates are potentiallyboth structured and of different types. Energy Trees incorporate EnergyStatistics to generalize Conditional Trees from which they inheritstatistically sound foundations interpretability scale invariance and lackof distributional assumptions. We focus on functions and graphs as structuredcovariates and we show how the model can be easily adapted to work with almostany other type of variable. Through an extensive simulation study we highlightthe good performance of our proposal in terms of variable selection androbustness to overfitting. Finally we validate the models predictive abilitythrough two empirical analyses with human biological data.,4
On the instrumental variable estimation with many weak and invalid instruments We discuss the fundamental issue of identification in linear instrumentalvariable IV models with unknown IV validity. We revisit the popular majorityand plurality rules and show that no identification condition can be if andonly if in general. With the assumption of the sparsest rule which isequivalent to the plurality rule but becomes operational in computationalgorithms we investigate and prove the advantages of nonconvex penalizedapproaches over other IV estimators based on twostep selections in terms ofselection consistency and accommodation for individually weak IVs. Furthermorewe propose a surrogate sparsest penalty that aligns with the identificationcondition and provides oracle sparse structure simultaneously. Desirabletheoretical properties are derived for the proposed estimator with weaker IVstrength conditions compared to the previous literature. Finite sampleproperties are demonstrated using simulations and the selection and estimationmethod is applied to an empirical study concerning the effect of trade oneconomic growth.,4
The role of the geometric mean in casecontrol studies Historically used in settings where the outcome is rare or data collection isexpensive outcomedependent sampling is relevant to many modern settings wheredata is readily available for a biased sample of the target population such aspublic administrative data. Under outcomedependent sampling common effectmeasures such as the average risk difference and the average risk ratio are notidentified but the conditional odds ratio is. Aggregation of the conditionalodds ratio is challenging since summary measures are generally not identified.Furthermore the marginal odds ratio can be larger or smaller than allconditional odds ratios. This socalled noncollapsibility of the odds ratio isavoidable if we use an alternative aggregation to the standard arithmetic mean.We provide a new definition of collapsibility that makes this choice ofaggregation method explicit and we demonstrate that the odds ratio iscollapsible under geometric aggregation. We describe how to partially identifyestimate and do inference on the geometric odds ratio under outcomedependentsampling. Our proposed estimator is based on the efficient influence functionand therefore has doubly robuststyle properties.,4
Fast computation of rankings from pairwise comparisons We study the ranking of individuals teams or objects on the basis ofpairwise comparisons using the BradleyTerry model. Maximumlikelihoodestimates of rankings within this model are commonly made using a simpleiterative algorithm first introduced by Zermelo almost a century ago. Here wedescribe an alternative and similarly simple iteration that solves the sameproblem much faster  over a hundred times faster in some cases. Wedemonstrate this algorithm with applications to a range of example data setsand derive some results regarding its convergence.,4
AMLB an AutoML Benchmark Comparing different AutoML frameworks is notoriously challenging and oftendone incorrectly. We introduce an open and extensible benchmark that followsbest practices and avoids common mistakes when comparing AutoML frameworks. Weconduct a thorough comparison of  wellknown AutoML frameworks across classification and  regression tasks. The differences between the AutoMLframeworks are explored with a multifaceted analysis evaluating modelaccuracy its tradeoffs with inference time and framework failures. We alsouse BradleyTerry trees to discover subsets of tasks where the relative AutoMLframework rankings differ. The benchmark comes with an opensource tool thatintegrates with many AutoML frameworks and automates the empirical evaluationprocess endtoend from framework installation and resource allocation toindepth evaluation. The benchmark uses public data sets can be easilyextended with other AutoML frameworks and tasks and has a website withuptodate results.,4
Joint Application of the Target Trial Causal Framework and Machine Learning Modeling to Optimize Antibiotic Therapy Use Case on Acute Bacterial Skin and Skin Structure Infections due to Methicillinresistant Staphylococcus aureus Bacterial infections are responsible for high mortality worldwide.Antimicrobial resistance underlying the infection and multifaceted patientsclinical status can hamper the correct choice of antibiotic treatment.Randomized clinical trials provide average treatment effect estimates but arenot ideal for risk stratification and optimization of therapeutic choice i.e.individualized treatment effects ITE. Here we leverage largescaleelectronic health record data collected from Southern US academic clinics toemulate a clinical trial i.e. target trial and develop a machine learningmodel of mortality prediction and ITE estimation for patients diagnosed withacute bacterial skin and skin structure infection ABSSSI due tomethicillinresistant Staphylococcus aureus MRSA. ABSSSIMRSA is achallenging condition with reduced treatment options  vancomycin is thepreferred choice but it has nonnegligible side effects. First we usepropensity score matching to emulate the trial and create a treatmentrandomized vancomycin vs. other antibiotics dataset. Next we use this datato train various machine learning methods including boostedLASSO logisticregression support vector machines and random forest and choose the bestmodel in terms of area under the receiver characteristic AUC throughbootstrap validation. Lastly we use the models to calculate ITE and identifypossible averted deaths by therapy change. The outofbag tests indicate thatSVM and RF are the most accurate with AUC of  and  respectively butBLRLASSO is not far behind . By calculating the counterfactuals using theBLRLASSO vancomycin increases the risk of death but it shows a largevariation odds ratio .  range .. and the contribution to outcomeprobability is modest. Instead the RF exhibits stronger changes in ITEsuggesting more complex treatment heterogeneity.,4
Can Populationbased Engagement Improve Personalisation A Novel Dataset and Experiments This work explores how populationbased engagement prediction can addresscoldstart at scale in large learning resource collections. The paperintroduces i VLE a novel dataset that consists of content and video basedfeatures extracted from publicly available scientific video lectures coupledwith implicit and explicit signals related to learner engagement ii twostandard tasks related to predicting and ranking contextagnostic engagement invideo lectures with preliminary baselines and iii a set of experiments thatvalidate the usefulness of the proposed dataset. Our experimental resultsindicate that the newly proposed VLE dataset leads to building contextagnosticengagement prediction models that are significantly performant than ones basedon previous datasets mainly attributing to the increase of training examples.VLE datasets suitability in building models towards Computer ScienceArtificial Intelligence education focused on elearning MOOC usecases is alsoevidenced. Further experiments in combining the built model with apersonalising algorithm show promising improvements in addressing thecoldstart problem encountered in educational recommenders. This is the largestand most diverse publicly available dataset to our knowledge that deals withlearner engagement prediction tasks. The dataset helper tools descriptivestatistics and example code snippets are available publicly.,4
Probabilistic forecasting for geosteering in fluvial successions using a generative adversarial network Quantitative workflows utilizing realtime data to constrain aheadofbituncertainty have the potential to improve geosteering significantly. Fastupdates based on realtime data are essential when drilling in complexreservoirs with high uncertainties in predrill models. However practicalassimilation of realtime data requires effective geological modeling andmathematically robust parameterization. We propose a generative adversarialdeep neural network GAN trained to reproduce geologically consistent Dsections of fluvial successions. Offline training produces a fast GANbasedapproximation of complex geology parameterized as a dimensional model vectorwith standard Gaussian distribution of each component. Probabilistic forecastsare generated using an ensemble of equiprobable model vector realizations. Aforwardmodeling sequence including a GAN converts the initial priorensemble of realizations into EM log predictions. An ensemble smootherminimizes statistical misfits between predictions and realtime data yieldingan update of model vectors and reduced uncertainty around the well. Updates canbe then translated to probabilistic predictions of facies and resistivities.The present paper demonstrates a workflow for geosteering in an outcropbasedsynthetic fluvial succession. In our example the method reduces uncertaintyand correctly predicts most major geological features up to  meters ahead ofdrillbit.,4
Variance estimation in graphs with the fused lasso We study the problem of variance estimation in general graphstructuredproblems. First we develop a linear time estimator for the homoscedastic casethat can consistently estimate the variance in general graphs. We show that ourestimator attains minimax rates for the chain and D grid graphs when the meansignal has a total variation with canonical scaling. Furthermore we providegeneral upper bounds on the mean squared error performance of the fused lassoestimator in general graphs under a moment condition and a bound on the tailbehavior of the errors. These upper bounds allow us to generalize for broaderclasses of distributions such as subExponential many existing results on thefused lasso that are only known to hold with the assumption that errors aresubGaussian random variables. Exploiting our upper bounds we then study asimple total variation regularization estimator for estimating the signal ofvariances in the heteroscedastic case. Our results show that the varianceestimator attains minimax rates for estimating signals of bounded variation ingrid graphs Knearest neighbor graphs with very mild assumptions and it isconsistent for estimating the variances in any connected graph. In additionextensive numerical results show that our proposed estimators performreasonably well in a variety of graphstructured models.,4
Partial Disentanglement via Mechanism Sparsity Disentanglement via mechanism sparsity was introduced recently as aprincipled approach to extract latent factors without supervision when thecausal graph relating them in time is sparse andor when actions are observedand affect them sparsely. However this theory applies only to groundtruthgraphs satisfying a specific criterion. In this work we introduce ageneralization of this theory which applies to any groundtruth graph andspecifies qualitatively how disentangled the learned representation is expectedto be via a new equivalence relation over models we call consistency. Thisequivalence captures which factors are expected to remain entangled and whichare not based on the specific form of the groundtruth graph. We call thisweaker form of identifiability partial disentanglement. The graphical criterionthat allows complete disentanglement proposed in an earlier work can bederived as a special case of our theory. Finally we enforce graph sparsitywith constrained optimization and illustrate our theory and algorithm insimulations.,4
Conservative SPDEs as fluctuating mean field limits of stochastic gradient descent The convergence of stochastic interacting particle systems in the meanfieldlimit to solutions to conservative stochastic partial differential equations isshown with optimal rate of convergence. As a second main result aquantitative central limit theorem for such SPDEs is derived again withoptimal rate of convergence.,4
Online Active Regression Active regression considers a linear regression problem where the learnerreceives a large number of data points but can only observe a small number oflabels. Since online algorithms can deal with incremental training data andtake advantage of low computational cost we consider an online extension ofthe active regression problem the learner receives data points one by one andimmediately decides whether it should collect the corresponding labels. Thegoal is to efficiently maintain the regression of received data points with asmall budget of label queries. We propose novel algorithms for this problemunder ellp loss where pin. To achieve a epsilonapproximatesolution our proposed algorithms only requiretildemathcalOepsilon d lognkappa queries of labels wheren is the number of data points and kappa is a quantity called thecondition number of the data points. The numerical results verify ourtheoretical results and show that our methods have comparable performance withoffline active regression algorithms.,4
Adaptive StepSize Methods for Compressed SGD Compressed Stochastic Gradient Descent SGD algorithms have been recentlyproposed to address the communication bottleneck in distributed anddecentralized optimization problems such as those that arise in federatedmachine learning. Existing compressed SGD algorithms assume the use ofnonadaptive stepsizesconstant or diminishing to provide theoreticalconvergence guarantees. Typically the stepsizes are finetuned in practice tothe dataset and the learning algorithm to provide good empirical performance.Such finetuning might be impractical in many learning scenarios and it istherefore of interest to study compressed SGD using adaptive stepsizes.Motivated by prior work on adaptive stepsize methods for SGD to train neuralnetworks efficiently in the uncompressed setting we develop an adaptivestepsize method for compressed SGD. In particular we introduce a scalingtechnique for the descent step in compressed SGD which we use to establishorderoptimal convergence rates for convexsmooth and strong convexsmoothobjectives under an interpolation condition and for nonconvex objectives undera strong growth condition. We also show through simulation examples thatwithout this scaling the algorithm can fail to converge. We presentexperimental results on deep neural networks for realworld datasets andcompare the performance of our proposed algorithm with previously proposedcompressed SGD methods in literature and demonstrate improved performance onResNet ResNet and DenseNet architectures for CIFAR and CIFARdatasets at various levels of compression.,4
Distributed Online System Identification for LTI Systems Using Reverse Experience Replay Identification of linear timeinvariant LTI systems plays an important rolein control and reinforcement learning. Both asymptotic and finitetime offlinesystem identification are wellstudied in the literature. For online systemidentification the idea of stochasticgradient descent with reverse experiencereplay SGDRER was recently proposed where the data sequence is stored inseveral buffers and the stochasticgradient descent SGD update performsbackward in each buffer to break the time dependency between data points.Inspired by this work we study distributed online system identification of LTIsystems over a multiagent network. We consider agents as identical LTIsystems and the network goal is to jointly estimate the system parameters byleveraging the communication between agents. We propose DSGDRER a distributedvariant of the SGDRER algorithm and theoretically characterize theimprovement of the estimation error with respect to the network size. Ournumerical experiments certify the reduction of estimation error as the networksize grows.,4
Statistical Hypothesis Testing Based on Machine Learning Large Deviations Analysis We study the performance  and specifically the rate at which the errorprobability converges to zero  of Machine Learning ML classificationtechniques. Leveraging the theory of large deviations we provide themathematical conditions for a ML classifier to exhibit error probabilities thatvanish exponentially say sim expleftnI  on right where n isthe number of informative observations available for testing or anotherrelevant parameter such as the size of the target in an image and I is theerror rate. Such conditions depend on the FenchelLegendre transform of thecumulantgenerating function of the DataDriven Decision Function DF i.e.what is thresholded before the final binary decision is made learned in thetraining phase. As such the DF and consequently the related error rate Idepend on the given training set which is assumed of finite size.Interestingly these conditions can be verified and tested numericallyexploiting the available dataset or a synthetic dataset generated accordingto the available information on the underlying statistical model. In otherwords the classification error probability convergence to zero and its ratecan be computed on a portion of the dataset available for training. Coherentlywith the large deviations theory we can also establish the convergence forn large enough of the normalized DF statistic to a Gaussian distribution.This property is exploited to set a desired asymptotic false alarm probabilitywhich empirically turns out to be accurate even for quite realistic values ofn. Furthermore approximate error probability curves sim zetanexpleftnI right are provided thanks to the refined asymptoticderivation often referred to as exact asymptotics where zetan representsthe most representative subexponential terms of the error probabilities.,4
Lazy Estimation of Variable Importance for Large Neural Networks As opaque predictive models increasingly impact many areas of modern lifeinterest in quantifying the importance of a given input variable for making aspecific prediction has grown. Recently there has been a proliferation ofmodelagnostic methods to measure variable importance VI that analyze thedifference in predictive power between a full model trained on all variablesand a reduced model that excludes the variables of interest. A bottleneckcommon to these methods is the estimation of the reduced model for eachvariable or subset of variables which is an expensive process that oftendoes not come with theoretical guarantees. In this work we propose a fast andflexible method for approximating the reduced model with important inferentialguarantees. We replace the need for fully retraining a wide neural network by alinearization initialized at the full model parameters. By adding a ridgelikepenalty to make the problem convex we prove that when the ridge penaltyparameter is sufficiently large our method estimates the variable importancemeasure with an error rate of Ofracsqrtn where n is the numberof training samples. We also show that our estimator is asymptotically normalenabling us to provide confidence bounds for the VI estimates. We demonstratethrough simulations that our method is fast and accurate under severaldatagenerating regimes and we demonstrate its realworld applicability on aseasonal climate forecasting example.,4
Delayed Feedback in Generalised Linear Bandits Revisited The stochastic generalised linear bandit is a wellunderstood model forsequential decisionmaking problems with many algorithms achievingnearoptimal regret guarantees under immediate feedback. However in many realworld settings the requirement that the reward is observed immediately is notapplicable. In this setting standard algorithms are no longer theoreticallyunderstood. We study the phenomenon of delayed rewards in a theoretical mannerby introducing a delay between selecting an action and receiving the reward.Subsequently we show that an algorithm based on the optimistic principleimproves on existing approaches for this setting by eliminating the need forprior knowledge of the delay distribution and relaxing assumptions on thedecision set and the delays. This also leads to improving the regret guaranteesfrom  widetilde OsqrtdTsqrtd  mathbbEtau to  widetildeOdsqrtT  dmathbbEtau where mathbbEtau denotes theexpected delay d is the dimension and T the time horizon and we havesuppressed logarithmic terms. We verify our theoretical results throughexperiments on simulated data.,4
GoalConditioned Generators of Deep Policies Goalconditioned Reinforcement Learning RL aims at learning optimalpolicies given goals encoded in special command inputs. Here we studygoalconditioned neural nets NNs that learn to generate deep NN policies inform of contextspecific weight matrices similar to Fast Weight Programmersand other methods from the s. Using context commands of the form generatea policy that achieves a desired expected return our NN generators combinepowerful exploration of parameter space with generalization across commands toiteratively find better and better policies. A form of weightsharingHyperNetworks and policy embeddings scales our method to generate deep NNs.Experiments show how a single learned policy generator can produce policiesthat achieve any return seen during training. Finally we evaluate ouralgorithm on a set of continuous control tasks where it exhibits competitiveperformance. Our code is public.,4
Do Not Sleep on Linear Models Simple and Interpretable Techniques Outperform Deep Learning for Sleep Scoring Over the last few years research in automatic sleep scoring has mainlyfocused on developing increasingly complex deep learning architectures.However recently these approaches achieved only marginal improvements oftenat the expense of requiring more data and more expensive training procedures.Despite all these efforts and their satisfactory performance automatic sleepstaging solutions are not widely adopted in a clinical context yet. We arguethat most deep learning solutions for sleep scoring are limited in theirrealworld applicability as they are hard to train deploy and reproduce.Moreover these solutions lack interpretability and transparency which areoften key to increase adoption rates. In this work we revisit the problem ofsleep stage classification using classical machine learning. Results show thatstateoftheart performance can be achieved with a conventional machinelearning pipeline consisting of preprocessing feature extraction and a simplemachine learning model. In particular we analyze the performance of a linearmodel and a nonlinear gradient boosting model. Our approach surpassesstateoftheart that uses the same data on two public datasets SleepEDFSC MF . and SleepEDF ST MF . while achieving competitiveresults on SleepEDF SC MF . and MASS SS MF .. We show thatfor the sleep stage scoring task the expressiveness of an engineered featurevector is on par with the internally learned representations of deep learningmodels. This observation opens the door to clinical adoption as arepresentative feature vector allows to leverage both the interpretability andsuccessful track record of traditional machine learning models.,4
Uniform Stability for FirstOrder Empirical Risk Minimization We consider the problem of designing uniformly stable firstorderoptimization algorithms for empirical risk minimization. Uniform stability isoften used to obtain generalization error bounds for optimization algorithmsand we are interested in a general approach to achieve it. For Euclideangeometry we suggest a blackbox conversion which given a smooth optimizationalgorithm produces a uniformly stable version of the algorithm whilemaintaining its convergence rate up to logarithmic factors. Using thisreduction we obtain a nearly optimal algorithm for smooth optimization withconvergence rate widetildeOT and uniform stability OTnresolving an open problem of Chen et al.  Attia and Koren . Formore general geometries we develop a variant of Mirror Descent for smoothoptimization with convergence rate widetildeOT and uniform stabilityOTn leaving open the question of devising a general conversion method asin the Euclidean case.,4
Nearly Optimal Private Linear Regression via Adaptive Clipping We study the problem of differentially private linear regression where eachdata point is sampled from a fixed subGaussian style distribution. We proposeand analyze a onepass minibatch stochastic gradient descent methodDPAMBSSGD where points in each iteration are sampled without replacement.Noise is added for DP but the noise standard deviation is estimated online.Compared to existing epsilon deltaDP techniques which have suboptimalerror bounds DPAMBSSGD is able to provide nearly optimal error bounds interms of key parameters like dimensionality d number of points N and thestandard deviation sigma of the noise in observations. For example when theddimensional covariates are sampled i.i.d. from the normal distributionthen the excess error of DPAMBSSGD due to privacy is fracsigmadNfracdepsilon N i.e. the error is meaningful when number ofsamples N Omegad log d which is the standard operative regime for linearregression. In contrast error bounds for existing efficient methods in thissetting are mathcalObigfracdepsilon Nbig even forsigma. That is for constant epsilon the existing techniques requireNOmegadsqrtd to provide a nontrivial result.,4
MultiStudy Boosting Theoretical Considerations for Merging vs. Ensembling Crossstudy replicability is a powerful model evaluation criterion thatemphasizes generalizability of predictions. When training crossstudyreplicable prediction models it is critical to decide between merging andtreating the studies separately. We study boosting algorithms in the presenceof potential heterogeneity in predictoroutcome relationships across studiesand compare two multistudy learning strategies  merging all the studies andtraining a single model and  multistudy ensembling which involves traininga separate model on each study and ensembling the resulting predictions. In theregression setting we provide theoretical guidelines based on an analyticaltransition point to determine whether it is more beneficial to merge or toensemble for boosting with linear learners. In addition we characterize abiasvariance decomposition of estimation error for boosting withcomponentwise linear learners. We verify the theoretical transition pointresult in simulation and illustrate how it can guide the decision on mergingvs. ensembling in an application to breast cancer gene expression data.,4
Orthogonalization of data via GromovWasserstein type feedback for clustering and visualization In this paper we propose an adaptive approach for clustering andvisualization of data by an orthogonalization process. Starting with the datapoints being represented by a Markov process using the diffusion map frameworkthe method adaptively increase the orthogonality of the clusters by applying afeedback mechanism inspired by the GromovWasserstein distance. This mechanismiteratively increases the spectral gap and refines the orthogonality of thedata to achieve a clustering with high specificity. By using the diffusion mapframework and representing the relation between data points using transitionprobabilities the method is robust with respect to both the underlyingdistance noise in the data and random initialization. We prove that the methodconverges globally to a unique fixpoint for certain parameter values. We alsopropose a related approach where the transition probabilities in the Markovprocess are required to be doubly stochastic in which case the methodgenerates a minimizer to a nonconvex optimization problem. We apply the methodon cryoelectron microscopy image data from biopharmaceutical manufacturingwhere we can confirm biologically relevant insights related to therapeuticefficacy. We consider an example with morphological variations of genepackaging and confirm that the method produces biologically meaningfulclustering results consistent with human expert classification.,4
Kernelbased Federated Learning with Personalization We consider federated learning with personalization where in addition to aglobal objective each client is also interested in maximizing a personalizedlocal objective. We consider this problem under a general continuous actionspace setting where the objective functions belong to a reproducing kernelHilbert space. We propose algorithms based on surrogate Gaussian process GPmodels that achieve the optimal regret order up to polylogarithmic factors.Furthermore we show that the sparse approximations of the GP modelssignificantly reduce the communication cost across clients.,4
Plex Towards Reliability using Pretrained Large Model Extensions A recent trend in artificial intelligence is the use of pretrained models forlanguage and vision tasks which have achieved extraordinary performance butalso puzzling failures. Probing these models abilities in diverse ways istherefore critical to the field. In this paper we explore the reliability ofmodels where we define a reliable model as one that not only achieves strongpredictive performance but also performs well consistently over manydecisionmaking tasks involving uncertainty e.g. selective prediction openset recognition robust generalization e.g. accuracy and proper scoringrules such as loglikelihood on in and outofdistribution datasets andadaptation e.g. active learning fewshot uncertainty. We devise  types oftasks over  datasets in order to evaluate different aspects of reliability onboth vision and language domains. To improve reliability we developed ViTPlexand TPlex pretrained large model extensions for vision and languagemodalities respectively. Plex greatly improves the stateoftheart acrossreliability tasks and simplifies the traditional protocol as it improves theoutofthebox performance and does not require designing scores or tuning themodel for each task. We demonstrate scaling effects over model sizes up to Bparameters and pretraining dataset sizes up to B examples. We also demonstratePlexs capabilities on challenging tasks including zeroshot open setrecognition active learning and uncertainty in conversational languageunderstanding.,4
Holistic Robust DataDriven Decisions The design of datadriven formulations for machine learning anddecisionmaking with good outofsample performance is a key challenge. Theobservation that good insample performance does not guarantee goodoutofsample performance is generally known as overfitting. Practicaloverfitting can typically not be attributed to a single cause but instead iscaused by several factors all at once. We consider here three overfittingsources i statistical error as a result of working with finite sample dataii data noise which occurs when the data points are measured only with finiteprecision and finally iii data misspecification in which a small fraction ofall data may be wholly corrupted. We argue that although existing datadrivenformulations may be robust against one of these three sources in isolation theydo not provide holistic protection against all overfitting sourcessimultaneously. We design a novel datadriven formulation which does guaranteesuch holistic protection and is furthermore computationally viable. Ourdistributionally robust optimization formulation can be interpreted as a novelcombination of a KullbackLeibler and LevyProkhorov robust optimizationformulation. Finally we show how in the context of classification andregression problems several popular regularized and robust formulations reduceto a particular case of our proposed more general formulation.,4
Forgetmenot Contrastive Critics for Mitigating Posterior Collapse Variational autoencoders VAEs suffer from posterior collapse where thepowerful neural networks used for modeling and inference optimize the objectivewithout meaningfully using the latent representation. We introduce inferencecritics that detect and incentivize against posterior collapse by requiringcorrespondence between latent variables and the observations. By connecting thecritics objective to the literature in selfsupervised contrastiverepresentation learning we show both theoretically and empirically thatoptimizing inference critics increases the mutual information betweenobservations and latents mitigating posterior collapse. This approach isstraightforward to implement and requires significantly less training time thanprior methods yet obtains competitive results on three established datasets.Overall the approach lays the foundation to bridge the previously disconnectedframeworks of contrastive learning and probabilistic modeling with variationalautoencoders underscoring the benefits both communities may find at theirintersection.,4
Recommendation Systems with DistributionFree Reliability Guarantees When building recommendation systems we seek to output a helpful set ofitems to the user. Under the hood a ranking model predicts which of twocandidate items is better and we must distill these pairwise comparisons intothe userfacing output. However a learned ranking model is never perfect sotaking its predictions at face value gives no guarantee that the userfacingoutput is reliable. Building from a pretrained ranking model we show how toreturn a set of items that is rigorously guaranteed to contain mostly gooditems. Our procedure endows any ranking model with rigorous finitesamplecontrol of the false discovery rate FDR regardless of the unknown datadistribution. Moreover our calibration algorithm enables the easy andprincipled integration of multiple objectives in recommender systems. As anexample we show how to optimize for recommendation diversity subject to auserspecified level of FDR control circumventing the need to specify ad hocweights of a diversity loss against an accuracy loss. Throughout we focus onthe problem of learning to rank a set of possible recommendations evaluatingour methods on the Yahoo Learning to Rank and MSMarco datasets.,4
Uncertainty Calibration in Bayesian Neural Networks via DistanceAware Priors As we move away from the data the predictive uncertainty should increasesince a great variety of explanations are consistent with the little availableinformation. We introduce DistanceAware Prior DAP calibration a method tocorrect overconfidence of Bayesian deep learning models outside of the trainingdomain. We define DAPs as prior distributions over the model parameters thatdepend on the inputs through a measure of their distance from the training set.DAP calibration is agnostic to the posterior inference method and it can beperformed as a postprocessing step. We demonstrate its effectiveness againstseveral baselines in a variety of classification and regression problemsincluding benchmarks designed to test the quality of predictive distributionsaway from the data.,4
Package for Fast ABCBoost This report presents the opensource package which implements the series ofour boosting works in the past years. In particular the package includesmainly three lines of techniques among which the following two are already thestandard implementations in popular boosted tree platforms,4
Statistical Inference with Stochastic Gradient Algorithms Stochastic gradient algorithms are widely used for both optimization andsampling in largescale learning and inference problems. However in practicetuning these algorithms is typically done using heuristics and trialanderrorrather than rigorous generalizable theory. To address this gap between theoryand practice we novel insights into the effect of tuning parameters bycharacterizing the largesample behavior of iterates of a very general class ofpreconditioned stochastic gradient algorithms with fixed step size. In theoptimization setting our results show that iterate averaging with a largefixed step size can result in statistically efficient approximation of thelocal Mestimator. In the sampling context our results show that withappropriate choices of tuning parameters the limiting stationary covariancecan match either the Bernsteinvon Mises limit of the posterior adjustmentsto the posterior for model misspecification or the asymptotic distribution ofthe MLE and that with a naive tuning the limit corresponds to none of these.Moreover we argue that an essentially independent sample from the stationarydistribution can be obtained after a fixed number of passes over the dataset.We validate our asymptotic results in realistic finitesample regimes viaseveral experiments using simulated and real data. Overall we demonstrate thatproperly tuned stochastic gradient algorithms with constant step size offer acomputationally efficient and statistically robust approach to obtaining pointestimates or posteriorlike samples.,4
TCT Convexifying Federated Learning using Bootstrapped Neural Tangent Kernels Stateoftheart federated learning methods can perform far worse than theircentralized counterparts when clients have dissimilar data distributions. Forneural networks even when centralized SGD easily finds a solution that issimultaneously performant for all clients current federated optimizationmethods fail to converge to a comparable solution. We show that thisperformance disparity can largely be attributed to optimization challengespresented by nonconvexity. Specifically we find that the early layers of thenetwork do learn useful features but the final layers fail to make use ofthem. That is federated optimization applied to this nonconvex problemdistorts the learning of the final layers. Leveraging this observation wepropose a TrainConvexifyTrain TCT procedure to sidestep this issue firstlearn features using offtheshelf methods e.g. FedAvg then optimize aconvexified problem obtained from the networks empirical neural tangent kernelapproximation. Our technique yields accuracy improvements of up to  onFMNIST and  on CIFAR when clients have dissimilar data.,4
