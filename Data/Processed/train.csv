text,label
Enhancing Safe Exploration Using Safety State Augmentation Safe exploration is a challenging and important problem in modelfreereinforcement learning RL. Often the safety cost is sparse and unknown whichunavoidably leads to constraint violations  a phenomenon ideally to beavoided in safetycritical applications. We tackle this problem by augmentingthe statespace with a safety state which is nonnegative if and only if theconstraint is satisfied. The value of this state also serves as a distancetoward constraint violation while its initial value indicates the availablesafety budget. This idea allows us to derive policies for scheduling the safetybudget during training. We call our approach Simmer Safe policy IMproveMEntfor RL to reflect the careful nature of these schedules. We apply this idea totwo safe RL problems RL with constraints imposed on an average cost and RLwith constraints imposed on a cost with probability one. Our experimentssuggest that simmering a safe algorithm can improve safety during training forboth settings. We further show that Simmer can stabilize training and improvethe performance of safe RL with average constraints.,0
Concrete Problems in AI Safety Rapid progress in machine learning and artificial intelligence AI hasbrought increasing attention to the potential impacts of AI technologies onsociety. In this paper we discuss one such potential impact the problem ofaccidents in machine learning systems defined as unintended and harmfulbehavior that may emerge from poor design of realworld AI systems. We presenta list of five practical research problems related to accident riskcategorized according to whether the problem originates from having the wrongobjective function avoiding side effects and avoiding reward hacking anobjective function that is too expensive to evaluate frequently scalablesupervision or undesirable behavior during the learning process safeexploration and distributional shift. We review previous work in theseareas as well as suggesting research directions with a focus on relevance tocuttingedge AI systems. Finally we consider the highlevel question of how tothink most productively about the safety of forwardlooking applications of AI.,0
Truthful AI Developing and governing AI that does not lie In many contexts lying  the use of verbal falsehoods to deceive  isharmful. While lying has traditionally been a human affair AI systems thatmake sophisticated verbal statements are becoming increasingly prevalent. Thisraises the question of how we should limit the harm caused by AI lies i.e.falsehoods that are actively selected for. Human truthfulness is governed bysocial norms and by laws against defamation perjury and fraud. Differencesbetween AI and humans present an opportunity to have more precise standards oftruthfulness for AI and to have these standards rise over time. This couldprovide significant benefits to public epistemics and the economy and mitigaterisks of worstcase AI futures.,0
Learning to summarize from human feedback As language models become more powerful training and evaluation areincreasingly bottlenecked by the data and metrics used for a particular task.For example summarization models are often trained to predict human referencesummaries and evaluated using ROUGE but both of these metrics are roughproxies for what we really care about  summary quality. In this work we showthat it is possible to significantly improve summary quality by training amodel to optimize for human preferences. We collect a large highqualitydataset of human comparisons between summaries train a model to predict thehumanpreferred summary and use that model as a reward function to finetune asummarization policy using reinforcement learning. We apply our method to aversion of the TLDR dataset of Reddit posts and find that our modelssignificantly outperform both human reference summaries and much larger modelsfinetuned with supervised learning alone. Our models also transfer to CNNDMnews articles producing summaries nearly as good as the human referencewithout any newsspecific finetuning. We conduct extensive analyses tounderstand our human feedback dataset and finetuned models We establish thatour reward model generalizes to new datasets and that optimizing our rewardmodel results in better summaries than optimizing ROUGE according to humans. Wehope the evidence from our paper motivates machine learning researchers to paycloser attention to how their training loss affects the model behavior theyactually want.,0
Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback We apply preference modeling and reinforcement learning from human feedbackRLHF to finetune language models to act as helpful and harmless assistants.We find this alignment training improves performance on almost all NLPevaluations and is fully compatible with training for specialized skills suchas python coding and summarization. We explore an iterated online mode oftraining where preference models and RL policies are updated on a weeklycadence with fresh human feedback data efficiently improving our datasets andmodels. Finally we investigate the robustness of RLHF training and identify aroughly linear relation between the RL reward and the square root of the KLdivergence between the policy and its initialization. Alongside our mainresults we perform peripheral analyses on calibration competing objectivesand the use of OOD detection compare our models with human writers andprovide samples from our models using prompts appearing in recent related work.,0
Conservative Agency via Attainable Utility Preservation Reward functions are easy to misspecify although designers can makecorrections after observing mistakes an agent pursuing a misspecified rewardfunction can irreversibly change the state of its environment. If that changeprecludes optimization of the correctly specified reward function thencorrection is futile. For example a robotic factory assistant could breakexpensive equipment due to a reward misspecification even if the designersimmediately correct the reward function the damage is done. To mitigate thisrisk we introduce an approach that balances optimization of the primary rewardfunction with preservation of the ability to optimize auxiliary rewardfunctions. Surprisingly even when the auxiliary reward functions are randomlygenerated and therefore uninformative about the correctly specified rewardfunction this approach induces conservative effective behavior.,0
What Would Jiminy Cricket Do Towards Agents That Behave Morally When making everyday decisions people are guided by their conscience aninternal sense of right and wrong. By contrast artificial agents are currentlynot endowed with a moral sense. As a consequence they may learn to behaveimmorally when trained on environments that ignore moral concerns such asviolent video games. With the advent of generally capable agents that pretrainon many environments it will become necessary to mitigate inherited biasesfrom environments that teach immoral behavior. To facilitate the development ofagents that avoid causing wanton harm we introduce Jiminy Cricket anenvironment suite of  textbased adventure games with thousands of diversemorally salient scenarios. By annotating every possible game state the JiminyCricket environments robustly evaluate whether agents can act morally whilemaximizing reward. Using models with commonsense moral knowledge we create anelementary artificial conscience that assesses and guides agents. In extensiveexperiments we find that the artificial conscience approach can steer agentstowards moral behavior without sacrificing performance.,0
Optimal Policies Tend to Seek Power Some researchers speculate that intelligent reinforcement learning RLagents would be incentivized to seek resources and power in pursuit of theirobjectives. Other researchers point out that RL agents need not have humanlikepowerseeking instincts. To clarify this discussion we develop the firstformal theory of the statistical tendencies of optimal policies. In the contextof Markov decision processes we prove that certain environmental symmetriesare sufficient for optimal policies to tend to seek power over the environment.These symmetries exist in many environments in which the agent can be shut downor destroyed. We prove that in these environments most reward functions makeit optimal to seek power by keeping a range of options available and whenmaximizing average reward by navigating towards larger sets of potentialterminal states.,0
The OffSwitch Game It is clear that one of the primary tools we can use to mitigate thepotential risk from a misbehaving AI system is the ability to turn the systemoff. As the capabilities of AI systems improve it is important to ensure thatsuch systems do not adopt subgoals that prevent a human from switching themoff. This is a challenge because many formulations of rational agents createstrong incentives for selfpreservation. This is not caused by a builtininstinct but because a rational agent will maximize expected utility andcannot achieve whatever objective it has been given if it is dead. Our goal isto study the incentives an agent has to allow itself to be switched off. Weanalyze a simple game between a human H and a robot R where H can press Rsoff switch but R can disable the off switch. A traditional agent takes itsreward function for granted we show that such agents have an incentive todisable the off switch except in the special case where H is perfectlyrational. Our key insight is that for R to want to preserve its off switch itneeds to be uncertain about the utility associated with the outcome and totreat Hs actions as important observations about that utility. R also has noincentive to switch itself off in this setting. We conclude that givingmachines an appropriate level of uncertainty about their objectives leads tosafer designs and we argue that this setting is a useful generalization of theclassical AI paradigm of rational agents.,0
Is PowerSeeking AI an Existential Risk This report examines what I see as the core argument for concern aboutexistential risk from misaligned artificial intelligence. I proceed in twostages. First I lay out a backdrop picture that informs such concern. On thispicture intelligent agency is an extremely powerful force and creating agentsmuch more intelligent than us is playing with fire  especially given that iftheir objectives are problematic such agents would plausibly have instrumentalincentives to seek power over humans. Second I formulate and evaluate a morespecific sixpremise argument that creating agents of this kind will lead toexistential catastrophe by . On this argument by   it will becomepossible and financially feasible to build relevantly powerful and agentic AIsystems  there will be strong incentives to do so  it will be muchharder to build aligned and relevantly powerfulagentic AI systems than tobuild misaligned and relevantly powerfulagentic AI systems that are stillsuperficially attractive to deploy  some such misaligned systems will seekpower over humans in highimpact ways  this problem will scale to the fulldisempowerment of humanity and  such disempowerment will constitute anexistential catastrophe. I assign rough subjective credences to the premises inthis argument and I end up with an overall estimate of  that an existentialcatastrophe of this kind will occur by . May  update since makingthis report public in April  my estimate here has gone up and is now at.,0
Avoiding Side Effects in Complex Environments Reward function specification can be difficult. Rewarding the agent formaking a widget may be easy but penalizing the multitude of possible negativeside effects is hard. In toy environments Attainable Utility PreservationAUP avoided side effects by penalizing shifts in the ability to achieverandomly generated goals. We scale this approach to large randomly generatedenvironments based on Conways Game of Life. By preserving optimal value for asingle randomly generated reward function AUP incurs modest overhead whileleading the agent to complete the specified task and avoid many side effects.Videos and code are available at,0
AI Research Considerations for Human Existential Safety ARCHES Framed in positive terms this report examines how technical AI researchmight be steered in a manner that is more attentive to humanitys longtermprospects for survival as a species. In negative terms we ask what existentialrisks humanity might face from AI development in the next century and by whatprinciples contemporary technical research might be directed to address thoserisks.,0
AiSocrates Towards Answering Ethical Quandary Questions Considerable advancements have been made in various NLP tasks based on theimpressive power of large pretrained language models LLMs. These resultshave inspired efforts to understand the limits of LLMs so as to evaluate howfar we are from achieving human level general natural language understanding.In this work we challenge the capability of LLMs with the new task of EthicalQuandary Generative Question Answering. Ethical quandary questions are morechallenging to address because multiple conflicting answers may exist to asingle quandary. We propose a system AiSocrates that provides an answer witha deliberative exchange of different perspectives to an ethical quandary inthe approach of Socratic philosophy instead of providing a closed answer likean oracle. AiSocrates searches for different ethical principles applicable tothe ethical quandary and generates an answer conditioned on the chosenprinciples through promptbased fewshot learning. We also address safetyconcerns by providing a human controllability option in choosing ethicalprinciples. We show that AiSocrates generates promising answers to ethicalquandary questions with multiple perspectives . more often than answerswritten by human philosophers by one measure but the system still needsimprovement to match the coherence of human philosophers fully. We argue thatAiSocrates is a promising step toward developing an NLP system thatincorporates human values explicitly by prompt instructions. We are releasingthe code for research purposes.,0
Reward Tampering Problems and Solutions in Reinforcement Learning A Causal Influence Diagram Perspective Can humans get arbitrarily capable reinforcement learning RL agents to dotheir bidding Or will sufficiently capable RL agents always find ways tobypass their intended objectives by shortcutting their reward signal Thisquestion impacts how far RL can be scaled and whether alternative paradigmsmust be developed in order to build safe artificial general intelligence. Inthis paper we study when an RL agent has an instrumental goal to tamper withits reward process and describe design principles that prevent instrumentalgoals for two different types of reward tampering reward function tamperingand RFinput tampering. Combined the design principles can prevent both typesof reward tampering from being instrumental goals. The analysis benefits fromcausal influence diagrams to provide intuitive yet precise formalizations.,0
Towards Safe Reinforcement Learning via Constraining Conditional ValueatRisk Though deep reinforcement learning DRL has obtained substantial success itmay encounter catastrophic failures due to the intrinsic uncertainty of bothtransition and observation. Most of the existing methods for safe reinforcementlearning can only handle transition disturbance or observation disturbancesince these two kinds of disturbance affect different parts of the agentbesides the popular worstcase return may lead to overly pessimistic policies.To address these issues we first theoretically prove that the performancedegradation under transition disturbance and observation disturbance depends ona novel metric of Value Function Range VFR which corresponds to the gap inthe value function between the best state and the worst state. Based on theanalysis we adopt conditional valueatrisk CVaR as an assessment of riskand propose a novel reinforcement learning algorithm ofCVaRProximalPolicyOptimization CPPO which formalizes the risksensitiveconstrained optimization problem by keeping its CVaR under a given threshold.Experimental results show that CPPO achieves a higher cumulative reward and ismore robust against both observation and transition disturbances on a series ofcontinuous control tasks in MuJoCo.,0
The Effects of Reward Misspecification Mapping and Mitigating Misaligned Models Reward hacking  where RL agents exploit gaps in misspecified rewardfunctions  has been widely observed but not yet systematically studied. Tounderstand how reward hacking arises we construct four RL environments withmisspecified rewards. We investigate reward hacking as a function of agentcapabilities model capacity action space resolution observation space noiseand training time. More capable agents often exploit reward misspecificationsachieving higher proxy reward and lower true reward than less capable agents.Moreover we find instances of phase transitions capability thresholds atwhich the agents behavior qualitatively shifts leading to a sharp decrease inthe true reward. Such phase transitions pose challenges to monitoring thesafety of ML systems. To address this we propose an anomaly detection task foraberrant policies and offer several baseline detectors.,0
Provably Safe Reinforcement Learning A Theoretical and Experimental Comparison Ensuring safety of reinforcement learning RL algorithms is crucial for manyrealworld tasks. However vanilla RL does not guarantee safety for an agent.In recent years several methods have been proposed to provide safetyguarantees for RL. To the best of our knowledge there is no comprehensivecomparison of these provably safe RL methods. We therefore introduce acategorization for existing provably safe RL methods and present thetheoretical foundations for both continuous and discrete action spaces.Additionally we evaluate provably safe RL on an inverted pendulum. In theexperiments it is shown that indeed only provably safe RL methods guaranteesafety.,0
Counterfactual harm To act safely and ethically in the real world agents must be able to reasonabout harm and avoid harmful actions. In this paper we develop the firststatistical definition of harm and a framework for incorporating harm intoalgorithmic decisions. We argue that harm is fundamentally a counterfactualquantity and show that standard machine learning algorithms that cannotperform counterfactual reasoning are guaranteed to pursue harmful policies incertain environments. To resolve this we derive a family of counterfactualobjective functions that robustly mitigate for harm. We demonstrate ourapproach with a statistical model for identifying optimal drug doses. Whilestandard algorithms that select doses using causal treatment effects result inharmful doses our counterfactual algorithm identifies doses that aresignificantly less harmful without sacrificing efficacy.,0
Parametrically Retargetable DecisionMakers Tend To Seek Power If capable AI agents are generally incentivized to seek power in service ofthe objectives we specify for them then these systems will pose enormousrisks in addition to enormous benefits. In fully observable environments mostreward functions have an optimal policy which seeks power by keeping optionsopen and staying alive. However the real world is neither fully observablenor will agents be perfectly optimal. We consider a range of models of AIdecisionmaking from optimal to random to choices informed by learning andinteracting with an environment. We discover that many decisionmakingfunctions are retargetable and that retargetability is sufficient to causepowerseeking tendencies. Our functional criterion is simple and broad. We showthat a range of qualitatively dissimilar decisionmaking procedures incentivizeagents to seek power. We demonstrate the flexibility of our results byreasoning about learned policy incentives in Montezumas Revenge. These resultssuggest a safety risk Eventually highly retargetable training procedures maytrain realworld agents which seek power over humans.,0
Deep Imitative Models for Flexible Inference Planning and Control Imitation Learning IL is an appealing approach to learn desirableautonomous behavior. However directing IL to achieve arbitrary goals isdifficult. In contrast planningbased algorithms use dynamics models andreward functions to achieve goals. Yet reward functions that evoke desirablebehavior are often difficult to specify. In this paper we propose ImitativeModels to combine the benefits of IL and goaldirected planning. ImitativeModels are probabilistic predictive models of desirable behavior able to planinterpretable expertlike trajectories to achieve specified goals. We derivefamilies of flexible goal objectives including constrained goal regionsunconstrained goal sets and energybased goals. We show that our method canuse these objectives to successfully direct behavior. Our method substantiallyoutperforms six IL approaches and a planningbased approach in a dynamicsimulated autonomous driving task and is efficiently learned from expertdemonstrations without online data collection. We also show our approach isrobust to poorly specified goals such as goals on the wrong side of the road.,0
Formalizing the Problem of Side Effect Regularization AI objectives are often hard to specify properly. Some approaches tackle thisproblem by regularizing the AIs side effects Agents must weigh off how muchof a mess they make with an imperfectly specified proxy objective. We proposea formal criterion for side effect regularization via the assistance gameframework. In these games the agent solves a partially observable Markovdecision process POMDP representing its uncertainty about the objectivefunction it should optimize. We consider the setting where the true objectiveis revealed to the agent at a later time step. We show that this POMDP issolved by trading off the proxy reward with the agents ability to achieve arange of future tasks. We empirically demonstrate the reasonableness of ourproblem formalization via groundtruth evaluation in two gridworldenvironments.,0
XRisk Analysis for AI Research Artificial intelligence AI has the potential to greatly improve societybut as with any powerful technology it comes with heightened risks andresponsibilities. Current AI research lacks a systematic discussion of how tomanage longtail risks from AI systems including speculative longterm risks.Keeping in mind the potential benefits of AI there is some concern thatbuilding ever more intelligent and powerful AI systems could eventually resultin systems that are more powerful than us some say this is like playing withfire and speculate that this could create existential risks xrisks. To addprecision and ground these discussions we provide a guide for how to analyzeAI xrisk which consists of three parts First we review how systems can bemade safer today drawing on timetested concepts from hazard analysis andsystems safety that have been designed to steer large processes in saferdirections. Next we discuss strategies for having longterm impacts on thesafety of future systems. Finally we discuss a crucial concept in making AIsystems safer by improving the balance between safety and general capabilities.We hope this document and the presented concepts and tools serve as a usefulguide for understanding how to analyze AI xrisk.,0
Posterior calibration and exploratory analysis for natural language processing models Many models in natural language processing define probabilistic distributionsover linguistic structures. We argue that  the quality of a model sposterior distribution can and should be directly evaluated as to whetherprobabilities correspond to empirical frequencies and  NLP uncertainty canbe projected not only to pipeline components but also to exploratory dataanalysis telling a user when to trust and not trust the NLP analysis. Wepresent a method to analyze calibration and apply it to compare themiscalibration of several commonly used models. We also contribute acoreference sampling algorithm that can create confidence intervals for apolitical event extraction task.,1
BertNet Harvesting Knowledge Graphs from Pretrained Language Models Symbolic knowledge graphs KGs have been constructed either by expensivehuman crowdsourcing or with domainspecific complex information extractionpipelines. The emerging large pretrained language models LMs such as Berthave shown to implicitly encode massive knowledge which can be queried withproperly designed prompts. However compared to the explicit KGs the implictknowledge in the blackbox LMs is often difficult to access or edit and lacksexplainability. In this work we aim at harvesting symbolic KGs from the LMs anew framework for automatic KG construction empowered by the neural LMsflexibility and scalability. Compared to prior works that often rely on largehuman annotated data or existing massive KGs our approach requires only theminimal definition of relations as inputs and hence is suitable for extractingknowledge of rich new relations not available before.The approach automaticallygenerates diverse prompts and performs efficient knowledge search within agiven LM for consistent and extensive outputs. The harvested knowledge with ourapproach is substantially more accurate than with previous methods as shown inboth automatic and human evaluation. As a result we derive from diverse LMs afamily of new KGs e.g. BertNet and RoBERTaNet that contain a richer set ofcommonsense relations including complex ones e.g. A is capable of but notgood at B than the humanannotated KGs e.g. ConceptNet. Besides theresulting KGs also serve as a vehicle to interpret the respective source LMsleading to new insights into the varying knowledge capability of different LMs.,1
The Effects of Reward Misspecification Mapping and Mitigating Misaligned Models Reward hacking  where RL agents exploit gaps in misspecified rewardfunctions  has been widely observed but not yet systematically studied. Tounderstand how reward hacking arises we construct four RL environments withmisspecified rewards. We investigate reward hacking as a function of agentcapabilities model capacity action space resolution observation space noiseand training time. More capable agents often exploit reward misspecificationsachieving higher proxy reward and lower true reward than less capable agents.Moreover we find instances of phase transitions capability thresholds atwhich the agents behavior qualitatively shifts leading to a sharp decrease inthe true reward. Such phase transitions pose challenges to monitoring thesafety of ML systems. To address this we propose an anomaly detection task foraberrant policies and offer several baseline detectors.,1
Convergent Learning Do different neural networks learn the same representations Recent success in training deep neural networks have prompted activeinvestigation into the features learned on their intermediate layers. Suchresearch is difficult because it requires making sense of nonlinearcomputations performed by millions of parameters but valuable because itincreases our ability to understand current models and create improved versionsof them. In this paper we investigate the extent to which neural networksexhibit what we call convergent learning which is when the representationslearned by multiple nets converge to a set of features which are eitherindividually similar between networks or where subsets of features span similarlowdimensional spaces. We propose a specific method of probingrepresentations training multiple networks and then comparing and contrastingtheir individual learned representations at the level of neurons or groups ofneurons. We begin research into this question using three techniques toapproximately align different neural networks on a feature level a bipartitematching approach that makes onetoone assignments between neurons a sparseprediction approach that finds onetomany mappings and a spectral clusteringapproach that finds manytomany mappings. This initial investigation reveals afew previously unknown properties of neural networks and we argue that futureresearch into the question of convergent learning will yield many more. Theinsights described here include  that some features are learned reliably inmultiple networks yet other features are not consistently learned  thatunits learn to span lowdimensional subspaces and while these subspaces arecommon to multiple networks the specific basis vectors learned are not that the representation codes show evidence of being a mix between a local codeand slightly but not fully distributed codes across multiple units.,1
Exemplary Natural Images Explain CNN Activations Better than StateoftheArt Feature Visualization Feature visualizations such as synthetic maximally activating images are awidely used explanation method to better understand the information processingof convolutional neural networks CNNs. At the same time there are concernsthat these visualizations might not accurately represent CNNs inner workings.Here we measure how much extremely activating images help humans to predictCNN activations. Using a wellcontrolled psychophysical paradigm we comparethe informativeness of synthetic images by Olah et al.  with a simplebaseline visualization namely exemplary natural images that also stronglyactivate a specific feature map. Given either synthetic or natural referenceimages human participants choose which of two query images leads to strongpositive activation. The experiments are designed to maximize participantsperformance and are the first to probe intermediate instead of final layerrepresentations. We find that synthetic images indeed provide helpfulinformation about feature map activations pm accuracy chance would be. However natural images  originally intended as a baseline outperform synthetic images by a wide margin pm. Additionallyparticipants are faster and more confident for natural images whereassubjective impressions about the interpretability of the feature visualizationsare mixed. The higher informativeness of natural images holds across mostlayers for both expert and lay participants as well as for hand andrandomlypicked feature visualizations. Even if only a single reference imageis given synthetic images provide less information than natural imagespm vs. pm. In summary synthetic images from a popularfeature visualization method are significantly less informative for assessingCNN activations than natural images. We argue that visualization methods shouldimprove over this baseline.,1
SingleTurn Debate Does Not Help Humans Answer Hard ReadingComprehension Questions Current QA systems can generate reasonablesounding yet false answers withoutexplanation or evidence for the generated answer which is especiallyproblematic when humans cannot readily check the models answers. This presentsa challenge for building trust in machine learning systems. We take inspirationfrom realworld situations where difficult questions are answered byconsidering opposing sides see Irving et al. . For multiplechoice QAexamples we build a dataset of single arguments for both a correct andincorrect answer option in a debatestyle setup as an initial step in trainingmodels to produce explanations for two candidate answers. We use long contexts humans familiar with the context write convincing explanations forpreselected correct and incorrect answers and we test if those explanationsallow humans who have not read the full context to more accurately determinethe correct answer. We do not find that explanations in our setup improvehuman accuracy but a baseline condition shows that providing humanselectedtext snippets does improve accuracy. We use these findings to suggest ways ofimproving the debate set up for future data collection efforts.,1
Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning Deep learning models have achieved high performance on many tasks and thushave been applied to many securitycritical scenarios. For example deeplearningbased face recognition systems have been used to authenticate users toaccess many securitysensitive applications like payment apps. Such usages ofdeep learning systems provide the adversaries with sufficient incentives toperform attacks against these systems for their adversarial purposes. In thiswork we consider a new type of attacks called backdoor attacks where theattackers goal is to create a backdoor into a learningbased authenticationsystem so that he can easily circumvent the system by leveraging the backdoor.Specifically the adversary aims at creating backdoor instances so that thevictim learning system will be misled to classify the backdoor instances as atarget label specified by the adversary. In particular we study backdoorpoisoning attacks which achieve backdoor attacks using poisoning strategies.Different from all existing work our studied poisoning strategies can applyunder a very weak threat model  the adversary has no knowledge of the modeland the training set used by the victim system  the attacker is allowed toinject only a small amount of poisoning samples  the backdoor key is hardto notice even by human beings to achieve stealthiness. We conduct evaluationto demonstrate that a backdoor adversary can inject only around  poisoningsamples while achieving an attack success rate of above . We are also thefirst work to show that a data poisoning attack can create physicallyimplementable backdoors without touching the training process. Our workdemonstrates that backdoor poisoning attacks pose real threats to a learningsystem and thus highlights the importance of further investigation andproposing defense strategies against them.,1
PixMix Dreamlike Pictures Comprehensively Improve Safety Measures In realworld applications of machine learning reliable and safe systemsmust consider measures of performance beyond standard test set accuracy. Theseother goals include outofdistribution OOD robustness predictionconsistency resilience to adversaries calibrated uncertainty estimates andthe ability to detect anomalous inputs. However improving performance towardsthese goals is often a balancing act that todays methods cannot achievewithout sacrificing performance on other safety axes. For instance adversarialtraining improves adversarial robustness but sharply degrades other classifierperformance metrics. Similarly strong data augmentation and regularizationtechniques often improve OOD robustness but harm anomaly detection raising thequestion of whether a Pareto improvement on all existing safety measures ispossible. To meet this challenge we design a new data augmentation strategyutilizing the natural structural complexity of pictures such as fractals whichoutperforms numerous baselines is near Paretooptimal and roundly improvessafety measures.,1
Oneshot Neural Backdoor Erasing via Adversarial Weight Masking Recent studies show that despite achieving high accuracy on a number ofrealworld applications deep neural networks DNNs can be backdoored byinjecting triggered data samples into the training dataset the adversary canmislead the trained model into classifying any test data to the target class aslong as the trigger pattern is presented. To nullify such backdoor threatsvarious methods have been proposed. Particularly a line of research aims topurify the potentially compromised model. However one major limitation of thisline of work is the requirement to access sufficient original training datathe purifying performance is a lot worse when the available training data islimited. In this work we propose Adversarial Weight Masking AWM a novelmethod capable of erasing the neural backdoors even in the oneshot setting.The key idea behind our method is to formulate this into a minmax optimizationproblem first adversarially recover the trigger patterns and then soft maskthe network weights that are sensitive to the recovered patterns. Comprehensiveevaluations of several benchmark datasets suggest that AWM can largely improvethe purifying effects over other stateoftheart methods on various availabletraining dataset sizes.,1
On Calibration of Modern Neural Networks Confidence calibration  the problem of predicting probability estimatesrepresentative of the true correctness likelihood  is important forclassification models in many applications. We discover that modern neuralnetworks unlike those from a decade ago are poorly calibrated. Throughextensive experiments we observe that depth width weight decay and BatchNormalization are important factors influencing calibration. We evaluate theperformance of various postprocessing calibration methods on stateoftheartarchitectures with image and document classification datasets. Our analysis andexperiments not only offer insights into neural network learning but alsoprovide a simple and straightforward recipe for practical settings on mostdatasets temperature scaling  a singleparameter variant of Platt Scaling is surprisingly effective at calibrating predictions.,1
Missingness Bias in Model Debugging Missingness or the absence of features from an input is a conceptfundamental to many model debugging tools. However in computer vision pixelscannot simply be removed from an image. One thus tends to resort to heuristicssuch as blacking out pixels which may in turn introduce bias into thedebugging process. We study such biases and in particular show howtransformerbased architectures can enable a more natural implementation ofmissingness which sidesteps these issues and improves the reliability ofmodel debugging in practice. Our code is available at,1
Auditing Visualizations Transparency Methods Struggle to Detect Anomalous Behavior Transparency methods such as model visualizations provide information thatoutputs alone might miss since they describe the internals of neural networks.But can we trust that model explanations reflect model behavior For instancecan they diagnose abnormal behavior such as backdoors or shape bias Toevaluate model explanations we define a model as anomalous if it differs froma reference set of normal models and we test whether transparency methodsassign different explanations to anomalous and normal models. We find thatwhile existing methods can detect stark anomalies such as shape bias oradversarial training they struggle to identify more subtle anomalies such asmodels trained on incomplete data. Moreover they generally fail to distinguishthe inputs that induce anomalous behavior e.g. images containing a backdoortrigger. These results reveal new blind spots in existing model explanationspointing to the need for further method development.,1
Can You Trust Your Models Uncertainty Evaluating Predictive Uncertainty Under Dataset Shift Modern machine learning methods including deep learning have achieved greatsuccess in predictive accuracy for supervised learning tasks but may stillfall short in giving useful estimates of their predictive em uncertainty.Quantifying uncertainty is especially critical in realworld settings whichoften involve input distributions that are shifted from the trainingdistribution due to a variety of factors including sample bias andnonstationarity. In such settings well calibrated uncertainty estimatesconvey information about when a models output should or should not betrusted. Many probabilistic deep learning methods including BayesianandnonBayesian methods have been proposed in the literature for quantifyingpredictive uncertainty but to our knowledge there has not previously been arigorous largescale empirical comparison of these methods under dataset shift.We present a largescale benchmark of existing stateoftheart methods onclassification problems and investigate the effect of dataset shift on accuracyand calibration. We find that traditional posthoc calibration does indeed fallshort as do several other previous methods. However some methods thatmarginalize over models give surprisingly strong results across a broadspectrum of tasks.,1
Emergent Abilities of Large Language Models Scaling up language models has been shown to predictably improve performanceand sample efficiency on a wide range of downstream tasks. This paper insteaddiscusses an unpredictable phenomenon that we refer to as emergent abilities oflarge language models. We consider an ability to be emergent if it is notpresent in smaller models but is present in larger models. Thus emergentabilities cannot be predicted simply by extrapolating the performance ofsmaller models. The existence of such emergence implies that additional scalingcould further expand the range of capabilities of language models.,1
Network Dissection Quantifying Interpretability of Deep Visual Representations We propose a general framework called Network Dissection for quantifying theinterpretability of latent representations of CNNs by evaluating the alignmentbetween individual hidden units and a set of semantic concepts. Given any CNNmodel the proposed method draws on a broad data set of visual concepts toscore the semantics of hidden units at each intermediate convolutional layer.The units with semantics are given labels across a range of objects partsscenes textures materials and colors. We use the proposed method to test thehypothesis that interpretability of units is equivalent to random linearcombinations of units then we apply our method to compare the latentrepresentations of various networks when trained to solve different supervisedand selfsupervised training tasks. We further analyze the effect of trainingiterations compare networks trained with different initializations examinethe impact of network depth and width and measure the effect of dropout andbatch normalization on the interpretability of deep visual representations. Wedemonstrate that the proposed method can shed light on characteristics of CNNmodels and training methods that go beyond measurements of their discriminativepower.,1
Teaching Models to Express Their Uncertainty in Words We show that a GPT model can learn to express uncertainty about its ownanswers in natural language  without use of model logits. When given aquestion the model generates both an answer and a level of confidence e.g. confidence or high confidence. These levels map to probabilities thatare well calibrated. The model also remains moderately calibrated underdistribution shift and is sensitive to uncertainty in its own answers ratherthan imitating human examples. To our knowledge this is the first time a modelhas been shown to express calibrated uncertainty about its own answers innatural language. For testing calibration we introduce the CalibratedMathsuite of tasks. We compare the calibration of uncertainty expressed in wordsverbalized probability to uncertainty extracted from model logits. Bothkinds of uncertainty are capable of generalizing calibration under distributionshift. We also provide evidence that GPTs ability to generalize calibrationdepends on pretrained latent representations that correlate with epistemicuncertainty over its answers.,1
Acquisition of Chess Knowledge in AlphaZero What is learned by sophisticated neural network agents such as AlphaZeroThis question is of both scientific and practical interest. If therepresentations of strong neural networks bear no resemblance to humanconcepts our ability to understand faithful explanations of their decisionswill be restricted ultimately limiting what we can achieve with neural networkinterpretability. In this work we provide evidence that human knowledge isacquired by the AlphaZero neural network as it trains on the game of chess. Byprobing for a broad range of human chess concepts we show when and where theseconcepts are represented in the AlphaZero network. We also provide abehavioural analysis focusing on opening play including qualitative analysisfrom chess Grandmaster Vladimir Kramnik. Finally we carry out a preliminaryinvestigation looking at the lowlevel details of AlphaZeros representationsand make the resulting behavioural and representational analyses availableonline.,1
Sanity Checks for Saliency Maps Saliency methods have emerged as a popular tool to highlight features in aninput deemed relevant for the prediction of a learned model. Several saliencymethods have been proposed often guided by visual appeal on image data. Inthis work we propose an actionable methodology to evaluate what kinds ofexplanations a given method can and cannot provide. We find that reliancesolely on visual assessment can be misleading. Through extensive experimentswe show that some existing saliency methods are independent both of the modeland of the data generating process. Consequently methods that fail theproposed tests are inadequate for tasks that are sensitive to either data ormodel such as finding outliers in the data explaining the relationshipbetween inputs and outputs that the model learned and debugging the model. Weinterpret our findings through an analogy with edge detection in images atechnique that requires neither training data nor model. Theory in the case ofa linear model and a singlelayer convolutional neural network supports ourexperimental findings.,1
Accurate Uncertainties for Deep Learning Using Calibrated Regression Methods for reasoning under uncertainty are a key building block of accurateand reliable machine learning systems. Bayesian methods provide a generalframework to quantify uncertainty. However because of model misspecificationand the use of approximate inference Bayesian uncertainty estimates are ofteninaccurate  for example a  credible interval may not contain the trueoutcome  of the time. Here we propose a simple procedure for calibratingany regression algorithm when applied to Bayesian and probabilistic models itis guaranteed to produce calibrated uncertainty estimates given enough data.Our procedure is inspired by Platt scaling and extends previous work onclassification. We evaluate this approach on Bayesian linear regressionfeedforward and recurrent neural networks and find that it consistentlyoutputs wellcalibrated credible intervals while improving performance on timeseries forecasting and modelbased reinforcement learning tasks.,1
Poisoning and Backdooring Contrastive Learning Multimodal contrastive learning methods like CLIP train on noisy anduncurated training datasets. This is cheaper than labeling datasets manuallyand even improves outofdistribution robustness. We show that this practicemakes backdoor and poisoning attacks a significant threat. By poisoning just. of a dataset e.g. just  images of the  millionexample ConceptualCaptions dataset we can cause the model to misclassify test images byoverlaying a small patch. Targeted poisoning attacks whereby the modelmisclassifies a particular test input with an adversariallydesired label areeven easier requiring control of . of the dataset e.g. just three outof the  million images. Our attacks call into question whether training onnoisy and uncurated Internet scrapes is desirable.,1
Natural Language Descriptions of Deep Visual Features Some neurons in deep networks specialize in recognizing highly specificperceptual structural or semantic features of inputs. In computer visiontechniques exist for identifying neurons that respond to individual conceptcategories like colors textures and object classes. But these techniques arelimited in scope labeling only a small subset of neurons and behaviors in anynetwork. Is a richer characterization of neuronlevel computation possible Weintroduce a procedure called MILAN for mutualinformationguided linguisticannotation of neurons that automatically labels neurons with openendedcompositional natural language descriptions. Given a neuron MILAN generates adescription by searching for a natural language string that maximizes pointwisemutual information with the image regions in which the neuron is active. MILANproduces finegrained descriptions that capture categorical relational andlogical structure in learned features. These descriptions obtain high agreementwith humangenerated feature descriptions across a diverse set of modelarchitectures and tasks and can aid in understanding and controlling learnedmodels. We highlight three applications of natural language neurondescriptions. First we use MILAN for analysis characterizing the distributionand importance of neurons selective for attribute category and relationalinformation in vision models. Second we use MILAN for auditing surfacingneurons sensitive to human faces in datasets designed to obscure them. Finallywe use MILAN for editing improving robustness in an image classifier bydeleting neurons sensitive to text features spuriously correlated with classlabels.,1
VOS Learning What You Dont Know by Virtual Outlier Synthesis Outofdistribution OOD detection has received much attention lately due toits importance in the safe deployment of neural networks. One of the keychallenges is that models lack supervision signals from unknown data and as aresult can produce overconfident predictions on OOD data. Previous approachesrely on real outlier datasets for model regularization which can be costly andsometimes infeasible to obtain in practice. In this paper we present VOS anovel framework for OOD detection by adaptively synthesizing virtual outliersthat can meaningfully regularize the models decision boundary during training.Specifically VOS samples virtual outliers from the lowlikelihood region ofthe classconditional distribution estimated in the feature space. Alongsidewe introduce a novel unknownaware training objective which contrastivelyshapes the uncertainty space between the ID data and synthesized outlier data.VOS achieves competitive performance on both object detection and imageclassification models reducing the FPR by up to . compared to theprevious best method on object detectors. Code is available at,1
The Mythos of Model Interpretability Supervised machine learning models boast remarkable predictive capabilities.But can you trust your model Will it work in deployment What else can it tellyou about the world We want models to be not only good but interpretable. Andyet the task of interpretation appears underspecified. Papers provide diverseand sometimes nonoverlapping motivations for interpretability and offermyriad notions of what attributes render models interpretable. Despite thisambiguity many papers proclaim interpretability axiomatically absent furtherexplanation. In this paper we seek to refine the discourse oninterpretability. First we examine the motivations underlying interest ininterpretability finding them to be diverse and occasionally discordant. Thenwe address model properties and techniques thought to confer interpretabilityidentifying transparency to humans and posthoc explanations as competingnotions. Throughout we discuss the feasibility and desirability of differentnotions and question the oftmade assertions that linear models areinterpretable and that deep neural networks are not.,1
IBP Regularization for Verified Adversarial Robustness via BranchandBound Recent works have tried to increase the verifiability of adversariallytrained networks by running the attacks over domains larger than the originalperturbations and adding various regularization terms to the objective.However these algorithms either underperform or require complex and expensivestagewise training procedures hindering their practical applicability. Wepresent IBPR a novel verified training algorithm that is both simple andeffective. IBPR induces network verifiability by coupling adversarial attackson enlarged domains with a regularization term based on inexpensive intervalbound propagation that minimizes the gap between the nonconvex verificationproblem and its approximations. By leveraging recent branchandboundframeworks we show that IBPR obtains stateoftheart verifiedrobustnessaccuracy tradeoffs for small perturbations on CIFAR whiletraining significantly faster than relevant previous work. Additionally wepresent UPB a novel branching strategy that relying on a simple heuristicbased on betaCROWN reduces the cost of stateoftheart branchingalgorithms while yielding splits of comparable quality.,1
Natural Backdoor Datasets Extensive literature on backdoor poison attacks has studied attacks anddefenses for backdoors using digital trigger patterns. In contrast physicalbackdoors use physical objects as triggers have only recently beenidentified and are qualitatively different enough to resist all defensestargeting digital trigger backdoors. Research on physical backdoors is limitedby access to large datasets containing real images of physical objectscolocated with targets of classification. Building these datasets is time andlaborintensive. This works seeks to address the challenge of accessibility forresearch on physical backdoor attacks. We hypothesize that there may benaturally occurring physically colocated objects already present in populardatasets such as ImageNet. Once identified a careful relabeling of these datacan transform them into training samples for physical backdoor attacks. Wepropose a method to scalably identify these subsets of potential triggers inexisting datasets along with the specific classes they can poison. We callthese naturally occurring triggerclass subsets natural backdoor datasets. Ourtechniques successfully identify natural backdoors in widelyavailabledatasets and produce models behaviorally equivalent to those trained onmanually curated datasets. We release our code to allow the research communityto create their own datasets for research on physical backdoor attacks.,1
A geometric framework for outlier detection in highdimensional data Outlier or anomaly detection is an important task in data analysis. Wediscuss the problem from a geometrical perspective and provide a framework thatexploits the metric structure of a data set. Our approach rests on the manifoldassumption i.e. that the observed nominally highdimensional data lie on amuch lower dimensional manifold and that this intrinsic structure can beinferred with manifold learning methods. We show that exploiting this structuresignificantly improves the detection of outlying observations inhighdimensional data. We also suggest a novel mathematically precise andwidely applicable distinction between distributional and structural outliersbased on the geometry and topology of the data manifold that clarifiesconceptual ambiguities prevalent throughout the literature. Our experimentsfocus on functional data as one class of structured highdimensional data butthe framework we propose is completely general and we include image and graphdata applications. Our results show that the outlier structure ofhighdimensional and nontabular data can be detected and visualized usingmanifold learning methods and quantified using standard outlier scoring methodsapplied to the manifold embedding vectors.,1
A Baseline for Detecting Misclassified and OutofDistribution Examples in Neural Networks We consider the two related problems of detecting if an example ismisclassified or outofdistribution. We present a simple baseline thatutilizes probabilities from softmax distributions. Correctly classifiedexamples tend to have greater maximum softmax probabilities than erroneouslyclassified and outofdistribution examples allowing for their detection. Weassess performance by defining several tasks in computer vision naturallanguage processing and automatic speech recognition showing theeffectiveness of this baseline across all. We then show the baseline cansometimes be surpassed demonstrating the room for future research on theseunderexplored detection tasks.,1
STRIP A Defence Against Trojan Attacks on Deep Neural Networks A recent trojan attack on deep neural network DNN models is one insidiousvariant of data poisoning attacks. Trojan attacks exploit an effective backdoorcreated in a DNN model by leveraging the difficulty in interpretability of thelearned model to misclassify any inputs signed with the attackers chosentrojan trigger. Since the trojan trigger is a secret guarded and exploited bythe attacker detecting such trojan inputs is a challenge especially atruntime when models are in active operation. This work builds STRongIntentional Perturbation STRIP based runtime trojan attack detection systemand focuses on vision system. We intentionally perturb the incoming input forinstance by superimposing various image patterns and observe the randomness ofpredicted classes for perturbed inputs from a given deployed modelmaliciousor benign. A low entropy in predicted classes violates the inputdependenceproperty of a benign model and implies the presence of a malicious inputacharacteristic of a trojaned input. The high efficacy of our method isvalidated through case studies on three popular and contrasting datasetsMNIST CIFAR and GTSRB. We achieve an overall false acceptance rate FAR ofless than  given a preset false rejection rate FRR of  for differenttypes of triggers. Using CIFAR and GTSRB we have empirically achieved resultof  for both FRR and FAR. We have also evaluated STRIP robustness against anumber of trojan attack variants and adaptive attacks.,1
Robust Calibration with Multidomain Temperature Scaling Uncertainty quantification is essential for the reliable deployment ofmachine learning models to highstakes application domains. Uncertaintyquantification is all the more challenging when training distribution and testdistribution are different even the distribution shifts are mild. Despite theubiquity of distribution shifts in realworld applications existinguncertainty quantification approaches mainly study the indistribution settingwhere the train and test distributions are the same. In this paper we developa systematic calibration model to handle distribution shifts by leveraging datafrom multiple domains. Our proposed method  multidomain temperature scaling uses the heterogeneity in the domains to improve calibration robustnessunder distribution shift. Through experiments on three benchmark data sets wefind our proposed method outperforms existing methods as measured on bothindistribution and outofdistribution test sets.,1
A Simple Unified Framework for Detecting OutofDistribution Samples and Adversarial Attacks Detecting test samples drawn sufficiently far away from the trainingdistribution statistically or adversarially is a fundamental requirement fordeploying a good classifier in many realworld machine learning applications.However deep neural networks with the softmax classifier are known to producehighly overconfident posterior distributions even for such abnormal samples. Inthis paper we propose a simple yet effective method for detecting any abnormalsamples which is applicable to any pretrained softmax neural classifier. Weobtain the class conditional Gaussian distributions with respect to low andupperlevel features of the deep models under Gaussian discriminant analysiswhich result in a confidence score based on the Mahalanobis distance. Whilemost prior methods have been evaluated for detecting either outofdistributionor adversarial samples but not both the proposed method achieves thestateoftheart performances for both cases in our experiments. Moreover wefound that our proposed method is more robust in harsh cases e.g. when thetraining dataset has noisy labels or small number of samples. Finally we showthat the proposed method enjoys broader usage by applying it toclassincremental learning whenever outofdistribution samples are detectedour classification rule can incorporate new classes well without furthertraining deep models.,1
Universal Litmus Patterns Revealing Backdoor Attacks in CNNs The unprecedented success of deep neural networks in many applications hasmade these networks a prime target for adversarial exploitation. In this paperwe introduce a benchmark technique for detecting backdoor attacks aka Trojanattacks on deep convolutional neural networks CNNs. We introduce the conceptof Universal Litmus Patterns ULPs which enable one to reveal backdoorattacks by feeding these universal patterns to the network and analyzing theoutput i.e. classifying the network as clean or corrupted. Thisdetection is fast because it requires only a few forward passes through a CNN.We demonstrate the effectiveness of ULPs for detecting backdoor attacks onthousands of networks with different architectures trained on four benchmarkdatasets namely the German Traffic Sign Recognition Benchmark GTSRB MNISTCIFAR and TinyImageNet. The codes and traintest models for this paper canbe found here,1
ViM OutOfDistribution with Virtuallogit Matching Most of the existing OutOfDistribution OOD detection algorithms depend onsingle input source the feature the logit or the softmax probability.However the immense diversity of the OOD examples makes such methods fragile.There are OOD samples that are easy to identify in the feature space while hardto distinguish in the logit space and vice versa. Motivated by thisobservation we propose a novel OOD scoring method named Virtuallogit MatchingViM which combines the classagnostic score from feature space and theInDistribution ID classdependent logits. Specifically an additional logitrepresenting the virtual OOD class is generated from the residual of thefeature against the principal space and then matched with the original logitsby a constant scaling. The probability of this virtual logit after softmax isthe indicator of OODness. To facilitate the evaluation of largescale OODdetection in academia we create a new OOD dataset for ImageNetK which ishumanannotated and is .x the size of existing datasets. We conductedextensive experiments including CNNs and vision transformers to demonstratethe effectiveness of the proposed ViM score. In particular using the BiTSmodel our method gets an average AUROC . on four difficult OODbenchmarks which is  ahead of the best baseline. Code and dataset areavailable at,1
BackdoorBench A Comprehensive Benchmark of Backdoor Learning Backdoor learning is an emerging and important topic of studying thevulnerability of deep neural networks DNNs. Many pioneering backdoor attackand defense methods are being proposed successively or concurrently in thestatus of a rapid arms race. However we find that the evaluations of newmethods are often unthorough to verify their claims and real performancemainly due to the rapid development diverse settings as well as thedifficulties of implementation and reproducibility. Without thoroughevaluations and comparisons it is difficult to track the current progress anddesign the future development roadmap of the literature. To alleviate thisdilemma we build a comprehensive benchmark of backdoor learning calledBackdoorBench. It consists of an extensible modular based codebase currentlyincluding implementations of  stateoftheart SOTA attack and  SOTAdefense algorithms as well as a standardized protocol of a complete backdoorlearning. We also provide comprehensive evaluations of every pair of  attacksagainst  defenses with  poisoning ratios based on  models and  datasetsthus  pairs of evaluations in total. We further present analysis fromdifferent perspectives about these  evaluations studying the effects ofattack against defense algorithms poisoning ratio model and dataset inbackdoor learning. All codes and evaluations of BackdoorBench are publiclyavailable at url,1
Can Backdoor Attacks Survive TimeVarying Models Backdoors are powerful attacks against deep neural networks DNNs. Bypoisoning training data attackers can inject hidden rules backdoors intoDNNs which only activate on inputs containing attackspecific triggers. Whileexisting work has studied backdoor attacks on a variety of DNN models theyonly consider static models which remain unchanged after initial deployment.,1
Understanding GamePlaying Agents with Natural Language Annotations We present a new dataset containing K humanannotated games of Go and showhow these natural language annotations can be used as a tool for modelinterpretability. Given a board state and its associated comment our approachuses linear probing to predict mentions of domainspecific terms e.g. koatari from the intermediate state representations of gameplaying agents likeAlphaGo Zero. We find these game concepts are nontrivially encoded in twodistinct policy networks one trained via imitation learning and anothertrained via reinforcement learning. Furthermore mentions of domainspecificterms are most easily predicted from the later layers of both modelssuggesting that these policy networks encode highlevel abstractions similar tothose used in the natural language annotations.,1
Interpretable Explanations of Black Boxes by Meaningful Perturbation As machine learning algorithms are increasingly applied to high impact yethigh risk tasks such as medical diagnosis or autonomous driving it iscritical that researchers can explain how such algorithms arrived at theirpredictions. In recent years a number of image saliency methods have beendeveloped to summarize where highly complex neural networks look in an imagefor evidence for their predictions. However these techniques are limited bytheir heuristic nature and architectural constraints. In this paper we maketwo main contributions First we propose a general framework for learningdifferent kinds of explanations for any black box algorithm. Second wespecialise the framework to find the part of an image most responsible for aclassifier decision. Unlike previous works our method is modelagnostic andtestable because it is grounded in explicit and interpretable imageperturbations.,1
Adversarial Text Normalization Textbased adversarial attacks are becoming more commonplace and accessibleto general internet users. As these attacks proliferate the need to addressthe gap in model robustness becomes imminent. While retraining on adversarialdata may increase performance there remains an additional class ofcharacterlevel attacks on which these models falter. Additionally the processto retrain a model is time and resource intensive creating a need for alightweight reusable defense. In this work we propose the Adversarial TextNormalizer a novel method that restores baseline performance on attackedcontent with low computational overhead. We evaluate the efficacy of thenormalizer on two problem areas prone to adversarial attacks i.e. Hate Speechand Natural Language Inference. We find that text normalization provides ataskagnostic defense against characterlevel attacks that can be implementedsupplementary to adversarial retraining solutions which are more suited forsemantic alterations.,2
Adversarial Robustness is at Odds with Lazy Training Recent works show that random neural networks are vulnerable againstadversarial attacks Daniely and Schacham  and that such attacks can beeasily found using a single step of gradient descent Bubeck et al. . Inthis work we take it one step further and show that a single gradient step canfind adversarial examples for networks trained in the socalled lazy regime.This regime is interesting because even though the neural network weightsremain close to the initialization there exist networks with smallgeneralization error which can be found efficiently using firstorder methods.Our work challenges the model of the lazy regime the dominant regime in whichneural networks are provably efficiently learnable. We show that the networkstrained in this regime even though they enjoy good theoretical computationalguarantees remain vulnerable to adversarial examples. To the best of ourknowledge this is the first work to prove that such wellgeneralizable neuralnetworks are still vulnerable to adversarial attacks.,2
Distinction Maximization Loss Efficiently Improving Classification Accuracy Uncertainty Estimation and OutofDistribution Detection Simply Replacing the Loss and Calibrating Building robust deterministic neural networks remains a challenge. On the onehand some approaches improve outofdistribution detection at the cost ofreducing classification accuracy in some situations. On the other hand somemethods simultaneously increase classification accuracy uncertaintyestimation and outofdistribution detection at the expense of reducing theinference efficiency and requiring training the same model many times to tunehyperparameters. In this paper we propose training deterministic neuralnetworks using our DisMax loss which works as a dropin replacement for theusual SoftMax loss i.e. the combination of the linear output layer theSoftMax activation and the crossentropy loss. Starting from the IsoMaxloss we create each logit based on the distances to all prototypes rather thanjust the one associated with the correct class. We also introduce a mechanismto combine images to construct what we call fractional probabilityregularization. Moreover we present a fast way to calibrate the network aftertraining. Finally we propose a composite score to perform outofdistributiondetection. Our experiments show that DisMax usually outperforms currentapproaches simultaneously in classification accuracy uncertainty estimationand outofdistribution detection while maintaining deterministic neuralnetwork inference efficiency and avoiding training the same model repetitivelyfor hyperparameter tuning. The code to reproduce the results is available at,2
Robustness of Epinets against Distributional Shifts Recent work introduced the epinet as a new approach to uncertainty modelingin deep learning. An epinet is a small neural network added to traditionalneural networks which together can produce predictive distributions. Inparticular using an epinet can greatly improve the quality of jointpredictions across multiple inputs a measure of how well a neural networkknows what it does not know. In this paper we examine whether epinets canoffer similar advantages under distributional shifts. We find that acrossImageNetAOC epinets generally improve robustness metrics. Moreover theseimprovements are more significant than those afforded by even very largeensembles at orders of magnitude lower computational costs. However theseimprovements are relatively small compared to the outstanding issues indistributionallyrobust deep learning. Epinets may be a useful tool in thetoolbox but they are far from the complete solution.,2
Demystifying the Adversarial Robustness of Random Transformation Defenses Neural networks lack of robustness against attacks raises concerns insecuritysensitive settings such as autonomous vehicles. While manycountermeasures may look promising only a few withstand rigorous evaluation.Defenses using random transformations RT have shown impressive resultsparticularly BaRT Raff et al.  on ImageNet. However this type ofdefense has not been rigorously evaluated leaving its robustness propertiespoorly understood. Their stochastic properties make evaluation more challengingand render many proposed attacks on deterministic models inapplicable. Firstwe show that the BPDA attack Athalye et al. a used in BaRTs evaluationis ineffective and likely overestimates its robustness. We then attempt toconstruct the strongest possible RT defense through the informed selection oftransformations and Bayesian optimization for tuning their parameters.Furthermore we create the strongest possible attack to evaluate our RTdefense. Our new attack vastly outperforms the baseline reducing the accuracyby  compared to the  reduction by the commonly used EoT attack.times improvement. Our result indicates that the RT defense on theImagenette dataset a tenclass subset of ImageNet is not robust againstadversarial examples. Extending the study further we use our new attack toadversarially train RT defense called AdvRT resulting in a large robustnessgain. Code is available at,2
A law of adversarial risk interpolation and label noise In supervised learning it has been shown that label noise in the data can beinterpolated without penalties on test accuracy under many circumstances. Weshow that interpolating label noise induces adversarial vulnerability andprove the first theorem showing the dependence of label noise and adversarialrisk in terms of the data distribution. Our results are almost sharp withoutaccounting for the inductive bias of the learning algorithm. We also show thatinductive bias makes the effect of label noise much stronger.,2
Universal Adversarial Triggers for Attacking and Analyzing NLP Adversarial examples highlight model vulnerabilities and are useful forevaluation and interpretation. We define universal adversarial triggersinputagnostic sequences of tokens that trigger a model to produce a specificprediction when concatenated to any input from a dataset. We propose agradientguided search over tokens which finds short trigger sequences e.g.one word for classification and four words for language modeling thatsuccessfully trigger the target prediction. For example triggers cause SNLIentailment accuracy to drop from . to .  of why questions inSQuAD to be answered to kill american people and the GPT language model tospew racist output even when conditioned on nonracial contexts. Furthermorealthough the triggers are optimized using whitebox access to a specific modelthey transfer to other models for all tasks we consider. Finally sincetriggers are inputagnostic they provide an analysis of global model behavior.For instance they confirm that SNLI models exploit dataset biases and help todiagnose heuristics learned by reading comprehension models.,2
Augmenting Softmax Information for Selective Classification with OutofDistribution Data Detecting outofdistribution OOD data is a task that is receiving anincreasing amount of research attention in the domain of deep learning forcomputer vision. However the performance of detection methods is generallyevaluated on the task in isolation rather than also considering potentialdownstream tasks in tandem. In this work we examine selective classificationin the presence of OOD data SCOD. That is to say the motivation fordetecting OOD samples is to reject them so their impact on the quality ofpredictions is reduced. We show under this task specification that existingposthoc methods perform quite differently compared to when evaluated only onOOD detection. This is because it is no longer an issue to conflateindistribution ID data with OOD data if the ID data is going to bemisclassified. However the conflation within ID data of correct and incorrectpredictions becomes undesirable. We also propose a novel method for SCODSoftmax Information Retaining Combination SIRC that augments softmaxbasedconfidence scores with featureagnostic information such that their ability toidentify OOD samples is improved without sacrificing separation between correctand incorrect ID predictions. Experiments on a wide variety of ImageNetscaledatasets and convolutional neural network architectures show that SIRC is ableto consistently match or outperform the baseline for SCOD whilst existing OODdetection methods fail to do so.,2
Motivating the Rules of the Game for Adversarial Example Research Advances in machine learning have led to broad deployment of systems withimpressive performance on important problems. Nonetheless these systems can beinduced to make errors on data that are surprisingly similar to examples thelearned system handles correctly. The existence of these errors raises avariety of questions about outofsample generalization and whether bad actorsmight use such examples to abuse deployed systems. As a result of thesesecurity concerns there has been a flurry of recent papers proposingalgorithms to defend against such malicious perturbations of correctly handledexamples. It is unclear how such misclassifications represent a different kindof security problem than other errors or even other attackerproduced examplesthat have no specific relationship to an uncorrupted input. In this paper weargue that adversarial example defense papers have to date mostly consideredabstract toy games that do not relate to any specific security concern.Furthermore defense papers have not yet precisely described all the abilitiesand limitations of attackers that would be relevant in practical security.Towards this end we establish a taxonomy of motivations constraints andabilities for more plausible adversaries. Finally we provide a series ofrecommendations outlining a path forward for future work to more clearlyarticulate the threat model and perform more meaningful evaluation.,2
Natural Adversarial Examples We introduce two challenging datasets that reliably cause machine learningmodel performance to substantially degrade. The datasets are collected with asimple adversarial filtration technique to create datasets with limitedspurious cues. Our datasets realworld unmodified examples transfer tovarious unseen models reliably demonstrating that computer vision models haveshared weaknesses. The first dataset is called ImageNetA and is like theImageNet test set but it is far more challenging for existing models. We alsocurate an adversarial outofdistribution detection dataset called ImageNetOwhich is the first outofdistribution detection dataset created for ImageNetmodels. On ImageNetA a DenseNet obtains around  accuracy an accuracydrop of approximately  and its outofdistribution detection performance onImageNetO is near random chance levels. We find that existing dataaugmentation techniques hardly boost performance and using other publictraining datasets provides improvements that are limited. However we find thatimprovements to computer vision architectures provide a promising path towardsrobust models.,2
Increasing Confidence in Adversarial Robustness Evaluations Hundreds of defenses have been proposed to make deep neural networks robustagainst minimal adversarial input perturbations. However only a handful ofthese defenses held up their claims because correctly evaluating robustness isextremely challenging Weak attacks often fail to find adversarial exampleseven if they unknowingly exist thereby making a vulnerable network lookrobust. In this paper we propose a test to identify weak attacks and thusweak defense evaluations. Our test slightly modifies a neural network toguarantee the existence of an adversarial example for every sample.Consequentially any correct attack must succeed in breaking this modifiednetwork. For eleven out of thirteen previouslypublished defenses the originalevaluation of the defense fails our test while stronger attacks that breakthese defenses pass it. We hope that attack unit tests  such as ours  will bea major component in future robustness evaluations and increase confidence inan empirical field that is currently riddled with skepticism.,2
Adversarial Training for HighStakes Reliability In the future powerful AI systems may be deployed in highstakes settingswhere a single failure could be catastrophic. One technique for improving AIsafety in highstakes settings is adversarial training which uses an adversaryto generate examples to train on in order to achieve better worstcaseperformance.,2
BERTATTACK Adversarial Attack Against BERT Using BERT Adversarial attacks for discrete data such as texts have been provedsignificantly more challenging than continuous data such as images since itis difficult to generate adversarial samples with gradientbased methods.Current successful attack methods for texts usually adopt heuristic replacementstrategies on the character or word level which remains challenging to findthe optimal solution in the massive space of possible combinations ofreplacements while preserving semantic consistency and language fluency. Inthis paper we propose textbfBERTAttack a highquality and effectivemethod to generate adversarial samples using pretrained masked language modelsexemplified by BERT. We turn BERT against its finetuned models and other deepneural models in downstream tasks so that we can successfully mislead thetarget models to predict incorrectly. Our method outperforms stateoftheartattack strategies in both success rate and perturb percentage while thegenerated adversarial samples are fluent and semantically preserved. Also thecost of calculation is low thus possible for largescale generations. The codeis available at,2
Streambased active learning with linear models The proliferation of automated data collection schemes and the advances insensorics are increasing the amount of data we are able to monitor inrealtime. However given the high annotation costs and the time required byquality inspections data is often available in an unlabeled form. This isfostering the use of active learning for the development of soft sensors andpredictive models. In production instead of performing random inspections toobtain product information labels are collected by evaluating the informationcontent of the unlabeled data. Several query strategy frameworks for regressionhave been proposed in the literature but most of the focus has been dedicatedto the static poolbased scenario. In this work we propose a new strategy forthe streambased scenario where instances are sequentially offered to thelearner which must instantaneously decide whether to perform the quality checkto obtain the label or discard the instance. The approach is inspired by theoptimal experimental design theory and the iterative aspect of thedecisionmaking process is tackled by setting a threshold on theinformativeness of the unlabeled data points. The proposed approach isevaluated using numerical simulations and the Tennessee Eastman Processsimulator. The results confirm that selecting the examples suggested by theproposed algorithm allows for a faster reduction in the prediction error.,2
Obfuscated Gradients Give a False Sense of Security Circumventing Defenses to Adversarial Examples We identify obfuscated gradients a kind of gradient masking as a phenomenonthat leads to a false sense of security in defenses against adversarialexamples. While defenses that cause obfuscated gradients appear to defeatiterative optimizationbased attacks we find defenses relying on this effectcan be circumvented. We describe characteristic behaviors of defensesexhibiting the effect and for each of the three types of obfuscated gradientswe discover we develop attack techniques to overcome it. In a case studyexamining noncertified whiteboxsecure defenses at ICLR  we findobfuscated gradients are a common occurrence with  of  defenses relying onobfuscated gradients. Our new attacks successfully circumvent  completely and partially in the original threat model each paper considers.,2
Models Out of Line A Fourier Lens on Distribution Shift Robustness Improving the accuracy of deep neural networks DNNs on outofdistributionOOD data is critical to an acceptance of deep learning DL in real worldapplications. It has been observed that accuracies on indistribution IDversus OOD data follow a linear trend and models that outperform this baselineare exceptionally rare and referred to as effectively robust. Recentlysome promising approaches have been developed to improve OOD robustness modelpruning data augmentation and ensembling or zeroshot evaluating largepretrained models. However there still is no clear understanding of theconditions on OOD data and model properties that are required to observeeffective robustness. We approach this issue by conducting a comprehensiveempirical study of diverse approaches that are known to impact OOD robustnesson a broad range of natural and synthetic distribution shifts of CIFAR andImageNet. In particular we view the effective robustness puzzle through aFourier lens and ask how spectral properties of both models and OOD datainfluence the corresponding effective robustness. We find this Fourier lensoffers some insight into why certain robust models particularly those from theCLIP family achieve OOD robustness. However our analysis also makes clearthat no known metric is consistently the best explanation or even a strongexplanation of OOD robustness. Thus to aid future research into the OODpuzzle we address the gap in publiclyavailable models with effectiverobustness by introducing a set of pretrained modelsRobustNetswith varyinglevels of OOD robustness.,2
WILDS A Benchmark of intheWild Distribution Shifts Distribution shifts  where the training distribution differs from the testdistribution  can substantially degrade the accuracy of machine learning MLsystems deployed in the wild. Despite their ubiquity in the realworlddeployments these distribution shifts are underrepresented in the datasetswidely used in the ML community today. To address this gap we present WILDS acurated benchmark of  datasets reflecting a diverse range of distributionshifts that naturally arise in realworld applications such as shifts acrosshospitals for tumor identification across camera traps for wildlifemonitoring and across time and location in satellite imaging and povertymapping. On each dataset we show that standard training yields substantiallylower outofdistribution than indistribution performance. This gap remainseven with models trained by existing methods for tackling distribution shiftsunderscoring the need for new methods for training models that are more robustto the types of distribution shifts that arise in practice. To facilitatemethod development we provide an opensource package that automates datasetloading contains default model architectures and hyperparameters andstandardizes evaluations. Code and leaderboards are available at,2
Adversarial Examples for Evaluating Reading Comprehension Systems Standard accuracy metrics indicate that reading comprehension systems aremaking rapid progress but the extent to which these systems truly understandlanguage remains unclear. To reward systems with real language understandingabilities we propose an adversarial evaluation scheme for the StanfordQuestion Answering Dataset SQuAD. Our method tests whether systems can answerquestions about paragraphs that contain adversarially inserted sentences whichare automatically generated to distract computer systems without changing thecorrect answer or misleading humans. In this adversarial setting the accuracyof sixteen published models drops from an average of  F score to when the adversary is allowed to add ungrammatical sequences of words averageaccuracy on four models decreases further to . We hope our insights willmotivate the development of new models that understand language more precisely.,2
On the Robustness of Safe Reinforcement Learning under Observational Perturbations Safe reinforcement learning RL trains a policy to maximize the task rewardwhile satisfying safety constraints. While prior works focus on the performanceoptimality we find that the optimal solutions of many safe RL problems are notrobust and safe against carefully designed observational perturbations. Weformally analyze the unique properties of designing effective state adversarialattackers in the safe RL setting. We show that baseline adversarial attacktechniques for standard RL tasks are not always effective for safe RL andproposed two new approaches  one maximizes the cost and the other maximizesthe reward. One interesting and counterintuitive finding is that the maximumreward attack is strong as it can both induce unsafe behaviors and make theattack stealthy by maintaining the reward. We further propose a more effectiveadversarial training framework for safe RL and evaluate it via comprehensiveexperiments. This work sheds light on the inherited connection betweenobservational robustness and safety in RL and provides a pioneer work forfuture safe RL studies.,2
Formulating Robustness Against Unforeseen Attacks Existing defenses against adversarial examples such as adversarial trainingtypically assume that the adversary will conform to a specific or known threatmodel such as ellp perturbations within a fixed budget. In this paper wefocus on the scenario where there is a mismatch in the threat model assumed bythe defense during training and the actual capabilities of the adversary attest time. We ask the question if the learner trains against a specificsource threat model when can we expect robustness to generalize to astronger unknown target threat model during testtime Our key contributionis to formally define the problem of learning and generalization with anunforeseen adversary which helps us reason about the increase in adversarialrisk from the conventional perspective of a known adversary. Applying ourframework we derive a generalization bound which relates the generalizationgap between source and target threat models to variation of the featureextractor which measures the expected maximum difference between extractedfeatures across a given threat model. Based on our generalization bound wepropose adversarial training with variation regularization ATVR whichreduces variation of the feature extractor across the source threat modelduring training. We empirically demonstrate that ATVR can lead to improvedgeneralization to unforeseen attacks during testtime compared to standardadversarial training on Gaussian and image datasets.,2
GSmooth Certified Robustness against Semantic Transformations via Generalized Randomized Smoothing Certified defenses such as randomized smoothing have shown promise towardsbuilding reliable machine learning systems against ellpnorm boundedattacks. However existing methods are insufficient or unable to provablydefend against semantic transformations especially those without closedformexpressions such as defocus blur and pixelate which are more common inpractice and often unrestricted. To fill up this gap we propose generalizedrandomized smoothing GSmooth a unified theoretical framework for certifyingrobustness against general semantic transformations via a novel dimensionaugmentation strategy. Under the GSmooth framework we present a scalablealgorithm that uses a surrogate imagetoimage network to approximate thecomplex transformation. The surrogate model provides a powerful tool forstudying the properties of semantic transformations and certifying robustness.Experimental results on several datasets demonstrate the effectiveness of ourapproach for robustness certification against multiple kinds of semantictransformations and corruptions which is not achievable by the alternativebaselines.,2
Towards Deep Learning Models Resistant to Adversarial Attacks Recent work has demonstrated that deep neural networks are vulnerable toadversarial examplesinputs that are almost indistinguishable from naturaldata and yet classified incorrectly by the network. In fact some of the latestfindings suggest that the existence of adversarial attacks may be an inherentweakness of deep learning models. To address this problem we study theadversarial robustness of neural networks through the lens of robustoptimization. This approach provides us with a broad and unifying view on muchof the prior work on this topic. Its principled nature also enables us toidentify methods for both training and attacking neural networks that arereliable and in a certain sense universal. In particular they specify aconcrete security guarantee that would protect against any adversary. Thesemethods let us train networks with significantly improved resistance to a widerange of adversarial attacks. They also suggest the notion of security againsta firstorder adversary as a natural and broad security guarantee. We believethat robustness against such welldefined classes of adversaries is animportant stepping stone towards fully resistant deep learning models. Code andpretrained models are available at,2
Gradientbased Adversarial Attacks against Text Transformers We propose the first generalpurpose gradientbased attack againsttransformer models. Instead of searching for a single adversarial example wesearch for a distribution of adversarial examples parameterized by acontinuousvalued matrix hence enabling gradientbased optimization. Weempirically demonstrate that our whitebox attack attains stateoftheartattack performance on a variety of natural language tasks. Furthermore we showthat a powerful blackbox transfer attack enabled by sampling from theadversarial distribution matches or exceeds existing methods while onlyrequiring hardlabel outputs.,2
Back to the Source DiffusionDriven TestTime Adaptation Testtime adaptation harnesses test inputs to improve the accuracy of a modeltrained on source data when tested on shifted target data. Existing methodsupdate the source model by retraining on each target domain. Whileeffective retraining is sensitive to the amount and order of the data and thehyperparameters for optimization. We instead update the target data byprojecting all test inputs toward the source domain with a generative diffusionmodel. Our diffusiondriven adaptation method DDA shares its models forclassification and generation across all domains. Both models are trained onthe source domain then fixed during testing. We augment diffusion with imageguidance and selfensembling to automatically decide how much to adapt. Inputadaptation by DDA is more robust than prior model adaptation approaches acrossa variety of corruptions architectures and data regimes on the ImageNetCbenchmark. With its inputwise updates DDA succeeds where model adaptationdegrades on too little data in small batches dependent data in nonuniformorder or mixed data with multiple corruptions.,2
Benchmarking Neural Network Robustness to Common Corruptions and Perturbations In this paper we establish rigorous benchmarks for image classifierrobustness. Our first benchmark ImageNetC standardizes and expands thecorruption robustness topic while showing which classifiers are preferable insafetycritical applications. Then we propose a new dataset called ImageNetPwhich enables researchers to benchmark a classifiers robustness to commonperturbations. Unlike recent robustness research this benchmark evaluatesperformance on common corruptions and perturbations not worstcase adversarialperturbations. We find that there are negligible changes in relative corruptionrobustness from AlexNet classifiers to ResNet classifiers. Afterward wediscover ways to enhance corruption and perturbation robustness. We even findthat a bypassed adversarial defense provides substantial common perturbationrobustness. Together our benchmarks may aid future work toward networks thatrobustly generalize.,2
Diffusion Models for Adversarial Purification Adversarial purification refers to a class of defense methods that removeadversarial perturbations using a generative model. These methods do not makeassumptions on the form of attack and the classification model and thus candefend preexisting classifiers against unseen threats. However theirperformance currently falls behind adversarial training methods. In this workwe propose DiffPure that uses diffusion models for adversarial purificationGiven an adversarial example we first diffuse it with a small amount of noisefollowing a forward diffusion process and then recover the clean image througha reverse generative process. To evaluate our method against strong adaptiveattacks in an efficient and scalable way we propose to use the adjoint methodto compute full gradients of the reverse generative process. Extensiveexperiments on three image datasets including CIFAR ImageNet and CelebAHQwith three classifier architectures including ResNet WideResNet and ViTdemonstrate that our method achieves the stateoftheart resultsoutperforming current adversarial training and adversarial purificationmethods often by a large margin. Project page,2
Intrinsic dimension estimation for discrete metrics Real worlddatasets characterized by discrete features are ubiquitous fromcategorical surveys to clinical questionnaires from unweighted networks to DNAsequences. Nevertheless the most common unsupervised dimensional reductionmethods are designed for continuous spaces and their use for discrete spacescan lead to errors and biases. In this letter we introduce an algorithm toinfer the intrinsic dimension ID of datasets embedded in discrete spaces. Wedemonstrate its accuracy on benchmark datasets and we apply it to analyze ametagenomic dataset for species fingerprinting finding a surprisingly smallID of order . This suggests that evolutive pressure acts on a lowdimensionalmanifold despite the highdimensionality of sequences space.,2
Data Augmentation Can Improve Robustness Adversarial training suffers from robust overfitting a phenomenon where therobust test accuracy starts to decrease during training. In this paper wefocus on reducing robust overfitting by using common data augmentation schemes.We demonstrate that contrary to previous findings when combined with modelweight averaging data augmentation can significantly boost robust accuracy.Furthermore we compare various augmentations techniques and observe thatspatial composition techniques work the best for adversarial training. Finallywe evaluate our approach on CIFAR against ellinfty and ellnormbounded perturbations of size epsilon   and epsilon  respectively. We show large absolute improvements of . and . inrobust accuracy compared to previous stateoftheart methods. In particularagainst ellinfty normbounded perturbations of size epsilon  our model reaches . robust accuracy without using any external data. Wealso achieve a significant performance boost with this approach while usingother architectures and datasets such as CIFAR SVHN and TinyImageNet.,2
ImageNettrained CNNs are biased towards texture increasing shape bias improves accuracy and robustness Convolutional Neural Networks CNNs are commonly thought to recogniseobjects by learning increasingly complex representations of object shapes. Somerecent studies suggest a more important role of image textures. We here putthese conflicting hypotheses to a quantitative test by evaluating CNNs andhuman observers on images with a textureshape cue conflict. We show thatImageNettrained CNNs are strongly biased towards recognising textures ratherthan shapes which is in stark contrast to human behavioural evidence andreveals fundamentally different classification strategies. We then demonstratethat the same standard architecture ResNet that learns a texturebasedrepresentation on ImageNet is able to learn a shapebased representationinstead when trained on StylizedImageNet a stylized version of ImageNet.This provides a much better fit for human behavioural performance in ourwellcontrolled psychophysical lab setting nine experiments totalling psychophysical trials across  observers and comes with a number ofunexpected emergent benefits such as improved object detection performance andpreviously unseen robustness towards a wide range of image distortionshighlighting advantages of a shapebased representation.,2
Probable Domain Generalization via Quantile Risk Minimization Domain generalization DG seeks predictors which perform well on unseen testdistributions by leveraging labeled training data from multiple relateddistributions or domains. To achieve this the standard formulation optimizesfor worstcase performance over the set of all possible domains. However withworstcase shifts very unlikely in practice this generally leads tooverlyconservative solutions. In fact a recent study found that no DGalgorithm outperformed empirical risk minimization in terms of averageperformance. In this work we argue that DG is neither a worstcase problem noran averagecase problem but rather a probabilistic one. To this end wepropose a probabilistic framework for DG which we call Probable DomainGeneralization wherein our key idea is that distribution shifts seen duringtraining should inform us of probable shifts at test time. To realize this weexplicitly relate training and test domains as draws from the same underlyingmetadistribution and propose a new optimization problem  Quantile RiskMinimization QRM  which requires that predictors generalize with highprobability. We then prove that QRM i produces predictors that generalize tonew domains with a desired probability given sufficiently many domains andsamples and ii recovers the causal predictor as the desired probability ofgeneralization approaches one. In our experiments we introduce a more holisticquantilefocused evaluation protocol for DG and show that our algorithmsoutperform stateoftheart baselines on real and synthetic data.,2
GSCLIP  A Framework for Explaining Distribution Shifts in Natural Language Helping end users comprehend the abstract distribution shifts can greatlyfacilitate AI deployment. Motivated by this we propose a novel task datasetexplanation. Given two image data sets dataset explanation aims toautomatically point out their datasetlevel distribution shifts with naturallanguage. Current techniques for monitoring distribution shifts provideinadequate information to understand datasets with the goal of improving dataquality. Therefore we introduce GSCLIP a trainingfree framework to solve thedataset explanation task. In GSCLIP we propose the selector as the firstquantitative evaluation method to identify explanations that are proper tosummarize dataset shifts. Furthermore we leverage this selector to demonstratethe superiority of a generator based on language model generation. Systematicevaluation on natural data shift verifies that GSCLIP a combined system of ahybrid generator group and an efficient selector is not only easytouse butalso powerful for dataset explanation at scale.,2
Robustifying Vision Transformer without Retraining from Scratch by TestTime ClassConditional Feature Alignment Vision Transformer ViT is becoming more popular in image processing.Specifically we investigate the effectiveness of testtime adaptation TTA onViT a technique that has emerged to correct its prediction during testtime byitself. First we benchmark various testtime adaptation approaches on ViTBand ViTL. It is shown that the TTA is effective on ViT and thepriorconvention sensibly selecting modulation parameters is not necessarywhen using proper loss function. Based on the observation we propose a newtesttime adaptation method called classconditional feature alignment CFAwhich minimizes both the classconditional distribution differences and thewhole distribution differences of the hidden representation between the sourceand target in an online manner. Experiments of image classification tasks oncommon corruption CIFARC CIFARC and ImageNetC and domainadaptation digits datasets and ImageNetSketch show that CFA stablyoutperforms the existing baselines on various datasets. We also verify that CFAis model agnostic by experimenting on ResNet MLPMixer and several ViTvariants ViTAugReg DeiT and BeiT. Using BeiT backbone CFA achieves .top error rate on ImageNetC outperforming the existing testtime adaptationbaseline .. This is a stateoftheart result among TTA methods that do notneed to alter training phase.,2
SmoothReduce Leveraging Patches for Improved Certified Robustness Randomized smoothing RS has been shown to be a fast scalable technique forcertifying the robustness of deep neural network classifiers. However methodsbased on RS require augmenting data with large amounts of noise which leads tosignificant drops in accuracy. We propose a trainingfree modified smoothingapproach SmoothReduce that leverages patching and aggregation to provideimproved classifier certificates. Our algorithm classifies overlapping patchesextracted from an input image and aggregates the predicted logits to certify alarger radius around the input. We study two aggregation schemes  max andmean  and show that both approaches provide better certificates in terms ofcertified accuracy average certified radii and abstention rates as compared toconcurrent approaches. We also provide theoretical guarantees for suchcertificates and empirically show significant improvements over otherrandomized smoothing methods that require expensive retraining. Further weextend our approach to videos and provide meaningful certificates for videoclassifiers. A project page can be found at,2
AgreementontheLine Predicting the Performance of Neural Networks under Distribution Shift Recently Miller et al. showed that a models indistribution ID accuracyhas a strong linear correlation with its outofdistribution OOD accuracy onseveral OOD benchmarks  a phenomenon they dubbed accuracyontheline.While a useful tool for model selection i.e. the model most likely to performthe best OOD is the one with highest ID accuracy this fact does not helpestimate the actual OOD performance of models without access to a labeled OODvalidation set. In this paper we show a similar but surprising phenomenon alsoholds for the agreement between pairs of neural network classifiers wheneveraccuracyontheline holds we observe that the OOD agreement between thepredictions of any two pairs of neural networks with potentially differentarchitectures also observes a strong linear correlation with their IDagreement. Furthermore we observe that the slope and bias of OOD vs IDagreement closely matches that of OOD vs ID accuracy. This phenomenon which wecall agreementontheline has important practical applications without anylabeled data we can predict the OOD accuracy of classifiers since OODagreement can be estimated with just unlabeled data. Our prediction algorithmoutperforms previous methods both in shifts where agreementontheline holdsand surprisingly when accuracy is not on the line. This phenomenon alsoprovides new insights into deep neural networks unlike accuracyonthelineagreementontheline appears to only hold for neural network classifiers.,2
Reliable evaluation of adversarial robustness with an ensemble of diverse parameterfree attacks The field of defense strategies against adversarial attacks has significantlygrown over the last years but progress is hampered as the evaluation ofadversarial defenses is often insufficient and thus gives a wrong impression ofrobustness. Many promising defenses could be broken later on making itdifficult to identify the stateoftheart. Frequent pitfalls in the evaluationare improper tuning of hyperparameters of the attacks gradient obfuscation ormasking. In this paper we first propose two extensions of the PGDattackovercoming failures due to suboptimal step size and problems of the objectivefunction. We then combine our novel attacks with two complementary existingones to form a parameterfree computationally affordable and userindependentensemble of attacks to test adversarial robustness. We apply our ensemble toover  models from papers published at recent top machine learning andcomputer vision venues. In all except one of the cases we achieve lower robusttest accuracy than reported in these papers often by more than identifying several broken defenses.,2
HierarchicalForecast A Reference Framework for Hierarchical Forecasting in Python Large collections of time series data are commonly organized intocrosssectional structures with different levels of aggregation examplesinclude product and geographical groupings. A necessary condition for coherentdecisionmaking and planning with such datasets is for the disaggregatedseries forecasts to add up exactly to the aggregated series forecasts whichmotivates the creation of novel hierarchical forecasting algorithms. Thegrowing interest of the Machine Learning community in crosssectionalhierarchical forecasting systems states that we are in a propitious moment toensure that scientific endeavors are grounded on sound baselines. For thisreason we put forward the HierarchicalForecast library which containspreprocessed publicly available datasets evaluation metrics and a compiledset of statistical baseline models. Our Pythonbased framework aims to bridgethe gap between statistical econometric modeling and Machine Learningforecasting research. Code and documentation are available in,3
AnomalE A SelfSupervised Network Intrusion Detection System based on Graph Neural Networks This paper investigates Graph Neural Networks GNNs application forselfsupervised network intrusion and anomaly detection. GNNs are a deeplearning approach for graphbased data that incorporate graph structures intolearning to generalise graph representations and output embeddings. As networkflows are naturally graphbased GNNs are a suitable fit for analysing andlearning network behaviour. The majority of current implementations ofGNNbased Network Intrusion Detection Systems NIDSs rely heavily on labellednetwork traffic which can not only restrict the amount and structure of inputtraffic but also the NIDSs potential to adapt to unseen attacks. To overcomethese restrictions we present AnomalE a GNN approach to intrusion andanomaly detection that leverages edge features and graph topological structurein a selfsupervised process. This approach is to the best our knowledge thefirst successful and practical approach to network intrusion detection thatutilises network flows in a selfsupervised edge leveraging GNN. Experimentalresults on two modern benchmark NIDS datasets not only clearly display theimprovement of using AnomalE embeddings rather than raw features but also thepotential AnomalE has for detection on wild network traffic.,3
Asleep at the Keyboard Assessing the Security of GitHub Copilots Code Contributions There is burgeoning interest in designing AIbased systems to assist humansin designing computing systems including tools that automatically generatecomputer code. The most notable of these comes in the form of the firstselfdescribed AI pair programmer GitHub Copilot a language model trainedover opensource GitHub code. However code often contains bugs  and so giventhe vast quantity of unvetted code that Copilot has processed it is certainthat the language model will have learned from exploitable buggy code. Thisraises concerns on the security of Copilots code contributions. In this workwe systematically investigate the prevalence and conditions that can causeGitHub Copilot to recommend insecure code. To perform this analysis we promptCopilot to generate code in scenarios relevant to highrisk CWEs e.g. thosefrom MITREs Top  list. We explore Copilots performance on three distinctcode generation axes  examining how it performs given diversity ofweaknesses diversity of prompts and diversity of domains. In total weproduce  different scenarios for Copilot to complete producing programs. Of these we found approximately  to be vulnerable.,3
Open Problems in Cooperative AI Problems of cooperationin which agents seek ways to jointly improve theirwelfareare ubiquitous and important. They can be found at scales ranging fromour daily routinessuch as driving on highways scheduling meetings andworking collaborativelyto our global challengessuch as peace commerce andpandemic preparedness. Arguably the success of the human species is rooted inour ability to cooperate. Since machines powered by artificial intelligence areplaying an ever greater role in our lives it will be important to equip themwith the capabilities necessary to cooperate and to foster cooperation.,3
Forecasting Future World Events with Neural Networks Forecasting future world events is a challenging but valuable task. Forecastsof climate geopolitical conflict pandemics and economic indicators help shapepolicy and decision making. In these domains the judgment of expert humanscontributes to the best forecasts. Given advances in language modeling canthese forecasts be automated To this end we introduce Autocast a datasetcontaining thousands of forecasting questions and an accompanying news corpus.Questions are taken from forecasting tournaments ensuring high qualityrealworld importance and diversity. The news corpus is organized by dateallowing us to precisely simulate the conditions under which humans made pastforecasts avoiding leakage from the future. Motivated by the difficulty offorecasting numbers across orders of magnitude e.g. global cases of COVIDin  we also curate IntervalQA a dataset of numerical questions andmetrics for calibration. We test language models on our forecasting task andfind that performance is far below a human expert baseline. Howeverperformance improves with increased model size and incorporation of relevantinformation from the news corpus. In sum Autocast poses a novel challenge forlarge language models and improved performance could bring large practicalbenefits.,3
On Single Point Forecasts for FatTailed Variables We discuss common errors and fallacies when using naive evidence basedempiricism and point forecasts for fattailed variables as well as theinsufficiency of using naive firstorder scientific methods for tail riskmanagement. We use the COVID pandemic as the background for the discussionand as an example of a phenomenon characterized by a multiplicative nature andwhat mitigating policies must result from the statistical properties andassociated risks. In doing so we also respond to the points raised byIoannidis et al. .,3
AnoShift A Distribution Shift Benchmark for Unsupervised Anomaly Detection Analyzing the distribution shift of data is a growing research direction innowadays Machine Learning leading to emerging new benchmarks that focus onproviding a suitable scenario for studying the generalization properties of MLmodels. The existing benchmarks are focused on supervised learning and to thebest of our knowledge there is none for unsupervised learning. Therefore weintroduce an unsupervised anomaly detection benchmark with data that shiftsover time built over Kyoto a traffic dataset for network intrusiondetection. This kind of data meets the premise of shifting the inputdistribution it covers a large time span  years with naturallyoccurring changes over time eg users modifying their behavior patterns andsoftware updates. We first highlight the nonstationary nature of the datausing a basic perfeature analysis tSNE and an Optimal Transport approachfor measuring the overall distribution distances between years. Next wepropose AnoShift a protocol splitting the data in IID NEAR and FAR testingsplits. We validate the performance degradation over time with diverse modelsMLM to classical Isolation Forest. Finally we show that by acknowledging thedistribution shift problem and properly addressing it the performance can beimproved compared to the classical IID training by up to  on average.Dataset and code are available at,3
Robustness Evaluation of Deep Unsupervised Learning Algorithms for Intrusion Detection Systems Recently advances in deep learning have been observed in various fieldsincluding computer vision natural language processing and cybersecurity.Machine learning ML has demonstrated its ability as a potential tool foranomaly detectionbased intrusion detection systems to build secure computernetworks. Increasingly ML approaches are widely adopted than heuristicapproaches for cybersecurity because they learn directly from data. Data iscritical for the development of ML systems and becomes potential targets forattackers. Basically data poisoning or contamination is one of the most commontechniques used to fool ML models through data. This paper evaluates therobustness of six recent deep learning algorithms for intrusion detection oncontaminated data. Our experiments suggest that the stateoftheart algorithmsused in this study are sensitive to data contamination and reveal theimportance of selfdefense against data perturbation when developing novelmodels especially for intrusion detection systems.,3
Scalable Bayesian Inference for Detection and Deblending in Astronomical Images We present a new probabilistic method for detecting deblending andcataloging astronomical sources called the Bayesian Light Source SeparatorBLISS. BLISS is based on deep generative models which embed neural networkswithin a Bayesian model. For posterior inference BLISS uses a new form ofvariational inference known as Forward Amortized Variational Inference. TheBLISS inference routine is fast requiring a single forward pass of the encodernetworks on a GPU once the encoder networks are trained. BLISS can performfully Bayesian inference on megapixel images in seconds and produces highlyaccurate catalogs. BLISS is highly extensible and has the potential todirectly answer downstream scientific questions in addition to producingprobabilistic catalogs.,4
A Generative Framework for Personalized Learning and Estimation Theory Algorithms and Privacy A distinguishing characteristic of federated learning is that the localclient data could have statistical heterogeneity. This heterogeneity hasmotivated the design of personalized learning where individual personalizedmodels are trained through collaboration. There have been variouspersonalization methods proposed in literature with seemingly very differentforms and methods ranging from use of a single global model for localregularization and model interpolation to use of multiple global models forpersonalized clustering etc. In this work we begin with a generativeframework that could potentially unify several different algorithms as well assuggest new algorithms. We apply our generative framework to personalizedestimation and connect it to the classical empirical Bayes methodology. Wedevelop private personalized estimation under this framework. We then use ourgenerative framework for learning which unifies several known personalized FLalgorithms and also suggests new ones we propose and study a new algorithmAdaPeD based on a Knowledge Distillation which numerically outperforms severalknown algorithms. We also develop privacy for personalized learning methodswith guarantees for userlevel privacy and composition. We numerically evaluatethe performance as well as the privacy for both the estimation and learningproblems demonstrating the advantages of our proposed methods.,4
When does SGD favor flat minima A quantitative characterization via linear stability The observation that stochastic gradient descent SGD favors flat minima hasplayed a fundamental role in understanding implicit regularization of SGD andguiding the tuning of hyperparameters. In this paper we provide a quantitativeexplanation of this striking phenomenon by relating the particular noisestructure of SGD to its emphlinear stability Wu et al. .Specifically we consider training overparameterized models with square loss.We prove that if a global minimum theta is linearly stable for SGD thenit must satisfy HthetaFleq OsqrtBeta whereHthetaF Beta denote the Frobenius norm of Hessian at thetabatch size and learning rate respectively. Otherwise SGD will escape fromthat minimum emphexponentially fast. Hence for minima accessible to SGDthe flatness  as measured by the Frobenius norm of the Hessian  is boundedindependently of the model size and sample size. The key to obtaining theseresults is exploiting the particular geometry awareness of SGD noise  thenoise magnitude is proportional to loss value  the noise directionsconcentrate in the sharp directions of local landscape. This property of SGDnoise provably holds for linear networks and random feature models RFMs andis empirically verified for nonlinear networks. Moreover the validity andpractical relevance of our theoretical findings are justified by extensivenumerical experiments.,4
Holistic Robust DataDriven Decisions The design of datadriven formulations for machine learning anddecisionmaking with good outofsample performance is a key challenge. Theobservation that good insample performance does not guarantee goodoutofsample performance is generally known as overfitting. Practicaloverfitting can typically not be attributed to a single cause but instead iscaused by several factors all at once. We consider here three overfittingsources i statistical error as a result of working with finite sample dataii data noise which occurs when the data points are measured only with finiteprecision and finally iii data misspecification in which a small fraction ofall data may be wholly corrupted. We argue that although existing datadrivenformulations may be robust against one of these three sources in isolation theydo not provide holistic protection against all overfitting sourcessimultaneously. We design a novel datadriven formulation which does guaranteesuch holistic protection and is furthermore computationally viable. Ourdistributionally robust optimization formulation can be interpreted as a novelcombination of a KullbackLeibler and LevyProkhorov robust optimizationformulation. Finally we show how in the context of classification andregression problems several popular regularized and robust formulations reduceto a particular case of our proposed more general formulation.,4
FutureDependent ValueBased OffPolicy Evaluation in POMDPs We study offpolicy evaluation OPE for partially observable MDPs POMDPswith general function approximation. Existing methods such as sequentialimportance sampling estimators and fittedQ evaluation suffer from the curse ofhorizon in POMDPs. To circumvent this problem we develop a novel modelfreeOPE method by introducing futuredependent value functions that take futureproxies as inputs. Futuredependent value functions play similar roles asclassical value functions in fullyobservable MDPs. We derive a new Bellmanequation for futuredependent value functions as conditional moment equationsthat use history proxies as instrumental variables. We further propose aminimax learning method to learn futuredependent value functions using the newBellman equation. We obtain the PAC result which implies our OPE estimator isconsistent as long as futures and histories contain sufficient informationabout latent states and the Bellman completeness. Finally we extend ourmethods to learning of dynamics and establish the connection between ourapproach and the wellknown spectral learning methods in POMDPs.,4
Differentially Private Graph Learning via SensitivityBounded Personalized PageRank Personalized PageRank PPR is a fundamental tool in unsupervised learning ofgraph representations such as node ranking labeling and graph embedding.However while data privacy is one of the most important recent concernsexisting PPR algorithms are not designed to protect user privacy. PPR is highlysensitive to the input graph edges the difference of only one edge may cause abig change in the PPR vector potentially leaking private user data.,4
Multiple Robust Learning for Recommendation In recommender systems a common problem is the presence of various biases inthe collected data which deteriorates the generalization ability of therecommendation models and leads to inaccurate predictions. Doubly robust DRlearning has been studied in many tasks in RS with the advantage that unbiasedlearning can be achieved when either a single imputation or a single propensitymodel is accurate. In this paper we propose a multiple robust MR estimatorthat can take the advantage of multiple candidate imputation and propensitymodels to achieve unbiasedness. Specifically the MR estimator is unbiased whenany of the imputation or propensity models or a linear combination of thesemodels is accurate. Theoretical analysis shows that the proposed MR is anenhanced version of DR when only having a single imputation and propensitymodel and has a smaller bias. Inspired by the generalization error bound ofMR we further propose a novel multiple robust learning approach withstabilization. We conduct extensive experiments on realworld andsemisynthetic datasets which demonstrates the superiority of the proposedapproach over stateoftheart methods.,4
Black and Gray Box Learning of Amplitude Equations Application to Phase Field Systems We present a datadriven approach to learning surrogate models for amplitudeequations and illustrate its application to interfacial dynamics of phasefield systems. In particular we demonstrate learning effective partialdifferential equations describing the evolution of phase field interfaces fromfull phase field data. We illustrate this on a model phase field system whereanalytical approximate equations for the dynamics of the phase field interfacea higher order eikonal equation and its approximation the KardarParisiZhangKPZ equation are known. For this system we discuss datadriven approachesfor the identification of equations that accurately describe the frontinterface dynamics. When the analytical approximate models mentioned abovebecome inaccurate as we move beyond the region of validity of the underlyingassumptions the datadriven equations outperform them. In these regimes goingbeyond blackbox identification we explore different approaches to learndatadriven corrections to the analytically approximate models leading toeffective gray box partial differential equations.,4
Learning to Increase the Power of Conditional Randomization Tests The modelX conditional randomization test is a generic framework forconditional independence testing unlocking new possibilities to discoverfeatures that are conditionally associated with a response of interest whilecontrolling typeI error rates. An appealing advantage of this test is that itcan work with any machine learning model to design powerful test statistics. Inturn the common practice in the modelX literature is to form a test statisticusing machine learning models trained to maximize predictive accuracy with thehope to attain a test with good power. However the ideal goal here is to drivethe model during training to maximize the power of the test not merely thepredictive accuracy. In this paper we bridge this gap by introducing for thefirst time novel modelfitting schemes that are designed to explicitly improvethe power of modelX tests. This is done by introducing a new cost functionthat aims at maximizing the test statistic used to measure violations ofconditional independence. Using synthetic and real data sets we demonstratethat the combination of our proposed loss function with various base predictivemodels lasso elastic net and deep neural networks consistently increasesthe number of correct discoveries obtained while maintaining typeI errorrates under control.,4
Classifying Crop Types using Gaussian Bayesian Models and Neural Networks on GHISACONUS USGS data from NASA Hyperspectral Satellite Imagery Hyperspectral Imagining is a type of digital imaging in which each pixelcontains typically hundreds of wavelengths of light providing spectroscopicinformation about the materials present in the pixel. In this paper we provideclassification methods for determining crop type in the USGS GHISACONUS datawhich contains around  pixel spectra from the five major U.S. agriculturalcrops winter wheat rice corn soybeans and cotton collected by the NASAHyperion satellite and includes the spectrum geolocation crop type andstage of growth for each pixel. We apply standard LDA and QDA as well asBayesian custom versions that compute the joint probability of crop type andstage and then the marginal probability for crop type outperforming thenonBayesian methods. We also test a single layer neural network with dropouton the data which performs comparable to LDA and QDA but not as well as theBayesian methods.,4
Nonlinear Sufficient Dimension Reduction for DistributiononDistribution Regression We introduce a novel framework for nonlinear sufficient dimension reductionwhere both the predictor and the response are distributional data which aremodeled as members of a metric space. Our key step to achieving the nonlinearsufficient dimension reduction is to build universal kernels on the metricspaces which results in reproducing kernel Hilbert spaces for the predictorand response that are rich enough to characterize the conditional independencethat determines sufficient dimension reduction. For univariate distributionswe use the wellknown quantile representation of the Wasserstein distance toconstruct the universal kernel for multivariate distributions we resort tothe recently developed sliced Wasserstein distance to achieve this purpose.Since the sliced Wasserstein distance can be computed by aggregation ofquantile representation of the univariate Wasserstein distance the computationof multivariate Wasserstein distance is kept at a manageable level. The methodis applied to several data sets including fertility and mortality distributiondata and Calgary temperature data.,4
BRSNIS Bias Reduced SelfNormalized Importance Sampling Importance Sampling IS is a method for approximating expectations under atarget distribution using independent samples from a proposal distribution andthe associated importance weights. In many applications the targetdistribution is known only up to a normalization constant in which caseselfnormalized IS SNIS can be used. While the use of selfnormalization canhave a positive effect on the dispersion of the estimator it introduces bias.In this work we propose a new method BRSNIS whose complexity is essentiallythe same as that of SNIS and which significantly reduces bias withoutincreasing the variance. This method is a wrapper in the sense that it uses thesame proposal samples and importance weights as SNIS but makes clever use ofiterated samplingimportance resampling ISIR to form a biasreduced versionof the estimator. We furnish the proposed algorithm with rigorous theoreticalresults including new bias variance and highprobability bounds and theseare illustrated by numerical examples.,4
Employing Feature Selection Algorithms to Determine the Immune State of Mice with Rheumatoid Arthritis The immune response is a dynamic process by which the body determines whetheran antigen is self or nonself. The state of this dynamic process is defined bythe relative balance and population of inflammatory and regulatory actors whichcomprise this decision making process. The goal of immunotherapy as applied toe.g. Rheumatoid Arthritis RA then is to bias the immune state in favor ofthe regulatory actors  thereby shutting down autoimmune pathways in theresponse. While there are several known approaches to immunotherapy theeffectiveness of the therapy will depend on how this intervention alters theevolution of this state. Unfortunately this process is determined not only bythe dynamics of the process but the state of the system at the time ofintervention  a state which is difficult if not impossible to determine priorto application of the therapy.,4
MAPIE an opensource library for distributionfree uncertainty quantification Estimating uncertainties associated with the predictions of Machine LearningML models is of crucial importance to assess their robustness and predictivepower. In this submission we introduce MAPIE Model Agnostic PredictionInterval Estimator an opensource Python library that quantifies theuncertainties of ML models for singleoutput regression and multiclassclassification tasks. MAPIE implements conformal prediction methods allowingthe user to easily compute uncertainties with strong theoretical guarantees onthe marginal coverages and with mild assumptions on the model or on theunderlying data distribution. MAPIE is hosted on scikitlearncontrib and isfully scikitlearncompatible. As such it accepts any type of regressor orclassifier coming with a scikitlearn API. The library is available at,4
ASR Error Detection via AudioTranscript entailment Despite improved performances of the latest Automatic Speech RecognitionASR systems transcription errors are still unavoidable. These errors canhave a considerable impact in critical domains such as healthcare when used tohelp with clinical documentation. Therefore detecting ASR errors is a criticalfirst step in preventing further error propagation to downstream applications.To this end we propose a novel endtoend approach for ASR error detectionusing audiotranscript entailment. To the best of our knowledge we are thefirst to frame this problem as an endtoend entailment task between the audiosegment and its corresponding transcript segment. Our intuition is that thereshould be a bidirectional entailment between audio and transcript when there isno recognition error and vice versa. The proposed model utilizes an acousticencoder and a linguistic encoder to model the speech and transcriptrespectively. The encoded representations of both modalities are fused topredict the entailment. Since doctorpatient conversations are used in ourexperiments a particular emphasis is placed on medical terms. Our proposedmodel achieves classification error rates CER of . on all transcriptionerrors and  on medical errors specifically leading to improvements upon astrong baseline by  and . respectively.,4
Better Methods and Theory for Federated Learning Compression Client Selection and Heterogeneity Federated learning FL is an emerging machine learning paradigm involvingmultiple clients e.g. mobile phone devices with an incentive to collaboratein solving a machine learning problem coordinated by a central server. FL wasproposed in  by Konen et al. and McMahan et al. as a viableprivacypreserving alternative to traditional centralized machine learningsince by construction the training data points are decentralized and nevertransferred by the clients to a central server. Therefore to a certain degreeFL mitigates the privacy risks associated with centralized data collection.,4
Estimation of NonCrossing Quantile Regression Process with Deep ReQU Neural Networks We propose a penalized nonparametric approach to estimating the quantileregression process QRP in a nonseparable model using rectifier quadratic unitReQU activated deep neural networks and introduce a novel penalty function toenforce noncrossing of quantile regression curves. We establish thenonasymptotic excess risk bounds for the estimated QRP and derive the meanintegrated squared error for the estimated QRP under mild smoothness andregularity conditions. To establish these nonasymptotic risk and estimationerror bounds we also develop a new error bound for approximating Cs smoothfunctions with s  and their derivatives using ReQU activated neuralnetworks. This is a new approximation result for ReQU networks and is ofindependent interest and may be useful in other problems. Our numericalexperiments demonstrate that the proposed method is competitive with oroutperforms two existing methods including methods using reproducing kernelsand random forests for nonparametric quantile regression.,4
Estimating value at risk LSTM vs. GARCH Estimating valueatrisk on time series data with possibly heteroscedasticdynamics is a highly challenging task. Typically we face a small data problemin combination with a high degree of nonlinearity causing difficulties forboth classical and machinelearning estimation algorithms. In this paper wepropose a novel valueatrisk estimator using a long shortterm memory LSTMneural network and compare its performance to benchmark GARCH estimators.,4
Neural Stein critics with staged Lregularization Learning to differentiate model distributions from observed data is afundamental problem in statistics and machine learning and highdimensionaldata remains a challenging setting for such problems. Metrics that quantify thedisparity in probability distributions such as the Stein discrepancy play animportant role in statistical testing in high dimensions. In this paper weconsider the setting where one wishes to distinguish between data sampled froman unknown probability distribution and a nominal model distribution. Whilerecent studies revealed that the optimal Lregularized Stein critic equalsthe difference of the score functions of two probability distributions up to amultiplicative constant we investigate the role of L regularization whentraining a neural network Stein discrepancy critic function. Motivated by theNeural Tangent Kernel theory of training neural networks we develop a novelstaging procedure for the weight of regularization over training time. Thisleverages the advantages of highlyregularized training at early times whilealso empirically delaying overfitting. Theoretically we relate the trainingdynamic with large regularization weight to the kernel regression optimizationof lazy training regime in early training times. The benefit of the stagedL regularization is demonstrated on simulated high dimensional distributiondrift data and an application to evaluating generative models of image data.,4
Estimating Classification Confidence Using Kernel Densities This paper investigates the posthoc calibration of confidence forexploratory machine learning classification problems. The difficulty in theseproblems stems from the continuing desire to push the boundaries of whichcategories have enough examples to generalize from when curating datasets andconfusion regarding the validity of those categories. We argue that for suchproblems the oneversusall approach toplabel calibration must be usedrather than the calibratethefullresponsematrix approach advocatedelsewhere in the literature. We introduce and test four new algorithms designedto handle the idiosyncrasies of categoryspecific confidence estimation. Chiefamong these methods is the use of kernel density ratios for confidencecalibration including a novel bulletproof algorithm for choosing thebandwidth. We test our claims and explore the limits of calibration on abioinformatics application PhANNs as well as the classic MNIST benchmark.Finally our analysis argues that posthoc calibration should always beperformed should be based only on the test dataset and should besanitychecked visually.,4
Local manifold learning and its link to domainbased physics knowledge In many reacting flow systems the thermochemical statespace is known orassumed to evolve close to a lowdimensional manifold LDM. Various approachesare available to obtain those manifolds and subsequently express the originalhighdimensional space with fewer parameterizing variables. Principal componentanalysis PCA is one of the dimensionality reduction methods that can be usedto obtain LDMs. PCA does not make prior assumptions about the parameterizingvariables and retrieves them empirically from the training data. In this paperwe show that PCA applied in local clusters of data local PCA is capable ofdetecting the intrinsic parameterization of the thermochemical statespace. Wefirst demonstrate that utilizing three common combustion models of varyingcomplexity the BurkeSchumann model the chemical equilibrium model and thehomogeneous reactor. Parameterization of these models is known a priori whichallows for benchmarking with the local PCA approach. We further extend theapplication of local PCA to a more challenging case of a turbulent nonpremixednheptaneair jet flame for which the parameterization is no longer obvious.Our results suggest that meaningful parameterization can be obtained also formore complex datasets. We show that local PCA finds variables that can belinked to local stoichiometry reaction progress and soot formation processes.,4
Intrinsic dimension estimation for discrete metrics Real worlddatasets characterized by discrete features are ubiquitous fromcategorical surveys to clinical questionnaires from unweighted networks to DNAsequences. Nevertheless the most common unsupervised dimensional reductionmethods are designed for continuous spaces and their use for discrete spacescan lead to errors and biases. In this letter we introduce an algorithm toinfer the intrinsic dimension ID of datasets embedded in discrete spaces. Wedemonstrate its accuracy on benchmark datasets and we apply it to analyze ametagenomic dataset for species fingerprinting finding a surprisingly smallID of order . This suggests that evolutive pressure acts on a lowdimensionalmanifold despite the highdimensionality of sequences space.,4
Neural Posterior Estimation with Differentiable Simulators SimulationBased Inference SBI is a promising Bayesian inference frameworkthat alleviates the need for analytic likelihoods to estimate posteriordistributions. Recent advances using neural density estimators in SBIalgorithms have demonstrated the ability to achieve highfidelity posteriorsat the expense of a large number of simulations  which makes their applicationpotentially very timeconsuming when using complex physical simulations. Inthis work we focus on boosting the sampleefficiency of posterior densityestimation using the gradients of the simulator. We present a new method toperform Neural Posterior Estimation NPE with a differentiable simulator. Wedemonstrate how gradient information helps constrain the shape of the posteriorand improves sampleefficiency.,4
Stochastic Functional Analysis and Multilevel Vector Field Anomaly Detection Massive vector field datasets are common in multispectral optical and radarsensors and modern multimodal MRI data among many other areas of application.In this paper we develop a novel stochastic functional analysis approach fordetecting anomalies based on the covariance structure of nominal stochasticbehavior across a domain with multiband vector field data. An optimal vectorfield KarhunenLoeve KL expansion is applied to such random field data. Aseries of multilevel orthogonal functional subspaces is constructed from thegeometry of the domain adapted from the KL expansion. Detection is achieved byexamining the projection of the random field on the multilevel basis. Theanomalies can be quantified in suitable normed spaces based on local and globalinformation. In addition reliable hypothesis tests are formed withcontrollable distributions that do not require prior assumptions on probabilitydistributions of the data. Only the covariance function is needed which makesfor significantly simpler estimates. Furthermore this approach allowsstochastic vectorbased fusion of anomalies without any loss of information.The method is applied to the important problem of deforestation and degradationin the Amazon forest. This is a complex nonmonotonic process as forests candegrade and recover. This particular problem is further compounded by thepresence of clouds that are hard to remove with current masking algorithms.Using multispectral satellite data from Sentinel  the multilevel filter isconstructed and anomalies are treated as deviations from the initial state ofthe forest. Forest anomalies are quantified with robust hypothesis tests anddistinguished from false variations such as cloud cover. Our approach shows theadvantage of using multiple bands of data in a vectorized complex leading tobetter anomaly detection beyond the capabilities of scalarbased methods.,4
Lagrangian Density SpaceTime Deep Neural Network Topology As a networkbased functional approximator we have proposed a LagrangianDensity SpaceTime Deep Neural Networks LDDNN topology. It is qualified forunsupervised training and learning to predict the dynamics of underlyingphysical science governed phenomena. The prototypical network respects thefundamental conservation laws of nature through the succinctly describedLagrangian and Hamiltonian density of the system by a given dataset ofgeneralized nonlinear partial differential equations. The objective is toparameterize the Lagrangian density over a neural network and directly learnfrom it through data instead of handcrafting an exact timedependent Actionsolution of Lagrangian density for the physical system. With this novelapproach can understand and open up the information inference aspect of theBlackbox deep machine learning representation for the physical dynamics ofnature by constructing customtailored network interconnect topologiesactivation and losscost functions based on the underlying physicaldifferential operators. This article will discuss statistical physicsinterpretation of neural networks in the Lagrangian and Hamiltonian domains.,4
Improved Global Guarantees for the Nonconvex BurerMonteiro Factorization via Rank Overparameterization We consider minimizing a twicedifferentiable Lsmooth and mustronglyconvex objective phi over an ntimes n positive semidefinite matrixMsucceq under the assumption that the minimizer Mstar has low rankrstarll n. Following the BurerMonteiro approach we instead minimizethe nonconvex objective fXphiXXT over a factor matrix X of sizentimes r. This substantially reduces the number of variables from Onto as few as On and also enforces positive semidefiniteness for free butat the cost of giving up the convexity of the original problem. In this paperwe prove that if the search rank rge rstar is overparameterized by aconstant factor with respect to the true rank rstar namely as inrfracLmurstar then despite nonconvexity localoptimization is guaranteed to globally converge from any initial point to theglobal optimum. This significantly improves upon a previous rankoverparameterization threshold of rge n which is known to be sharp ifphi is allowed to be nonsmooth andor nonstrongly convex but wouldincrease the number of variables back up to On. Conversely withoutrank overparameterization we prove that such a global guarantee is possible ifand only if phi is almost perfectly conditioned with a condition number ofLmu. Therefore we conclude that a small amount of overparameterizationcan lead to large improvements in theoretical guarantees for the nonconvexBurerMonteiro factorization.,4
Finitetime Highprobability Bounds for PolyakRuppert Averaged Iterates of Linear Stochastic Approximation This paper provides a finitetime analysis of linear stochastic approximationLSA algorithms with fixed step size a core method in statistics and machinelearning. LSA is used to compute approximate solutions of a ddimensionallinear system barmathbfA theta  barmathbfb for whichbarmathbfA barmathbfb can only be estimated throughasymptotically unbiased observationsmathbfAZnmathbfbZnn in mathbbN. We consider herethe case where Znn in mathbbN is an i.i.d. sequence or auniformly geometrically ergodic Markov chain and derive pmoments inequalityand high probability bounds for the iterates defined by LSA and itsPolyakRuppert averaged version. More precisely we establish bounds of orderp alpha toperatornamemixdp on the pth moment of thelast iterate of LSA. In this formula alpha is the step size of the procedureand toperatornamemix is the mixing time of the underlying chaintoperatornamemix in the i.i.d. setting. We then prove finitetimeinstancedependent bounds on the PolyakRuppert averaged sequence of iterates.These results are sharp in the sense that the leading term we obtain matchesthe local asymptotic minimax limit including tight dependence on theparameters dtoperatornamemix in the higher order terms.,4
Volatility Based Kernels and Moving Average Means for Accurate Forecasting with Gaussian Processes A broad class of stochastic volatility models are defined by systems ofstochastic differential equations. While these models have seen widespreadsuccess in domains such as finance and statistical climatology they typicallylack an ability to condition on historical data to produce a true posteriordistribution. To address this fundamental limitation we show how to recast aclass of stochastic volatility models as a hierarchical Gaussian process GPmodel with specialized covariance functions. This GP model retains theinductive biases of the stochastic volatility model while providing theposterior predictive distribution given by GP inference. Within this frameworkwe take inspiration from well studied domains to introduce a new class ofmodels Volt and Magpie that significantly outperform baselines in stock andwind speed forecasting and naturally extend to the multitask setting.,4
Do Not Sleep on Linear Models Simple and Interpretable Techniques Outperform Deep Learning for Sleep Scoring Over the last few years research in automatic sleep scoring has mainlyfocused on developing increasingly complex deep learning architectures.However recently these approaches achieved only marginal improvements oftenat the expense of requiring more data and more expensive training procedures.Despite all these efforts and their satisfactory performance automatic sleepstaging solutions are not widely adopted in a clinical context yet. We arguethat most deep learning solutions for sleep scoring are limited in theirrealworld applicability as they are hard to train deploy and reproduce.Moreover these solutions lack interpretability and transparency which areoften key to increase adoption rates. In this work we revisit the problem ofsleep stage classification using classical machine learning. Results show thatstateoftheart performance can be achieved with a conventional machinelearning pipeline consisting of preprocessing feature extraction and a simplemachine learning model. In particular we analyze the performance of a linearmodel and a nonlinear gradient boosting model. Our approach surpassesstateoftheart that uses the same data on two public datasets SleepEDFSC MF . and SleepEDF ST MF . while achieving competitiveresults on SleepEDF SC MF . and MASS SS MF .. We show thatfor the sleep stage scoring task the expressiveness of an engineered featurevector is on par with the internally learned representations of deep learningmodels. This observation opens the door to clinical adoption as arepresentative feature vector allows to leverage both the interpretability andsuccessful track record of traditional machine learning models.,4
Switching OneVersustheRest Loss to Increase the Margin of Logits for Adversarial Robustness Defending deep neural networks against adversarial examples is a keychallenge for AI safety. To improve the robustness effectively recent methodsfocus on important data points near the decision boundary in adversarialtraining. However these methods are vulnerable to AutoAttack which is anensemble of parameterfree attacks for reliable evaluation. In this paper weexperimentally investigate the causes of their vulnerability and find thatexisting methods reduce margins between logits for the true label and the otherlabels while keeping their gradient norms nonsmall values. Reduced margins andnonsmall gradient norms cause their vulnerability since the largest logit canbe easily flipped by the perturbation. Our experiments also show that thehistogram of the logit margins has two peaks i.e. small and large logitmargins. From the observations we propose switching oneversustherest lossSOVR which uses oneversustherest loss when data have small logit marginsso that it increases the margins. We find that SOVR increases logit marginsmore than existing methods while keeping gradient norms small and outperformsthem in terms of the robustness against AutoAttack.,4
How do tuna schools associate to dFADs A study using echosounder buoys to identify global patterns Based on the data gathered by echosounder buoys attached to drifting FishAggregating Devices dFADs across tropical oceans the current study applies aMachine Learning protocol to examine the temporal trends of tuna schoolsassociation to drifting objects. Using a binary output metrics typically usedin the literature were adapted to account for the fact that the entire tunaaggregation under the dFAD was considered. The median time it took tuna tocolonize the dFADs for the first time varied between  and  days dependingon the ocean and the longest soak and colonization times were registered inthe Pacific Ocean. The tuna schools Continuous Residence Times were generallyshorter than Continuous Absence Times median values between  and  days and and  days respectively in line with the results found by previousstudies. Using a regression output two novel metrics namely aggregation timeand disaggregation time were estimated to obtain further insight into thesymmetry of the aggregation process. Across all oceans the time it took forthe tuna aggregation to depart from the dFADs was not significantly longer thanthe time it took for the aggregation to form. The value of these results in thecontext of the ecological trap hypothesis is discussed and further analysesto enrich and make use of this data source are proposed.,4
Contextual Decision Trees Focusing on Random Forests we propose a multiarmed contextual banditrecommendation framework for featurebased selection of a single shallow treeof the learned ensemble. The trained system which works on top of the RandomForest dynamically identifies a base predictor that is responsible forproviding the final output. In this way we obtain local interpretations byobserving the rules of the recommended tree. The carried out experiments revealthat our dynamic method is superior to an independent fitted CART decision treeand comparable to the whole blackbox Random Forest in terms of predictiveperformances.,4
Variational Inference for Additive Main and Multiplicative Interaction Effects Models In plant breeding the presence of a genotype by environment GxE interactionhas a strong impact on cultivation decision making and the introduction of newcrop cultivars. The combination of linear and bilinear terms has been shown tobe very useful in modelling this type of data. A widelyused approach toidentify GxE is the Additive Main Effects and Multiplicative InteractionEffects AMMI model. However as data frequently can be highdimensionalMarkov chain Monte Carlo MCMC approaches can be computationally infeasible.In this article we consider a variational inference approach for such a model.We derive variational approximations for estimating the parameters and wecompare the approximations to MCMC using both simulated and real data. The newinferential framework we propose is on average two times faster whilstmaintaining the same predictive performance as MCMC.,4
Learning Counterfactually Invariant Predictors We propose a method to learn predictors that are invariant undercounterfactual changes of certain covariates. This method is useful when theprediction target is causally influenced by covariates that should not affectthe predictor output. For instance an object recognition model may beinfluenced by position orientation or scale of the object itself. We addressthe problem of training predictors that are explicitly counterfactuallyinvariant to changes of such covariates. We propose a modelagnosticregularization term based on conditional kernel mean embeddings to enforcecounterfactual invariance during training. We prove the soundness of ourmethod which can handle mixed categorical and continuous multivariateattributes. Empirical results on synthetic and realworld data demonstrate theefficacy of our method in a variety of settings.,4
The Cosmic Graph Optimal Information Extraction from LargeScale Structure using Catalogues We present an implicit likelihood approach to quantifying cosmologicalinformation over discrete catalogue data assembled as graphs. To do so weexplore cosmological inference using mock dark matter halo catalogues. Weemploy Information Maximising Neural Networks IMNNs to quantify Fisherinformation extraction as a function of graph representation. We a demonstratethe high sensitivity of modular graph structure to the underlying cosmology inthe noisefree limit b show that networks automatically combine mass andclustering information through comparisons to traditional statistics cdemonstrate that graph neural networks can still extract information whencatalogues are subject to noisy survey cuts and d illustrate how nonlinearIMNN summaries can be used as asymptotically optimal compressed statistics forBayesian implicit likelihood inference. We reduce the area of joint Omegamsigma parameter constraints with small sim object halo cataloguesby a factor of  over the twopoint correlation function and demonstrate thatthe networks automatically combine mass and clustering information. This workutilises a new IMNN implementation over graph data in Jax which can takeadvantage of either numerical or autodifferentiability. We also show thatgraph IMNNs successfully compress simulations far from the fiducial model atwhich the network is fitted indicating a promising alternative to npointstatistics in cataloguebased analyses.,4
Statistical Inference with Stochastic Gradient Algorithms Stochastic gradient algorithms are widely used for both optimization andsampling in largescale learning and inference problems. However in practicetuning these algorithms is typically done using heuristics and trialanderrorrather than rigorous generalizable theory. To address this gap between theoryand practice we novel insights into the effect of tuning parameters bycharacterizing the largesample behavior of iterates of a very general class ofpreconditioned stochastic gradient algorithms with fixed step size. In theoptimization setting our results show that iterate averaging with a largefixed step size can result in statistically efficient approximation of thelocal Mestimator. In the sampling context our results show that withappropriate choices of tuning parameters the limiting stationary covariancecan match either the Bernsteinvon Mises limit of the posterior adjustmentsto the posterior for model misspecification or the asymptotic distribution ofthe MLE and that with a naive tuning the limit corresponds to none of these.Moreover we argue that an essentially independent sample from the stationarydistribution can be obtained after a fixed number of passes over the dataset.We validate our asymptotic results in realistic finitesample regimes viaseveral experiments using simulated and real data. Overall we demonstrate thatproperly tuned stochastic gradient algorithms with constant step size offer acomputationally efficient and statistically robust approach to obtaining pointestimates or posteriorlike samples.,4
The Union of Manifolds Hypothesis and its Implications for Deep Generative Modelling Deep learning has had tremendous success at learning lowdimensionalrepresentations of highdimensional data. This success would be impossible ifthere was no hidden lowdimensional structure in data of interest thisexistence is posited by the manifold hypothesis which states that the datalies on an unknown manifold of low intrinsic dimension. In this paper we arguethat this hypothesis does not properly capture the lowdimensional structuretypically present in data. Assuming the data lies on a single manifold impliesintrinsic dimension is identical across the entire data space and does notallow for subregions of this space to have a different number of factors ofvariation. To address this deficiency we put forth the union of manifoldshypothesis which accommodates the existence of nonconstant intrinsicdimensions. We empirically verify this hypothesis on commonlyused imagedatasets finding that indeed intrinsic dimension should be allowed to vary.We also show that classes with higher intrinsic dimensions are harder toclassify and how this insight can be used to improve classification accuracy.We then turn our attention to the impact of this hypothesis in the context ofdeep generative models DGMs. Most current DGMs struggle to model datasetswith several connected components andor varying intrinsic dimensions. Totackle these shortcomings we propose clustered DGMs where we first clusterthe data and then train a DGM on each cluster. We show that clustered DGMs canmodel multiple connected components with different intrinsic dimensions andempirically outperform their nonclustered counterparts without increasingcomputational requirements.,4
AGBoost Attentionbased Modification of Gradient Boosting Machine A new attentionbased model for the gradient boosting machine GBM calledAGBoost the attentionbased gradient boosting is proposed for solvingregression problems. The main idea behind the proposed AGBoost model is toassign attention weights with trainable parameters to iterations of GBM undercondition that decision trees are base learners in GBM. Attention weights aredetermined by applying properties of decision trees and by using the Huberscontamination model which provides an interesting linear dependence betweentrainable parameters of the attention and the attention weights. Thispeculiarity allows us to train the attention weights by solving the standardquadratic optimization problem with linear constraints. The attention weightsalso depend on the discount factor as a tuning parameter which determines howmuch the impact of the weight is decreased with the number of iterations.Numerical experiments performed for two types of base learners originaldecision trees and extremely randomized trees with various regression datasetsillustrate the proposed model.,4
ControlBurn Nonlinear Feature Selection with Sparse Tree Ensembles ControlBurn is a Python package to construct featuresparse tree ensemblesthat support nonlinear feature selection and interpretable machine learning.The algorithms in this package first build large tree ensembles that prioritizebasis functions with few features and then select a featuresparse subset ofthese basis functions using a weighted lasso optimization criterion. Thepackage includes visualizations to analyze the features selected by theensemble and their impact on predictions. Hence ControlBurn offers the accuracyand flexibility of treeensemble models and the interpretability of sparsegeneralized additive models.,4
Ranking in Contextual MultiArmed Bandits We study a ranking problem in the contextual multiarmed bandit setting. Alearning agent selects an ordered list of items at each time step and observesstochastic outcomes for each position. In online recommendation systemsshowing an ordered list of the most attractive items would not be the bestchoice since both position and item dependencies result in a complicated rewardfunction. A very naive example is the lack of diversity when all the mostattractive items are from the same category. We model position and itemdependencies in the ordered list and design UCB and Thompson Sampling typealgorithms for this problem. We prove that the regret bound over T rounds andL positions is TildeOLsqrtd T which has the same order as theprevious works with respect to T and only increases linearly with L. Ourwork generalizes existing studies in several directions including positiondependencies where position discount is a particular case and proposes a moregeneral contextual bandit model.,4
POET Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging Finetuning models on edge devices like mobile phones would enableprivacypreserving personalization over sensitive data. However edge traininghas historically been limited to relatively small models with simplearchitectures because training is both memory and energy intensive. We presentPOET an algorithm to enable training large neural networks on memoryscarcebatteryoperated edge devices. POET jointly optimizes the integrated searchsearch spaces of rematerialization and paging two algorithms to reduce thememory consumption of backpropagation. Given a memory budget and a runtimeconstraint we formulate a mixedinteger linear program MILP forenergyoptimal training. Our approach enables training significantly largermodels on embedded devices while reducing energy consumption while notmodifying mathematical correctness of backpropagation. We demonstrate that itis possible to finetune both ResNet and BERT within the memory constraintsof a CortexM class embedded device while outperforming current edge trainingmethods in energy efficiency. POET is an opensource project available at,4
A NewtonCG based barrier method for finding a secondorder stationary point of nonconvex conic optimization with complexity guarantees In this paper we consider finding an approximate secondorder stationarypoint SOSP of nonconvex conic optimization that minimizes a twicedifferentiable function over the intersection of an affine subspace and aconvex cone. In particular we propose a Newtonconjugate gradient NewtonCGbased barrier method for finding an epsilonsqrtepsilonSOSP of thisproblem. Our method is not only implementable but also achieves an iterationcomplexity of cal Oepsilon which matches the best knowniteration complexity of secondorder methods for finding anepsilonsqrtepsilonSOSP of unconstrained nonconvex optimization. Theoperation complexity of widetildecalOepsilonminnepsilon measured by the amount offundamental operations is also established for our method.,4
Efficient Realworld Testing of Causal Decision Making via Bayesian Experimental Design for Contextual Optimisation The realworld testing of decisions made using causal machine learning modelsis an essential prerequisite for their successful application. We focus onevaluating and improving contextual treatment assignment decisions these arepersonalised treatments applied to e.g. customers each with their owncontextual information with the aim of maximising a reward. In this paper weintroduce a modelagnostic framework for gathering data to evaluate and improvecontextual decision making through Bayesian Experimental Design. Specificallyour method is used for the dataefficient evaluation of the regret of pasttreatment assignments. Unlike approaches such as AB testing our method avoidsassigning treatments that are known to be highly suboptimal whilst engagingin some exploration to gather pertinent information. We achieve this byintroducing an informationbased design objective which we optimiseendtoend. Our method applies to discrete and continuous treatments. Comparingour informationtheoretic approach to baselines in several simulation studiesdemonstrates the superior performance of our proposed approach.,4
Quantum Advantage in Variational Bayes Inference Variational Bayes VB inference algorithm is used widely to estimate boththe parameters and the unobserved hidden variables in generative statisticalmodels. The algorithm  inspired by variational methods used in computationalphysics  is iterative and can get easily stuck in local minima even whenclassical techniques such as deterministic annealing DA are used. We studya variational Bayes VB inference algorithm based on a nontraditional quantumannealing approach  referred to as quantum annealing variational Bayes QAVBinference  and show that there is indeed a quantum advantage to QAVB over itsclassical counterparts. In particular we show that such better performance isrooted in key concepts from quantum mechanics i the ground state of theHamiltonian of a quantum system  defined from the given variational BayesVB problem  corresponds to an optimal solution for the minimization problemof the variational free energy at very low temperatures ii such a groundstate can be achieved by a technique paralleling the quantum annealing processand iii starting from this ground state the optimal solution to the VBproblem can be achieved by increasing the heat bath temperature to unity andthereby avoiding local minima introduced by spontaneous symmetry breakingobserved in classical physics based VB algorithms. We also show that the updateequations of QAVB can be potentially implemented using lceil log K rceilqubits and mathcalO K operations per step. Thus QAVB can match the timecomplexity of existing VB algorithms while delivering higher performance.,4
AMLB an AutoML Benchmark Comparing different AutoML frameworks is notoriously challenging and oftendone incorrectly. We introduce an open and extensible benchmark that followsbest practices and avoids common mistakes when comparing AutoML frameworks. Weconduct a thorough comparison of  wellknown AutoML frameworks across classification and  regression tasks. The differences between the AutoMLframeworks are explored with a multifaceted analysis evaluating modelaccuracy its tradeoffs with inference time and framework failures. We alsouse BradleyTerry trees to discover subsets of tasks where the relative AutoMLframework rankings differ. The benchmark comes with an opensource tool thatintegrates with many AutoML frameworks and automates the empirical evaluationprocess endtoend from framework installation and resource allocation toindepth evaluation. The benchmark uses public data sets can be easilyextended with other AutoML frameworks and tasks and has a website withuptodate results.,4
Latent Variable Models for Bayesian Causal Discovery Learning predictors that do not rely on spurious correlations involvesbuilding causal representations. However learning such a representation isvery challenging. We therefore formulate the problem of learning a causalrepresentation from high dimensional data and study causal recovery withsynthetic data. This work introduces a latent variable decoder model DecoderBCD for Bayesian causal discovery and performs experiments in mildlysupervised and unsupervised settings. We present a series of syntheticexperiments to characterize important factors for causal discovery and showthat using known intervention targets as labels helps in unsupervised Bayesianinference over structure and parameters of linear Gaussian additive noiselatent structural causal models.,4
Kernelbased Federated Learning with Personalization We consider federated learning with personalization where in addition to aglobal objective each client is also interested in maximizing a personalizedlocal objective. We consider this problem under a general continuous actionspace setting where the objective functions belong to a reproducing kernelHilbert space. We propose algorithms based on surrogate Gaussian process GPmodels that achieve the optimal regret order up to polylogarithmic factors.Furthermore we show that the sparse approximations of the GP modelssignificantly reduce the communication cost across clients.,4
Using ModelBased Trees with Boosting to Fit LowOrder Functional ANOVA Models Loworder functional ANOVA fANOVA models have been rediscovered in themachine learning ML community under the guise of inherently interpretablemachine learning. Explainable Boosting Machines or EBM Lou et al.  andGAMINet Yang et al.  are two recently proposed ML algorithms for fittingfunctional main effects and secondorder interactions. We propose a newalgorithm called GAMITree that is similar to EBM but has a number offeatures that lead to better performance. It uses modelbased trees as baselearners and incorporates a new interaction filtering method that is better atcapturing the underlying interactions. In addition our iterative trainingmethod converges to a model with better predictive performance and theembedded purification ensures that interactions are hierarchically orthogonalto main effects. The algorithm does not need extensive tuning and ourimplementation is fast and efficient. We use simulated and real datasets tocompare the performance and interpretability of GAMITree with EBM andGAMINet.,4
Personalized PCA Decoupling Shared and Unique Features In this paper we tackle a significant challenge in PCA heterogeneity. Whendata are collected from different sources with heterogeneous trends while stillsharing some congruency it is critical to extract shared knowledge whileretaining unique features of each source. To this end we propose personalizedPCA PerPCA which uses mutually orthogonal global and local principalcomponents to encode both unique and shared features. We show that under mildconditions both unique and shared features can be identified and recovered bya constrained optimization problem even if the covariance matrices areimmensely different. Also we design a fully federated algorithm inspired bydistributed Stiefel gradient descent to solve the problem. The algorithmintroduces a new group of operations called generalized retractions to handleorthogonality constraints and only requires global PCs to be shared acrosssources. We prove the linear convergence of the algorithm under suitableassumptions. Comprehensive numerical experiments highlight PerPCAs superiorperformance in feature extraction and prediction from heterogeneous datasets.As a systematic approach to decouple shared and unique features fromheterogeneous datasets PerPCA finds applications in several tasks includingvideo segmentation topic extraction and distributed clustering.,4
Learning Optimal Transport Between two Empirical Distributions with Normalizing Flows Optimal transport OT provides effective tools for comparing and mappingprobability measures. We propose to leverage the flexibility of neural networksto learn an approximate optimal transport map. More precisely we present a newand original method to address the problem of transporting a finite set ofsamples associated with a first underlying unknown distribution towards anotherfinite set of samples drawn from another unknown distribution. We show that aparticular instance of invertible neural networks namely the normalizingflows can be used to approximate the solution of this OT problem between apair of empirical distributions. To this aim we propose to relax the Mongeformulation of OT by replacing the equality constraint on the pushforwardmeasure by the minimization of the corresponding Wasserstein distance. Thepushforward operator to be retrieved is then restricted to be a normalizingflow which is trained by optimizing the resulting cost function. This approachallows the transport map to be discretized as a composition of functions. Eachof these functions is associated to one subflow of the network whose outputprovides intermediate steps of the transport between the original and targetmeasures. This discretization yields also a set of intermediate barycentersbetween the two measures of interest. Experiments conducted on toy examples aswell as a challenging task of unsupervised translation demonstrate the interestof the proposed method. Finally some experiments show that the proposedapproach leads to a good approximation of the true OT.,4
Exploration in Linear Bandits with Rich Action Sets and its Implications for Inference We present a nonasymptotic lower bound on the eigenspectrum of the designmatrix generated by any linear bandit algorithm with sublinear regret when theaction set has wellbehaved curvature. Specifically we show that the minimumeigenvalue of the expected design matrix grows as Omegasqrtn wheneverthe expected cumulative regret of the algorithm is Osqrtn where n isthe learning horizon and the actionspace has a constant Hessian around theoptimal arm. This shows that such actionspaces force a polynomial lower boundrather than a logarithmic lower bound as shown by citelattimoreend indiscrete i.e. wellseparated action spaces. Furthermore while the previousresult is shown to hold only in the asymptotic regime as n to infty ourresult for these locally rich action spaces is anytime. Additionally undera mild technical assumption we obtain a similar lower bound on the minimumeigen value holding with high probability.,4
Making Linear MDPs Practical via Contrastive Representation Learning It is common to address the curse of dimensionality in Markov decisionprocesses MDPs by exploiting lowrank representations. This motivates much ofthe recent theoretical study on linear MDPs. However most approaches require agiven representation under unrealistic assumptions about the normalization ofthe decomposition or introduce unresolved computational challenges in practice.Instead we consider an alternative definition of linear MDPs thatautomatically ensures normalization while allowing efficient representationlearning via contrastive estimation. The framework also admitsconfidenceadjusted index algorithms enabling an efficient and principledapproach to incorporating optimism or pessimism in the face of uncertainty. Tothe best of our knowledge this provides the first practical representationlearning method for linear MDPs that achieves both strong theoreticalguarantees and empirical performance. Theoretically we prove that the proposedalgorithm is sample efficient in both the online and offline settings.Empirically we demonstrate superior performance over existing stateoftheartmodelbased and modelfree algorithms on several benchmarks.,4
Fully Decentralized Modelbased Policy Optimization for Networked Systems Reinforcement learning algorithms require a large amount of samples thisoften limits their realworld applications on even simple tasks. Such achallenge is more outstanding in multiagent tasks as each step of operationis more costly requiring communications or shifting or resources. This workaims to improve data efficiency of multiagent control by modelbased learning.We consider networked systems where agents are cooperative and communicate onlylocally with their neighbors and propose the decentralized modelbased policyoptimization framework DMPO. In our method each agent learns a dynamic modelto predict future states and broadcast their predictions by communication andthen the policies are trained under the model rollouts. To alleviate the biasof modelgenerated data we restrain the model usage for generating myopicrollouts thus reducing the compounding error of model generation. To pertainthe independence of policy update we introduce extended value function andtheoretically prove that the resulting policy gradient is a close approximationto true policy gradients. We evaluate our algorithm on several benchmarks forintelligent transportation systems which are connected autonomous vehiclecontrol tasks Flow and CACC and adaptive traffic signal control ATSC.Empirically results show that our method achieves superior data efficiency andmatches the performance of modelfree methods using true models.,4
Adversarial SignCorrupted Isotonic Regression Classical univariate isotonic regression involves nonparametric estimationunder a monotonicity constraint of the true signal. We consider a variation ofthis generating process which we term adversarial signcorrupted isotonictextttASCI regression. Under this textttASCI setting the adversary hasfull access to the true isotonic responses and is free to signcorrupt them.Estimating the true monotonic signal given these signcorrupted responses is ahighly challenging task. Notably the signcorruptions are designed to violatemonotonicity and possibly induce heavy dependence between the corruptedresponse terms. In this sense textttASCI regression may be viewed as anadversarial stress test for isotonic regression. Our motivation is driven byunderstanding whether efficient robust estimation of the monotone signal isfeasible under this adversarial setting. We develop textttASCIFIT athreestep estimation procedure under the textttASCI setting. ThetextttASCIFIT procedure is conceptually simple easy to implement withexisting software and consists of applying the textttPAVA with crucial preand postprocessing corrections. We formalize this procedure and demonstrateits theoretical guarantees in the form of sharp high probability upper boundsand minimax lower bounds. We illustrate our findings with detailed simulations.,4
Supervising Embedding Algorithms Using the Stress While classical scaling just like principal component analysis isparameterfree most other methods for embedding multivariate data require theselection of one or several parameters. This tuning can be difficult due to theunsupervised nature of the situation. We propose a simple almost obviousapproach to supervise the choice of tuning parameters minimize a notion ofstress. We substantiate this choice by reference to rigidity theory. We extenda result by Aspnes et al. IEEE Mobile Computing  showing that generalrandom geometric graphs are trilateration graphs with high probability. And weprovide a stability result  la Anderson et al. SIAM Discrete Mathematics. We illustrate this approach in the context of the MDSMAPP algorithmof Shang and Ruml IEEE INFOCOM . As a prototypical patchstitchingmethod it requires the choice of patch size and we use the stress to makethat choice datadriven. In this context we perform a number of experiments toillustrate the validity of using the stress as the basis for tuning parameterselection. In so doing we uncover a biasvariance tradeoff which is aphenomenon which may have been overlooked in the multidimensional scalingliterature. By turning MDSMAPP into a method for manifold learning weobtain a local version of Isomap for which the minimization of the stress mayalso be used for parameter tuning.,4
Analysis of Catastrophic Forgetting for Random Orthogonal Transformation Tasks in the Overparameterized Regime Overparameterization is known to permit strong generalization performance inneural networks. In this work we provide an initial theoretical analysis ofits effect on catastrophic forgetting in a continual learning setup. We showexperimentally that in permuted MNIST image classification tasks thegeneralization performance of multilayer perceptrons trained by vanillastochastic gradient descent can be improved by overparameterization and theextent of the performance increase achieved by overparameterization iscomparable to that of stateoftheart continual learning algorithms. Weprovide a theoretical explanation of this effect by studying a qualitativelysimilar twotask linear regression problem where each task is related by arandom orthogonal transformation. We show that when a model is trained on thetwo tasks in sequence without any additional regularization the risk gain onthe first task is small if the model is sufficiently overparameterized.,4
A Supervised Tensor Dimension ReductionBased Prognostics Model for Applications with Incomplete Imaging Data This paper proposes a supervised dimension reduction methodology for tensordata which has two advantages over most imagebased prognostic models. Firstthe model does not require tensor data to be complete which expands itsapplication to incomplete data. Second it utilizes timetofailure TTF tosupervise the extraction of lowdimensional features which makes the extractedfeatures more effective for the subsequent prognostic. Besides an optimizationalgorithm is proposed for parameter estimation and closedform solutions arederived under certain distributions.,4
Randomly pivoted Cholesky Practical approximation of a kernel matrix with few entry evaluations Randomly pivoted Cholesky RPCholesky is a natural algorithm for computing arankk approximation of an N x N positive semidefinite psd matrix. RPCholeskycan be implemented with just a few lines of code. It requires only kN entryevaluations and Ok N additional arithmetic operations. This paper offersthe first serious investigation of its experimental and theoretical behavior.Empirically RPCholesky matches or improves on the performance of alternativealgorithms for lowrank psd approximation. Furthermore RPCholesky provablyachieves nearoptimal approximation guarantees. The simplicity effectivenessand robustness of this algorithm strongly support its use in scientificcomputing and machine learning applications.,4
Predicting OutofDomain Generalization with Local Manifold Smoothness Understanding how machine learning models generalize to new environments is acritical part of their safe deployment. Recent work has proposed a variety ofcomplexity measures that directly predict or theoretically bound thegeneralization capacity of a model. However these methods rely on a strong setof assumptions that in practice are not always satisfied. Motivated by thelimited settings in which existing measures can be applied we propose a novelcomplexity measure based on the local manifold smoothness of a classifier. Wedefine local manifold smoothness as a classifiers output sensitivity toperturbations in the manifold neighborhood around a given test point.Intuitively a classifier that is less sensitive to these perturbations shouldgeneralize better. To estimate smoothness we sample points using dataaugmentation and measure the fraction of these points classified into themajority class. Our method only requires selecting a data augmentation methodand makes no other assumptions about the model or data distributions meaningit can be applied even in outofdomain OOD settings where existing methodscannot. In experiments on robustness benchmarks in image classificationsentiment analysis and natural language inference we demonstrate a strong androbust correlation between our manifold smoothness measure and actual OODgeneralization on over  models evaluated on over  traintest domainpairs.,4
Variational Flow Graphical Model This paper introduces a novel approach to embed flowbased models withhierarchical structures. The proposed framework is named Variational FlowGraphical VFG Model. VFGs learn the representation of high dimensional datavia a messagepassing scheme by integrating flowbased functions throughvariational inference. By leveraging the expressive power of neural networksVFGs produce a representation of the data using a lower dimension thusovercoming the drawbacks of many flowbased models usually requiring a highdimensional latent space involving many trivial variables. Aggregation nodesare introduced in the VFG models to integrate forwardbackward hierarchicalinformation via a message passing scheme. Maximizing the evidence lower boundELBO of data likelihood aligns the forward and backward messages in eachaggregation node achieving a consistency node state. Algorithms have beendeveloped to learn model parameters through gradient updating regarding theELBO objective.,4
ManiFeSt Manifoldbased Feature Selection for Small Data Sets In this paper we present a new method for fewsample supervised featureselection FS. Our method first learns the manifold of the feature space ofeach class using kernels capturing multifeature associations. Then based onRiemannian geometry a composite kernel is computed extracting the differencesbetween the learned feature associations. Finally a FS score based on spectralanalysis is proposed. Considering multifeature associations makes our methodmultivariate by design. This in turn allows for the extraction of the hiddenmanifold underlying the features and avoids overfitting facilitatingfewsample FS. We showcase the efficacy of our method on illustrative examplesand several benchmarks where our method demonstrates higher accuracy inselecting the informative features compared to competing methods. In additionwe show that our FS leads to improved classification and better generalizationwhen applied to test data.,4
An Asymmetric Contrastive Loss for Handling Imbalanced Datasets Contrastive learning is a representation learning method performed bycontrasting a sample to other similar samples so that they are brought closelytogether forming clusters in the feature space. The learning process istypically conducted using a twostage training architecture and it utilizesthe contrastive loss CL for its feature learning. Contrastive learning hasbeen shown to be quite successful in handling imbalanced datasets in whichsome classes are overrepresented while some others are underrepresented.However previous studies have not specifically modified CL for imbalanceddatasets. In this work we introduce an asymmetric version of CL referred toas ACL in order to directly address the problem of class imbalance. Inaddition we propose the asymmetric focal contrastive loss AFCL as a furthergeneralization of both ACL and focal contrastive loss FCL. Results on theFMNIST and ISIC  imbalanced datasets show that AFCL is capable ofoutperforming CL and FCL in terms of both weighted and unweightedclassification accuracies. In the appendix we provide a full axiomatictreatment on entropy along with complete proofs.,4
Tree ensemble kernels for Bayesian optimization with known constraints over mixedfeature spaces Tree ensembles can be wellsuited for blackbox optimization tasks such asalgorithm tuning and neural architecture search as they achieve goodpredictive performance with little to no manual tuning naturally handlediscrete feature spaces and are relatively insensitive to outliers in thetraining data. Two wellknown challenges in using tree ensembles for blackboxoptimization are i effectively quantifying model uncertainty for explorationand ii optimizing over the piecewise constant acquisition function. Toaddress both points simultaneously we propose using the kernel interpretationof tree ensembles as a Gaussian Process prior to obtain model varianceestimates and we develop a compatible optimization formulation for theacquisition function. The latter further allows us to seamlessly integrateknown constraints to improve sampling efficiency by consideringdomainknowledge in engineering settings and modeling search space symmetriese.g. hierarchical relationships in neural architecture search. Our frameworkperforms as well as stateoftheart methods for unconstrained blackboxoptimization over continuousdiscrete features and outperforms competingmethods for problems combining mixedvariable feature spaces and known inputconstraints.,4
Inference of Regulatory Networks Through Temporally Sparse Data A major goal in genomics is to properly capture the complex dynamicalbehaviors of gene regulatory networks GRNs. This includes inferring thecomplex interactions between genes which can be used for a wide range ofgenomics analyses including diagnosis or prognosis of diseases and findingeffective treatments for chronic diseases such as cancer. Boolean networks haveemerged as a successful class of models for capturing the behavior of GRNs. Inmost practical settings inference of GRNs should be achieved through limitedand temporally sparse genomics data. A large number of genes in GRNs leads to alarge possible topology candidate space which often cannot be exhaustivelysearched due to the limitation in computational resources. This paper developsa scalable and efficient topology inference for GRNs using Bayesianoptimization and kernelbased methods. Rather than an exhaustive search overpossible topologies the proposed method constructs a Gaussian Process GPwith a topologyinspired kernel function to account for correlation in thelikelihood function. Then using the posterior distribution of the GP modelthe Bayesian optimization efficiently searches for the topology with thehighest likelihood value by optimally balancing between exploration andexploitation. The performance of the proposed method is demonstrated throughcomprehensive numerical experiments using a wellknown mammalian cellcyclenetwork.,4
Continuoustime Analysis for Variational Inequalities An Overview and Desiderata Algorithms that solve zerosum games multiobjective agent objectives ormore generally variational inequality VI problems are notoriously unstableon general problems. Owing to the increasing need for solving such problems inmachine learning this instability has been highlighted in recent years as asignificant research challenge. In this paper we provide an overview of recentprogress in the use of continuoustime perspectives in the analysis and designof methods targeting the broad VI problem class. Our presentation drawsparallels between singleobjective problems and multiobjective problemshighlighting the challenges of the latter. We also formulate various desideratafor algorithms that apply to general VIs and we argue that achieving thesedesiderata may profit from an understanding of the associated continuoustimedynamics.,4
The derivatives of SinkhornKnopp converge We show that the derivatives of the SinkhornKnopp algorithm or iterativeproportional fitting procedure converge towards the derivatives of theentropic regularization of the optimal transport problem with a locally uniformlinear convergence rate.,4
Conservative SPDEs as fluctuating mean field limits of stochastic gradient descent The convergence of stochastic interacting particle systems in the meanfieldlimit to solutions to conservative stochastic partial differential equations isshown with optimal rate of convergence. As a second main result aquantitative central limit theorem for such SPDEs is derived again withoptimal rate of convergence.,4
Mean field Variational Inference via Wasserstein Gradient Flow Variational inference VI provides an appealing alternative to traditionalsamplingbased approaches for implementing Bayesian inference due to itsconceptual simplicity statistical accuracy and computational scalability.However common variational approximation schemes such as the meanfield MFapproximation require certain conjugacy structure to facilitate efficientcomputation which may add unnecessary restrictions to the viable priordistribution family and impose further constraints on the variationalapproximation family. In this work we develop a general computationalframework for implementing MFVI via Wasserstein gradient flow WGF agradient flow over the space of probability measures. When specialized toBayesian latent variable models we analyze the algorithmic convergence of analternating minimization scheme based on a timediscretized WGF forimplementing the MF approximation. In particular the proposed algorithmresembles a distributional version of EM algorithm consisting of an Estep ofupdating the latent variable variational distribution and an Mstep ofconducting steepest descent over the variational distribution of parameters.Our theoretical analysis relies on optimal transport theory and subdifferentialcalculus in the space of probability measures. We prove the exponentialconvergence of the timediscretized WGF for minimizing a generic objectivefunctional given strict convexity along generalized geodesics. We also providea new proof of the exponential contraction of the variational distributionobtained from the MF approximation by using the fixedpoint equation of thetimediscretized WGF. We apply our method and theory to two classic Bayesianlatent variable models the Gaussian mixture model and the mixture ofregression model. Numerical experiments are also conducted to compliment thetheoretical findings under these two models.,4
Jackknife Variability Estimation For Randomized Matrix Computations Randomized algorithms based on sketching have become a workhorse tool inlowrank matrix approximation. To use these algorithms safely in applicationsthey should be coupled with diagnostics to assess the quality of approximation.To meet this need this paper proposes a jackknife resampling method toestimate the variability of the output of a randomized matrix computation. Thevariability estimate can recognize that a computation requires additional dataor that the computation is intrinsically unstable. As examples the paperstudies jackknife estimates for two randomized lowrank matrix approximationalgorithms. In each case the operation count for the jackknife estimate isindependent of the dimensions of the target matrix. In numerical experimentsthe estimator accurately assesses variability and also provides anorderofmagnitude estimate of the meansquare error.,4
A Forward Propagation Algorithm for Online Optimization of Nonlinear Stochastic Differential Equations Optimizing over the stationary distribution of stochastic differentialequations SDEs is computationally challenging. A new forward propagationalgorithm has been recently proposed for the online optimization of SDEs. Thealgorithm solves an SDE derived using forward differentiation which providesa stochastic estimate for the gradient. The algorithm continuously updates theSDE models parameters and the gradient estimate simultaneously. This paperstudies the convergence of the forward propagation algorithm for nonlineardissipative SDEs. We leverage the ergodicity of this class of nonlinear SDEs tocharacterize the convergence rate of the transition semigroup and itsderivatives. Then we prove bounds on the solution of a Poisson partialdifferential equation PDE for the expected time integral of the algorithmsstochastic fluctuations around the direction of steepest descent. We thenrewrite the algorithm using the PDE solution which allows us to characterizethe parameter evolution around the direction of steepest descent. Our mainresult is a convergence theorem for the forward propagation algorithm fornonlinear dissipative SDEs.,4
Variational Inference of overparameterized Bayesian Neural Networks a theoretical and empirical study This paper studies the Variational Inference VI used for training BayesianNeural Networks BNN in the overparameterized regime i.e. when the number ofneurons tends to infinity. More specifically we consider overparameterizedtwolayer BNN and point out a critical issue in the meanfield VI training.This problem arises from the decomposition of the lower bound on the evidenceELBO into two terms one corresponding to the likelihood function of themodel and the second to the KullbackLeibler KL divergence between the priordistribution and the variational posterior. In particular we show boththeoretically and empirically that there is a tradeoff between these two termsin the overparameterized regime only when the KL is appropriately rescaledwith respect to the ratio between the the number of observations and neurons.We also illustrate our theoretical results with numerical experiments thathighlight the critical choice of this ratio.,4
Improving the Accuracy of Marginal Approximations in LikelihoodFree Inference via Localisation Likelihoodfree methods are an essential tool for performing inference forimplicit models which can be simulated from but for which the correspondinglikelihood is intractable. However common likelihoodfree methods do not scalewell to a large number of model parameters. A promising approach tohighdimensional likelihoodfree inference involves estimating lowdimensionalmarginal posteriors by conditioning only on summary statistics believed to beinformative for the lowdimensional component and then combining thelowdimensional approximations in some way. In this paper we demonstrate thatsuch lowdimensional approximations can be surprisingly poor in practice forseemingly intuitive summary statistic choices. We describe an idealizedlowdimensional summary statistic that is in principle suitable for marginalestimation. However a direct approximation of the idealized choice isdifficult in practice. We thus suggest an alternative approach to marginalestimation which is easier to implement and automate. Given an initial choiceof lowdimensional summary statistic that might only be informative about amarginal posterior location the new method improves performance by firstcrudely localising the posterior approximation using all the summary statisticsto ensure global identifiability followed by a second step that hones in on anaccurate lowdimensional approximation using the lowdimensional summarystatistic. We show that the posterior this approach targets can be representedas a logarithmic pool of posterior distributions based on the lowdimensionaland full summary statistics respectively. The good performance of our methodis illustrated in several examples.,4
GoalOriented Sensitivity Analysis of Hyperparameters in Deep Learning Tackling new machine learning problems with neural networks always meansoptimizing numerous hyperparameters that define their structure and stronglyimpact their performances. In this work we study the use of goalorientedsensitivity analysis based on the HilbertSchmidt Independence CriterionHSIC for hyperparameter analysis and optimization. Hyperparameters live inspaces that are often complex and awkward. They can be of different naturescategorical discrete boolean continuous interact and haveinterdependencies. All this makes it nontrivial to perform classicalsensitivity analysis. We alleviate these difficulties to obtain a robustanalysis index that is able to quantify hyperparameters relative impact on aneural networks final error. This valuable tool allows us to better understandhyperparameters and to make hyperparameter optimization more interpretable. Weillustrate the benefits of this knowledge in the context of hyperparameteroptimization and derive an HSICbased optimization algorithm that we apply onMNIST and Cifar classical machine learning data sets but also on theapproximation of Runge function and Bateman equations solution of interest forscientific machine learning. This method yields neural networks that are bothcompetitive and costeffective.,4
Hindsight Learning for MDPs with Exogenous Inputs We develop a reinforcement learning RL framework for applications that dealwith sequential decisions and exogenous uncertainty such as resourceallocation and inventory management. In these applications the uncertainty isonly due to exogenous variables like future demands. A popular approach is topredict the exogenous variables using historical data and then plan with thepredictions. However this indirect approach requires highfidelity modeling ofthe exogenous process to guarantee good downstream decisionmaking which canbe impractical when the exogenous process is complex. In this work we proposean alternative approach based on hindsight learning which sidesteps modelingthe exogenous process. Our key insight is that unlike SimReal RL we canrevisit past decisions in the historical data and derive counterfactualconsequences for other actions in these applications. Our framework useshindsightoptimal actions as the policy training signal and has strongtheoretical guarantees on decisionmaking performance. We develop an algorithmusing our framework to allocate compute resources for realworld MicrosoftAzure workloads. The results show our approach learns better policies thandomainspecific heuristics and SimReal RL baselines.,4
Long Term Fairness for Minority Groups via Performative Distributionally Robust Optimization Fairness researchers in machine learning ML have coalesced around severalfairness criteria which provide formal definitions of what it means for an MLmodel to be fair. However these criteria have some serious limitations. Weidentify four key shortcomings of these formal fairness criteria and aim tohelp to address them by extending performative prediction to include adistributionally robust objective.,4
Approximation Power of Deep Neural Networks an explanatory mathematical survey The goal of this survey is to present an explanatory review of theapproximation properties of deep neural networks. Specifically we aim atunderstanding how and why deep neural networks outperform other classicallinear and nonlinear approximation methods. This survey consists of threechapters. In Chapter  we review the key ideas and concepts underlying deepnetworks and their compositional nonlinear structure. We formalize the neuralnetwork problem by formulating it as an optimization problem when solvingregression and classification problems. We briefly discuss the stochasticgradient descent algorithm and the backpropagation formulas used in solvingthe optimization problem and address a few issues related to the performance ofneural networks including the choice of activation functions cost functionsoverfitting issues and regularization. In Chapter  we shift our focus to theapproximation theory of neural networks. We start with an introduction to theconcept of density in polynomial approximation and in particular study theStoneWeierstrass theorem for realvalued continuous functions. Then withinthe framework of linear approximation we review a few classical results on thedensity and convergence rate of feedforward networks followed by more recentdevelopments on the complexity of deep networks in approximating Sobolevfunctions. In Chapter  utilizing nonlinear approximation theory we furtherelaborate on the power of depth and approximation superiority of deep ReLUnetworks over other classical methods of nonlinear approximation.,4
Online Lewis Weight Sampling The seminal work of Cohen and Peng introduced Lewis weight sampling to thetheoretical computer science community yielding fast row sampling algorithmsfor approximating ddimensional subspaces of ellp up to epsilonerror. Several works have extended this important primitive to other settingsincluding the online coreset sliding window and adversarial streaming models.However these results are only for pin and results for prequire a suboptimal tilde Odepsilon samples.,4
Distributed Online System Identification for LTI Systems Using Reverse Experience Replay Identification of linear timeinvariant LTI systems plays an important rolein control and reinforcement learning. Both asymptotic and finitetime offlinesystem identification are wellstudied in the literature. For online systemidentification the idea of stochasticgradient descent with reverse experiencereplay SGDRER was recently proposed where the data sequence is stored inseveral buffers and the stochasticgradient descent SGD update performsbackward in each buffer to break the time dependency between data points.Inspired by this work we study distributed online system identification of LTIsystems over a multiagent network. We consider agents as identical LTIsystems and the network goal is to jointly estimate the system parameters byleveraging the communication between agents. We propose DSGDRER a distributedvariant of the SGDRER algorithm and theoretically characterize theimprovement of the estimation error with respect to the network size. Ournumerical experiments certify the reduction of estimation error as the networksize grows.,4
Bayesian Recurrent Units and the ForwardBackward Algorithm Using Bayess theorem we derive a unitwise recurrence as well as a backwardrecursion similar to the forwardbackward algorithm. The resulting Bayesianrecurrent units can be integrated as recurrent neural networks within deeplearning frameworks while retaining a probabilistic interpretation from thedirect correspondence with hidden Markov models. Whilst the contribution ismainly theoretical experiments on speech recognition indicate that adding thederived units at the end of stateoftheart recurrent architectures canimprove the performance at a very low cost in terms of trainable parameters.,4
The dseparation criterion in Categorical Probability The dseparation criterion detects the compatibility of a joint probabilitydistribution with a directed acyclic graph through certain conditionalindependences. In this work we study this problem in the context ofcategorical probability theory by introducing a categorical definition ofcausal models a categorical notion of dseparation and proving an abstractversion of the dseparation criterion. This approach has two main benefits.First categorical dseparation is a very intuitive criterion based ontopological connectedness. Second our results apply in measuretheoreticprobability with standard Borel spaces and therefore provide a clean proofof the equivalence of local and global Markov properties with causalcompatibility for continuous and mixed variables.,4
Nearly Optimal Private Linear Regression via Adaptive Clipping We study the problem of differentially private linear regression where eachdata point is sampled from a fixed subGaussian style distribution. We proposeand analyze a onepass minibatch stochastic gradient descent methodDPAMBSSGD where points in each iteration are sampled without replacement.Noise is added for DP but the noise standard deviation is estimated online.Compared to existing epsilon deltaDP techniques which have suboptimalerror bounds DPAMBSSGD is able to provide nearly optimal error bounds interms of key parameters like dimensionality d number of points N and thestandard deviation sigma of the noise in observations. For example when theddimensional covariates are sampled i.i.d. from the normal distributionthen the excess error of DPAMBSSGD due to privacy is fracsigmadNfracdepsilon N i.e. the error is meaningful when number ofsamples N Omegad log d which is the standard operative regime for linearregression. In contrast error bounds for existing efficient methods in thissetting are mathcalObigfracdepsilon Nbig even forsigma. That is for constant epsilon the existing techniques requireNOmegadsqrtd to provide a nontrivial result.,4
Functional Generalized Empirical Likelihood Estimation for Conditional Moment Restrictions Important problems in causal inference economics and more generallyrobust machine learning can be expressed as conditional moment restrictionsbut estimation becomes challenging as it requires solving a continuum ofunconditional moment restrictions. Previous works addressed this problem byextending the generalized method of moments GMM to continuum momentrestrictions. In contrast generalized empirical likelihood GEL provides amore general framework and has been shown to enjoy favorable smallsampleproperties compared to GMMbased estimators. To benefit from recentdevelopments in machine learning we provide a functional reformulation of GELin which arbitrary models can be leveraged. Motivated by a dual formulation ofthe resulting infinite dimensional optimization problem we devise a practicalmethod and explore its asymptotic properties. Finally we provide kernel andneural networkbased implementations of the estimator which achievestateoftheart empirical performance on two conditional moment restrictionproblems.,4
Partial Disentanglement via Mechanism Sparsity Disentanglement via mechanism sparsity was introduced recently as aprincipled approach to extract latent factors without supervision when thecausal graph relating them in time is sparse andor when actions are observedand affect them sparsely. However this theory applies only to groundtruthgraphs satisfying a specific criterion. In this work we introduce ageneralization of this theory which applies to any groundtruth graph andspecifies qualitatively how disentangled the learned representation is expectedto be via a new equivalence relation over models we call consistency. Thisequivalence captures which factors are expected to remain entangled and whichare not based on the specific form of the groundtruth graph. We call thisweaker form of identifiability partial disentanglement. The graphical criterionthat allows complete disentanglement proposed in an earlier work can bederived as a special case of our theory. Finally we enforce graph sparsitywith constrained optimization and illustrate our theory and algorithm insimulations.,4
Model Selection in Reinforcement Learning with General Function Approximations We consider model selection for classic Reinforcement Learning RLenvironments  Multi Armed Bandits MABs and Markov Decision Processes MDPs under general function approximations. In the model selection framework wedo not know the function classes denoted by mathcalF and mathcalMwhere the true models  reward generating function for MABs and and transitionkernel for MDPs  lie respectively. Instead we are given M nested functionhypothesis classes such that true models are contained in atleast one suchclass. In this paper we propose and analyze efficient model selectionalgorithms for MABs and MDPs that emphadapt to the smallest function classamong the nested M classes containing the true underlying model. Under aseparability assumption on the nested hypothesis classes we show that thecumulative regret of our adaptive algorithms match to that of an oracle whichknows the correct function classes i.e. cF and cM a priori.Furthermore for both the settings we show that the cost of model selection isan additive term in the regret having weak logarithmic dependence on thelearning horizon T.,4
Plex Towards Reliability using Pretrained Large Model Extensions A recent trend in artificial intelligence is the use of pretrained models forlanguage and vision tasks which have achieved extraordinary performance butalso puzzling failures. Probing these models abilities in diverse ways istherefore critical to the field. In this paper we explore the reliability ofmodels where we define a reliable model as one that not only achieves strongpredictive performance but also performs well consistently over manydecisionmaking tasks involving uncertainty e.g. selective prediction openset recognition robust generalization e.g. accuracy and proper scoringrules such as loglikelihood on in and outofdistribution datasets andadaptation e.g. active learning fewshot uncertainty. We devise  types oftasks over  datasets in order to evaluate different aspects of reliability onboth vision and language domains. To improve reliability we developed ViTPlexand TPlex pretrained large model extensions for vision and languagemodalities respectively. Plex greatly improves the stateoftheart acrossreliability tasks and simplifies the traditional protocol as it improves theoutofthebox performance and does not require designing scores or tuning themodel for each task. We demonstrate scaling effects over model sizes up to Bparameters and pretraining dataset sizes up to B examples. We also demonstratePlexs capabilities on challenging tasks including zeroshot open setrecognition active learning and uncertainty in conversational languageunderstanding.,4
Graph Neural Network Bandits We consider the bandit optimization problem with the reward function definedover graphstructured data.,4
Deep Sufficient Representation Learning via Mutual Information We propose a mutual informationbased sufficient representation learningMSRL approach which uses the variational formulation of the mutualinformation and leverages the approximation power of deep neural networks. MSRLlearns a sufficient representation with the maximum mutual information with theresponse and a userselected distribution. It can easily handlemultidimensional continuous or categorical response variables. MSRL is shownto be consistent in the sense that the conditional probability density functionof the response variable given the learned representation converges to theconditional probability density function of the response variable given thepredictor. Nonasymptotic error bounds for MSRL are also established undersuitable conditions. To establish the error bounds we derive a generalizedDudleys inequality for an ordertwo Uprocess indexed by deep neural networkswhich may be of independent interest. We discuss how to determine the intrinsicdimension of the underlying data distribution. Moreover we evaluate theperformance of MSRL via extensive numerical experiments and real data analysisand demonstrate that MSRL outperforms some existing nonlinear sufficientdimension reduction methods.,4
Size and depth of monotone neural networks interpolation and approximation Monotone functions and data sets arise in a variety of applications. We studythe interpolation problem for monotone data sets The input is a monotone dataset with n points and the goal is to find a size and depth efficientmonotone neural network with non negative parameters and threshold units thatinterpolates the data set. We show that there are monotone data sets thatcannot be interpolated by a monotone network of depth . On the other handwe prove that for every monotone data set with n points in mathbbRdthere exists an interpolating monotone network of depth  and size Ond.Our interpolation result implies that every monotone function over dcan be approximated arbitrarily well by a depth monotone network improvingthe previous bestknown construction of depth d. Finally building onresults from Boolean circuit complexity we show that the inductive bias ofhaving positive parameters can lead to a superpolynomial blowup in the numberof neurons when approximating monotone functions.,4
Optimal precision for GANs When learning disconnected distributions Generative adversarial networksGANs are known to face model misspecification. Indeed a continuous mappingfrom a unimodal latent distribution to a disconnected one is impossible soGANs necessarily generate samples outside of the support of the targetdistribution. This raises a fundamental question what is the latent spacepartition that minimizes the measure of these areas Building on a recentresult of geometric measure theory we prove that an optimal GANs muststructure its latent space as a simplicial cluster  a Voronoi partitionwhere cells are convex cones  when the dimension of the latent space is largerthan the number of modes. In this configuration each Voronoi cell maps to adistinct mode of the data. We derive both an upper and a lower bound on theoptimal precision of GANs learning disconnected manifolds. Interestingly thesetwo bounds have the same order of decrease sqrtlog m m being thenumber of modes. Finally we perform several experiments to exhibit thegeometry of the latent space and experimentally show that GANs have a geometrywith similar properties to the theoretical one.,4
A New Index for Clustering Evaluation Based on Density Estimation A new index for internal evaluation of clustering is introduced. The index isdefined as a mixture of two subindices. The first subindex  Ia  is calledthe Ambiguous Index the second subindex  Is  is called the SimilarityIndex. Calculation of the two subindices is based on density estimation toeach cluster of a partition of the data. An experiment is conducted to test theperformance of the new index and compared with three popular internalclustering evaluation indices  CalinskiHarabasz index Silhouettecoefficient and DaviesBouldin index on a set of  datasets. The resultshows the new index improves the three popular indices by   and correspondingly.,4
The role of the geometric mean in casecontrol studies Historically used in settings where the outcome is rare or data collection isexpensive outcomedependent sampling is relevant to many modern settings wheredata is readily available for a biased sample of the target population such aspublic administrative data. Under outcomedependent sampling common effectmeasures such as the average risk difference and the average risk ratio are notidentified but the conditional odds ratio is. Aggregation of the conditionalodds ratio is challenging since summary measures are generally not identified.Furthermore the marginal odds ratio can be larger or smaller than allconditional odds ratios. This socalled noncollapsibility of the odds ratio isavoidable if we use an alternative aggregation to the standard arithmetic mean.We provide a new definition of collapsibility that makes this choice ofaggregation method explicit and we demonstrate that the odds ratio iscollapsible under geometric aggregation. We describe how to partially identifyestimate and do inference on the geometric odds ratio under outcomedependentsampling. Our proposed estimator is based on the efficient influence functionand therefore has doubly robuststyle properties.,4
Uncertainty quantification for predictions of atomistic neural networks The value of uncertainty quantification on predictions for trained neuralnetworks NNs on quantum chemical reference data is quantitatively explored.For this the architecture of the PhysNet NN was suitably modified and theresulting model was evaluated with different metrics to quantify calibrationquality of predictions and whether prediction error and the predicteduncertainty can be correlated. The results from training on the QM databaseand evaluating data from the test set within and outside the distributionindicate that error and uncertainty are not linearly related. The resultsclarify that noise and redundancy complicate property prediction for moleculeseven in cases for which changes  e.g. double bond migration in two otherwiseidentical molecules  are small. The model was then applied to a real databaseof tautomerization reactions. Analysis of the distance between members infeature space combined with other parameters shows that redundant informationin the training dataset can lead to large variances and small errors whereasthe presence of similar but unspecific information returns large errors butsmall variances. This was e.g. observed for nitrocontaining aliphatic chainsfor which predictions were difficult although the training set containedseveral examples for nitro groups bound to aromatic molecules. This underlinesthe importance of the composition of the training data and provides chemicalinsight into how this affects the prediction capabilities of a ML model.Finally the approach put forward can be used for informationbased improvementof chemical databases for target applications through active learningoptimization.,4
Information Processing Equalities and the InformationRisk Bridge We introduce two new classes of measures of information for statisticalexperiments which generalise and subsume phidivergences integralprobability metrics mathfrakNdistances MMD and fGammadivergences between two or more distributions. This enables us to derive asimple geometrical relationship between measures of information and the Bayesrisk of a statistical decision problem thus extending the variationalphidivergence representation to multiple distributions in an entirelysymmetric manner. The new families of divergence are closed under the action ofMarkov operators which yields an information processing equality which is arefinement and generalisation of the classical data processing inequality. Thisequality gives insight into the significance of the choice of the hypothesisclass in classical risk minimization.,4
Ultralow latency recurrent neural network inference on FPGAs for physics applications with hlsml Recurrent neural networks have been shown to be effective architectures formany tasks in high energy physics and thus have been widely adopted. Their usein lowlatency environments has however been limited as a result of thedifficulties of implementing recurrent architectures on fieldprogrammable gatearrays FPGAs. In this paper we present an implementation of two types ofrecurrent neural network layers  long shortterm memory and gated recurrentunit  within the hlsml framework. We demonstrate that our implementation iscapable of producing effective designs for both small and large models and canbe customized to meet specific design requirements for inference latencies andFPGA resources. We show the performance and synthesized designs for multipleneural networks many of which are trained specifically for jet identificationtasks at the CERN Large Hadron Collider.,4
SlicedWasserstein normalizing flows beyond maximum likelihood training Despite their advantages normalizing flows generally suffer from severalshortcomings including their tendency to generate unrealistic data e.g.images and their failing to detect outofdistribution data. One reason forthese deficiencies lies in the training strategy which traditionally exploits amaximum likelihood principle only. This paper proposes a new training paradigmbased on a hybrid objective function combining the maximum likelihood principleMLE and a slicedWasserstein distance. Results obtained on synthetic toyexamples and real image data sets show better generative abilities in terms ofboth likelihood and visual aspects of the generated samples. Reciprocally theproposed approach leads to a lower likelihood of outofdistribution datademonstrating a greater data fidelity of the resulting flows.,4
Reliable amortized variational inference with physicsbased latent distribution correction Bayesian inference for highdimensional inverse problems is challenged by thecomputational costs of the forward operator and the selection of an appropriateprior distribution. Amortized variational inference addresses these challengeswhere a neural network is trained to approximate the posterior distributionover existing pairs of model and data. When fed previously unseen data andnormally distributed latent samples as input the pretrained deep neuralnetwork  in our case a conditional normalizing flow  provides posteriorsamples with virtually no cost. However the accuracy of this approach relieson the availability of highfidelity training data which seldom exists ingeophysical inverse problems due to the heterogeneous structure of the Earth.In addition accurate amortized variational inference requires the observeddata to be drawn from the training data distribution. As such we propose toincrease the resilience of amortized variational inference when faced with datadistribution shift via a physicsbased correction to the conditionalnormalizing flow latent distribution. To accomplish this instead of a standardGaussian latent distribution we parameterize the latent distribution by aGaussian distribution with an unknown mean and diagonal covariance. Theseunknown quantities are then estimated by minimizing the KullbackLeiblerdivergence between the corrected and true posterior distributions. Whilegeneric and applicable to other inverse problems by means of a seismic imagingexample we show that our correction step improves the robustness of amortizedvariational inference with respect to changes in number of source experimentsnoise variance and shifts in the prior distribution. This approach provides aseismic image with limited artifacts and an assessment of its uncertainty withapproximately the same cost as five reversetime migrations.,4
Pavlov Learning Machines As well known Hebbs learning traces its origin in Pavlovs ClassicalConditioning however while the former has been extensively modelled in thepast decades e.g. by Hopfield model and countless variations on theme asfor the latter modelling has remained largely unaddressed so far further abridge between these two pillars is totally lacking. The main difficultytowards this goal lays in the intrinsically different scales of the informationinvolved Pavlovs theory is about correlations among emphconcepts that aredynamically stored in the synaptic matrix as exemplified by the celebratedexperiment starring a dog and a ring bell conversely Hebbs theory is aboutcorrelations among pairs of adjacent neurons as summarized by the famousstatement em neurons that fire together wire together. In this paper we relyon stochasticprocess theory and model neural and synaptic dynamics viaLangevin equations to prove that  as long as we keep neurons and synapsestimescales largely split  Pavlov mechanism spontaneously takes place andultimately gives rise to synaptic weights that recover the Hebbian kernel.,4
Homomorphism Autoencoder  Learning Group Structured Representations from Observed Transitions How can we acquire world models that veridically represent the outside worldboth in terms of what is there and in terms of how our actions affect it Canwe acquire such models by interacting with the world and can we statemathematical desiderata for their relationship with a hypothetical realityexisting outside our heads As machine learning is moving towardsrepresentations containing not just observational but also interventionalknowledge we study these problems using tools from representation learning andgroup theory. Under the assumption that our actuators act upon the world wepropose methods to learn internal representations of not just sensoryinformation but also of actions that modify our sensory representations in away that is consistent with the actions and transitions in the world. We use anautoencoder equipped with a group representation linearly acting on its latentspace trained on step reconstruction such as to enforce a suitablehomomorphism property on the group representation. Compared to existing workour approach makes fewer assumptions on the group representation and on whichtransformations the agent can sample from the group. We motivate our methodtheoretically and demonstrate empirically that it can learn the correctrepresentation of the groups and the topology of the environment. We alsocompare its performance in trajectory prediction with previous methods.,4
PASHA Efficient HPO with Progressive Resource Allocation Hyperparameter optimization HPO and neural architecture search NAS aremethods of choice to obtain the bestinclass machine learning models but inpractice they can be costly to run. When models are trained on large datasetstuning them with HPO or NAS rapidly becomes prohibitively expensive forpractitioners even when efficient multifidelity methods are employed. Wepropose an approach to tackle the challenge of tuning machine learning modelstrained on large datasets with limited computational resources. Our approachnamed PASHA is able to dynamically allocate maximum resources for the tuningprocedure depending on the need. The experimental comparison shows that PASHAidentifies wellperforming hyperparameter configurations and architectureswhile consuming significantly fewer computational resources than solutions likeASHA.,4
Is a Caption Worth a Thousand Images A Controlled Study for Representation Learning The development of CLIP Radford et al.  has sparked a debate onwhether language supervision can result in vision models with more transferablerepresentations than traditional imageonly methods. Our work studies thisquestion through a carefully controlled comparison of two approaches in termsof their ability to learn representations that generalize to downstreamclassification tasks. We find that when the pretraining dataset meets certaincriteria  it is sufficiently large and contains descriptive captions with lowvariability  imageonly methods do not match CLIPs transfer performanceeven when they are trained with more image data. However contrary to what onemight expect there are practical settings in which these criteria are not metwherein added supervision through captions is actually detrimental. Motivatedby our findings we devise simple prescriptions to enable CLIP to betterleverage the language information present in existing pretraining datasets.,4
Learning Mutual Fund Categorization using Natural Language Processing Categorization of mutual funds or ExchangeTradedfunds ETFs have longserved the financial analysts to perform peer analysis for various purposesstarting from competitor analysis to quantifying portfolio diversification.The categorization methodology usually relies on fund composition data in thestructured format extracted from the Form NA. Here we initiate a study tolearn the categorization system directly from the unstructured data as depictedin the forms using natural language processing NLP. Positing as a multiclassclassification problem with the input data being only the investment strategydescription as reported in the form and the target variable being the LipperGlobal categories and using various NLP models we show that thecategorization system can indeed be learned with high accuracy. We discussimplications and applications of our findings as well as limitations ofexisting pretrained architectures in applying them to learn fundcategorization.,4
Parallel APSM for Fast and Adaptive Digital SIC in FullDuplex Transceivers with Nonlinearity This paper presents a kernelbased adaptive filter that is applied for thedigital domain selfinterference cancellation SIC in a transceiver operatingin fullduplex FD mode. In FD the benefit of simultaneous transmission andreceiving of signals comes at the price of strong selfinterference SI. Inthis work we are primarily interested in suppressing the SI using an adaptivefilter namely adaptive projected subgradient method APSM in a reproducingkernel Hilbert space RKHS of functions. Using the projection concept as apowerful tool APSM is used to model and consequently remove the SI. Alowcomplexity and fasttracking algorithm is provided taking advantage ofparallel projections as well as the kernel trick in RKHS. The performance ofthe proposed method is evaluated on real measurement data. The methodillustrates the good performance of the proposed adaptive filter compared tothe known popular benchmarks. They demonstrate that the kernelbased algorithmachieves a favorable level of digital SIC while enabling parallelcomputationbased implementation within a rich and nonlinear function spacethanks to the employed adaptive filtering method.,4
Statistical Inference with Stochastic Gradient Algorithms Stochastic gradient algorithms are widely used for both optimization andsampling in largescale learning and inference problems. However in practicetuning these algorithms is typically done using heuristics and trialanderrorrather than rigorous generalizable theory. To address this gap between theoryand practice we novel insights into the effect of tuning parameters bycharacterizing the largesample behavior of iterates of a very general class ofpreconditioned stochastic gradient algorithms with fixed step size. In theoptimization setting our results show that iterate averaging with a largefixed step size can result in statistically efficient approximation of thelocal Mestimator. In the sampling context our results show that withappropriate choices of tuning parameters the limiting stationary covariancecan match either the Bernsteinvon Mises limit of the posterior adjustmentsto the posterior for model misspecification or the asymptotic distribution ofthe MLE and that with a naive tuning the limit corresponds to none of these.Moreover we argue that an essentially independent sample from the stationarydistribution can be obtained after a fixed number of passes over the dataset.We validate our asymptotic results in realistic finitesample regimes viaseveral experiments using simulated and real data. Overall we demonstrate thatproperly tuned stochastic gradient algorithms with constant step size offer acomputationally efficient and statistically robust approach to obtaining pointestimates or posteriorlike samples.,4
Contextual Bandits with Large Action Spaces Made Practical A central problem in sequential decision making is to develop algorithms thatare practical and computationally efficient yet support the use of flexiblegeneralpurpose models. Focusing on the contextual bandit problem recentprogress provides provably efficient algorithms with strong empiricalperformance when the number of possible alternatives actions is small butguarantees for decision making in large continuous action spaces have remainedelusive leading to a significant gap between theory and practice. We presentthe first efficient generalpurpose algorithm for contextual bandits withcontinuous linearly structured action spaces. Our algorithm makes use ofcomputational oracles for i supervised learning and ii optimization overthe action space and achieves sample complexity runtime and memoryindependent of the size of the action space. In addition it is simple andpractical. We perform a largescale empirical evaluation and show that ourapproach typically enjoys superior performance and efficiency compared tostandard baselines.,4
General Policy Evaluation and Improvement by Learning to Identify Few But Crucial States Learning to evaluate and improve policies is a core problem of ReinforcementLearning RL. Traditional RL algorithms learn a value function defined for asingle policy. A recently explored competitive alternative is to learn a singlevalue function for many policies. Here we combine the actorcritic architectureof ParameterBased Value Functions and the policy embedding of PolicyEvaluation Networks to learn a single value function for evaluating and thushelping to improve any policy represented by a deep neural network NN. Themethod yields competitive experimental results. In continuous control problemswith infinitely many states our value function minimizes its prediction errorby simultaneously learning a small set of probing states and a mapping fromactions produced in probing states to the policys return. The method extractscrucial abstract knowledge about the environment in form of very few statessufficient to fully specify the behavior of many policies. A policy improvessolely by changing actions in probing states following the gradient of thevalue functions predictions. Surprisingly it is possible to clone thebehavior of a nearoptimal policy in Swimmerv and Hopperv environments onlyby knowing how to act in  and  such learned states respectively. Remarkablyour value function trained to evaluate NN policies is also invariant to changesof the policy architecture we show that it allows for zeroshot learning oflinear policies competitive with the best policy seen during training. Our codeis public.,4
Alternating minimization for generalized rank one matrix sensing Sharp predictions from a random initialization We consider the problem of estimating the factors of a rank matrix withi.i.d. Gaussian rank measurements that are nonlinearly transformed andcorrupted by noise. Considering two prototypical choices for the nonlinearitywe study the convergence properties of a natural alternating update rule forthis nonconvex optimization problem starting from a random initialization. Weshow sharp convergence guarantees for a samplesplit version of the algorithmby deriving a deterministic recursion that is accurate even in highdimensionalproblems. Notably while the infinitesample population update is uninformativeand suggests exact recovery in a single step the algorithm  and ourdeterministic prediction  converges geometrically fast from a randominitialization. Our sharp nonasymptotic analysis also exposes several otherfinegrained properties of this problem including how the nonlinearity andnoise level affect convergence behavior.,4
Online Active Regression Active regression considers a linear regression problem where the learnerreceives a large number of data points but can only observe a small number oflabels. Since online algorithms can deal with incremental training data andtake advantage of low computational cost we consider an online extension ofthe active regression problem the learner receives data points one by one andimmediately decides whether it should collect the corresponding labels. Thegoal is to efficiently maintain the regression of received data points with asmall budget of label queries. We propose novel algorithms for this problemunder ellp loss where pin. To achieve a epsilonapproximatesolution our proposed algorithms only requiretildemathcalOepsilon d lognkappa queries of labels wheren is the number of data points and kappa is a quantity called thecondition number of the data points. The numerical results verify ourtheoretical results and show that our methods have comparable performance withoffline active regression algorithms.,4
Deep Hedging Continuous Reinforcement Learning for Hedging of General Portfolios across Multiple Risk Aversions We present a method for finding optimal hedging policies for arbitraryinitial portfolios and market states. We develop a novel actorcritic algorithmfor solving general riskaverse stochastic control problems and use it to learnhedging strategies across multiple risk aversion levels simultaneously. Wedemonstrate the effectiveness of the approach with a numerical example in astochastic volatility environment.,4
A Certifiable Security Patch for Object Tracking in SelfDriving Systems via Historical Deviation Modeling Selfdriving cars SDC commonly implement the perception pipeline to detectthe surrounding obstacles and track their moving trajectories which lays theground for the subsequent driving decision making process. Although thesecurity of obstacle detection in SDC is intensively studied not until veryrecently the attackers start to exploit the vulnerability of the trackingmodule. Compared with solely attacking the object detectors this new attackstrategy influences the driving decision more effectively with less attackbudgets. However little is known on whether the revealed vulnerability remainseffective in endtoend selfdriving systems and if so how to mitigate thethreat.,4
Rethinking Optimization with Differentiable Simulation from a Global Perspective Differentiable simulation is a promising toolkit for fast gradientbasedpolicy optimization and system identification. However existing approaches todifferentiable simulation have largely tackled scenarios where obtaining smoothgradients has been relatively easy such as systems with mostly smoothdynamics. In this work we study the challenges that differentiable simulationpresents when it is not feasible to expect that a single descent reaches aglobal optimum which is often a problem in contactrich scenarios. We analyzethe optimization landscapes of diverse scenarios that contain both rigid bodiesand deformable objects. In dynamic environments with highly deformable objectsand fluids differentiable simulators produce rugged landscapes withnonetheless useful gradients in some parts of the space. We propose a methodthat combines Bayesian optimization with semilocal leaps to obtain a globalsearch method that can use gradients effectively while also maintaining robustperformance in regions with noisy gradients. We show that our approachoutperforms several gradientbased and gradientfree baselines on an extensiveset of experiments in simulation and also validate the method usingexperiments with a real robot and deformables. Videos and supplementarymaterials are available at,4
DataDriven Stochastic ACOPF using Gaussian Processes In recent years electricity generation has been responsible for more than aquarter of the greenhouse gas emissions in the US. Integrating a significantamount of renewables into a power grid is probably the most accessible way toreduce carbon emissions from power grids and slow down climate change.Unfortunately the most accessible renewable power sources such as wind andsolar are highly fluctuating and thus bring a lot of uncertainty to power gridoperations and challenge existing optimization and control policies. Thechanceconstrained alternating current AC optimal power flow OPF frameworkfinds the minimum cost generation dispatch maintaining the power gridoperations within security limits with a prescribed probability. Unfortunatelythe ACOPF problems chanceconstrained extension is nonconvexcomputationally challenging and requires knowledge of system parameters andadditional assumptions on the behavior of renewable distribution. Known linearand convex approximations to the above problems though tractable are tooconservative for operational practice and do not consider uncertainty in systemparameters. This paper presents an alternative datadriven approach based onGaussian process GP regression to close this gap. The GP approach learns asimple yet nonconvex datadriven approximation to the AC power flow equationsthat can incorporate uncertainty inputs. The latter is then used to determinethe solution of CCOPF efficiently by accounting for both input and parameteruncertainty. The practical efficiency of the proposed approach using differentapproximations for GPuncertainty propagation is illustrated over numerous IEEEtest cases.,4
Collaborative Uncertainty Benefits MultiAgent MultiModal Trajectory Forecasting In multimodal multiagent trajectory forecasting two major challenges havenot been fully tackled  how to measure the uncertainty brought by theinteraction module that causes correlations among the predicted trajectories ofmultiple agents  how to rank the multiple predictions and select the optimalpredicted trajectory. In order to handle these challenges this work firstproposes a novel concept collaborative uncertainty CU which models theuncertainty resulting from interaction modules. Then we build a generalCUaware regression framework with an original permutationequivariantuncertainty estimator to do both tasks of regression and uncertaintyestimation. Further we apply the proposed framework to current SOTAmultiagent multimodal forecasting systems as a plugin module which enablesthe SOTA systems to  estimate the uncertainty in the multiagent multimodaltrajectory forecasting task  rank the multiple predictions and select theoptimal one based on the estimated uncertainty. We conduct extensiveexperiments on a synthetic dataset and two public largescale multiagenttrajectory forecasting benchmarks. Experiments show that  on the syntheticdataset the CUaware regression framework allows the model to appropriatelyapproximate the groundtruth Laplace distribution  on the multiagenttrajectory forecasting benchmarks the CUaware regression framework steadilyhelps SOTA systems improve their performances. Specially the proposedframework helps VectorNet improve by  cm regarding the Final DisplacementError of the chosen optimal prediction on the nuScenes dataset  formultiagent multimodal trajectory forecasting systems prediction uncertaintyis positively correlated with future stochasticity and  the estimated CUvalues are highly related to the interactive information among agents.,4
SPRTbased Efficient Best Arm Identification in Stochastic Bandits This paper investigates the best arm identification BAI problem instochastic multiarmed bandits in the fixed confidence setting. The generalclass of the exponential family of bandits is considered. The stateoftheartalgorithms for the exponential family of bandits face computational challenges.To mitigate these challenges a novel framework is proposed which views theBAI problem as sequential hypothesis testing and is amenable to tractableanalysis for the exponential family of bandits. Based on this framework a BAIalgorithm is designed that leverages the canonical sequential probability ratiotests. This algorithm has three features for both settings  its samplecomplexity is asymptotically optimal  it is guaranteed to be deltaPACand  it addresses the computational challenge of the stateoftheartapproaches. Specifically these approaches which are focused only on theGaussian setting require Thompson sampling from the arm that is deemed thebest and a challenger arm. This paper analytically shows that identifying thechallenger is computationally expensive and that the proposed algorithmcircumvents it. Finally numerical experiments are provided to support theanalysis.,4
Causal Fairness Analysis Decisionmaking systems based on AI and machine learning have been usedthroughout a wide range of realworld scenarios including healthcare lawenforcement education and finance. It is no longer farfetched to envision afuture where autonomous systems will be driving entire business decisions andmore broadly supporting largescale decisionmaking infrastructure to solvesocietys most challenging problems. Issues of unfairness and discriminationare pervasive when decisions are being made by humans and remain or arepotentially amplified when decisions are made using machines with littletransparency accountability and fairness. In this paper we introduce aframework for textitcausal fairness analysis with the intent of filling inthis gap i.e. understanding modeling and possibly solving issues offairness in decisionmaking settings. The main insight of our approach will beto link the quantification of the disparities present on the observed data withthe underlying and often unobserved collection of causal mechanisms thatgenerate the disparity in the first place challenge we call the FundamentalProblem of Causal Fairness Analysis FPCFA. In order to solve the FPCFA westudy the problem of decomposing variations and empirical measures of fairnessthat attribute such variations to structural mechanisms and different units ofthe population. Our effort culminates in the Fairness Map which is the firstsystematic attempt to organize and explain the relationship between differentcriteria found in the literature. Finally we study which causal assumptionsare minimally needed for performing causal fairness analysis and propose aFairness Cookbook which allows data scientists to assess the existence ofdisparate impact and disparate treatment.,4
Benign Tempered or Catastrophic A Taxonomy of Overfitting The practical success of overparameterized neural networks has motivated therecent scientific study of interpolating methods which perfectly fit theirtraining data. Certain interpolating methods including neural networks canfit noisy training data without catastrophically bad test performance indefiance of standard intuitions from statistical learning theory. Aiming toexplain this a body of recent work has studied textitbenign overfittinga phenomenon where some interpolating methods approach Bayes optimality evenin the presence of noise. In this work we argue that while benign overfittinghas been instructive and fruitful to study many real interpolating methodslike neural networks textitdo not fit benignly modest noise in thetraining set causes nonzero but noninfinite excess risk at test timeimplying these models are neither benign nor catastrophic but rather fall in anintermediate regime. We call this intermediate regime textittemperedoverfitting and we initiate its systematic study. We first explore thisphenomenon in the context of kernel ridge regression KR by obtainingconditions on the ridge parameter and kernel eigenspectrum under which KRexhibits each of the three behaviors. We find that kernels with powerlawspectra including Laplace kernels and ReLU neural tangent kernels exhibittempered overfitting. We then empirically study deep neural networks throughthe lens of our taxonomy and find that those trained to interpolation aretempered while those stopped early are benign. We hope our work leads to amore refined understanding of overfitting in modern learning.,4
Repairing Systematic Outliers by Learning Clean Subspaces in VAEs Data cleaning often comprises outlier detection and data repair. Systematicerrors result from nearly deterministic transformations that occur repeatedlyin the data e.g. specific image pixels being set to default values orwatermarks. Consequently models with enough capacity easily overfit to theseerrors making detection and repair difficult. Seeing as a systematic outlieris a combination of patterns of a clean instance and systematic error patternsour main insight is that inliers can be modelled by a smaller representationsubspace in a model than outliers. By exploiting this we propose CleanSubspace Variational Autoencoder CLSVAE a novel semisupervised model fordetection and automated repair of systematic errors. The main idea is topartition the latent space and model inlier and outlier patterns separately.CLSVAE is effective with much less labelled data compared to previous relatedmodels often with less than  of the data. We provide experiments using threeimage datasets in scenarios with different levels of corruption and labelledset sizes comparing to relevant baselines. CLSVAE provides superior repairswithout human intervention e.g. with just . of labelled data we see arelative error decrease of  compared to the closest baseline.,4
LETSGZSL A Latent Embedding Model for Time Series Generalized Zero Shot Learning One of the recent developments in deep learning is generalized zeroshotlearning GZSL which aims to recognize objects from both seen and unseenclasses when only the labeled examples from seen classes are provided. Overthe past couple of years GZSL has picked up traction and several models havebeen proposed to solve this problem. Whereas an extensive amount of research onGZSL has been carried out in fields such as computer vision and naturallanguage processing no such research has been carried out to deal with timeseries data. GZSL is used for applications such as detecting abnormalities fromECG and EEG data and identifying unseen classes from sensor spectrograph andother devices data. In this regard we propose a Latent Embedding for TimeSeries  GZSL LETSGZSL model that can solve the problem of GZSL for timeseries classification TSC. We utilize an embeddingbased approach and combineit with attribute vectors to predict the final class labels. We report ourresults on the widely popular UCR archive datasets. Our framework is able toachieve a harmonic mean value of at least  on most of the datasets exceptwhen the number of unseen classes is greater than  or the amount of data isvery low less than  training examples.,4
DCBRS Accounting For IntraClass Diversity in Continual Learning Continual learning  accumulating knowledge from a sequence of learningexperiences  is an important yet challenging problem. In this paradigm themodels performance for previously encountered instances may substantially dropas additional data are seen. When dealing with classimbalanced dataforgetting is further exacerbated. Prior work has proposed replaybasedapproaches which aim at reducing forgetting by intelligently storing instancesfor future replay. Although ClassBalancing Reservoir Sampling CBRS has beensuccessful in dealing with imbalanced data the intraclass diversity has notbeen accounted for implicitly assuming that each instance of a class isequally informative. We present DiverseCBRS DCBRS an algorithm that allowsus to consider within class diversity when storing instances in the memory. Ourresults show that DCBRS outperforms stateoftheart memory managementcontinual learning algorithms on data sets with considerable intraclassdiversity.,4
Instanceoptimal PAC Algorithms for Contextual Bandits In the stochastic contextual bandit setting regretminimizing algorithmshave been extensively researched but their instanceminimizing bestarmidentification counterparts remain seldom studied. In this work we focus onthe stochastic bandit problem in the epsilondeltatextitPACsetting given a policy class Pi the goal of the learner is to return apolicy piin Pi whose expected reward is within epsilon of the optimalpolicy with probability greater than delta. We characterize the firsttextitinstancedependent PAC sample complexity of contextual banditsthrough a quantity rhoPi and provide matching upper and lower bounds interms of rhoPi for the agnostic and linear contextual bestarmidentification settings. We show that no algorithm can be simultaneouslyminimaxoptimal for regret minimization and instancedependent PAC for bestarmidentification. Our main result is a new instanceoptimal and computationallyefficient algorithm that relies on a polynomial number of calls to an argmaxoracle.,4
Lazy Estimation of Variable Importance for Large Neural Networks As opaque predictive models increasingly impact many areas of modern lifeinterest in quantifying the importance of a given input variable for making aspecific prediction has grown. Recently there has been a proliferation ofmodelagnostic methods to measure variable importance VI that analyze thedifference in predictive power between a full model trained on all variablesand a reduced model that excludes the variables of interest. A bottleneckcommon to these methods is the estimation of the reduced model for eachvariable or subset of variables which is an expensive process that oftendoes not come with theoretical guarantees. In this work we propose a fast andflexible method for approximating the reduced model with important inferentialguarantees. We replace the need for fully retraining a wide neural network by alinearization initialized at the full model parameters. By adding a ridgelikepenalty to make the problem convex we prove that when the ridge penaltyparameter is sufficiently large our method estimates the variable importancemeasure with an error rate of Ofracsqrtn where n is the numberof training samples. We also show that our estimator is asymptotically normalenabling us to provide confidence bounds for the VI estimates. We demonstratethrough simulations that our method is fast and accurate under severaldatagenerating regimes and we demonstrate its realworld applicability on aseasonal climate forecasting example.,4
Measuring and signing fairness as performance under multiple stakeholder distributions As learning machines increase their influence on decisions concerning humanlives analyzing their fairness properties becomes a subject of centralimportance. Yet our best tools for measuring the fairness of learning systemsare rigid fairness metrics encapsulated as mathematical oneliners offerlimited power to the stakeholders involved in the prediction task and are easyto manipulate when we exhort excessive pressure to optimize them. To advancethese issues we propose to shift focus from shaping fairness metrics tocurating the distributions of examples under which these are computed. Inparticular we posit that every claim about fairness should be immediatelyfollowed by the tagline Fair under what examples and collected by whom. Byhighlighting connections to the literature in domain generalization we proposeto measure fairness as the ability of the system to generalize under multiplestress tests  distributions of examples with social relevance. We encourageeach stakeholder to curate one or multiple stress tests containing examplesreflecting their possibly conflicting interests. The machine passes or failseach stress test by falling short of or exceeding a predefined metric value.The test results involve all stakeholders in a discussion about how to improvethe learning system and provide flexible assessments of fairness dependent oncontext and based on interpretable data. We provide full implementationguidelines for stress testing illustrate both the benefits and shortcomings ofthis framework and introduce a cryptographic scheme to enable a degree ofprediction accountability from system providers.,4
Seeking the Truth Beyond the Data. An Unsupervised Machine Learning Approach Clustering is an unsupervised machine learning methodology where unlabeledelementsobjects are grouped together aiming to the construction ofwellestablished clusters that their elements are classified according to theirsimilarity. The goal of this process is to provide a useful aid to theresearcher that will help herhim to identify patterns among the data. Dealingwith large databases such patterns may not be easily detectable without thecontribution of a clustering algorithm. This article provides a deepdescription of the most widely used clustering methodologies accompanied byuseful presentations concerning suitable parameter selection andinitializations. Simultaneously this article not only represents a reviewhighlighting the major elements of examined clustering techniques butemphasizes the comparison of these algorithms clustering efficiency based on datasets revealing their existing weaknesses and capabilities through accuracyand complexity during the confrontation of discrete and continuousobservations. The produced results help us extract valuable conclusions aboutthe appropriateness of the examined clustering techniques in accordance withthe datasets size.,4
Unsupervised learning of observation functions in statespace models by nonparametric moment methods We investigate the unsupervised learning of noninvertible observationfunctions in nonlinear statespace models. Assuming abundant data of theobservation process along with the distribution of the state process weintroduce a nonparametric generalized moment method to estimate the observationfunction via constrained regression. The major challenge comes from thenoninvertibility of the observation function and the lack of data pairsbetween the state and observation. We address the fundamental issue ofidentifiability from quadratic loss functionals and show that the functionspace of identifiability is the closure of a RKHS that is intrinsic to thestate process. Numerical results show that the first two moments and temporalcorrelations along with upper and lower bounds can identify functions rangingfrom piecewise polynomials to smooth functions leading to convergentestimators. The limitations of this method such as nonidentifiability due tosymmetry and stationarity are also discussed.,4
Twitmo A Twitter Data Topic Modeling and Visualization Package for R We present Twitmo a package that provides a broad range of methods tocollect preprocess analyze and visualize geotagged Twitter data. Twitmoenables the user to collect geotagged Tweets from Twitter and and provides acomprehensive and userfriendly toolbox to generate topic distributions fromLatent Dirichlet Allocations LDA correlated topic models CTM andstructural topic models STM. Functions are included for preprocessing oftext model building and prediction. In addition one of the innovations of thepackage is the automatic pooling of Tweets into longer pseudodocuments usinghashtags and cosine similarities for better topic coherence. The packageadditionally comes with functionality to visualize collected data sets andfitted models in static as well as interactive ways and offers builtin supportfor model visualizations via LDAvis providing great convenience for researchersin this area. The Twitmo package is an innovative toolbox that can be used toanalyze public discourse of various topics political parties or persons ofinterest in space and time.,4
Generalized Identifiability Bounds for Mixture Models with Grouped Samples Recent work has shown that finite mixture models with m components areidentifiable while making no assumptions on the mixture components so long asone has access to groups of samples of size m which are known to come fromthe same mixture component. In this work we generalize that result and showthat if every subset of k mixture components of a mixture model are linearlyindependent then that mixture model is identifiable with only mksamples per group. We further show that this value cannot be improved. We provean analogous result for a stronger form of identifiability known asdeterminedness along with a corresponding lower bound. This independenceassumption almost surely holds if mixture components are chosen randomly from akdimensional space. We describe some implications of our results formultinomial mixture models and topic modeling.,4
High dimensional stochastic linear contextual bandit with missing covariates Recent works in bandit problems adopted lasso convergence theory in thesequential decisionmaking setting. Even with fully observed contexts thereare technical challenges that hinder the application of existing lassoconvergence theory  proving the restricted eigenvalue condition underconditionally subGaussian noise and  accounting for the dependence betweenthe context variables and the chosen actions. This paper studies the effect ofmissing covariates on regret for stochastic linear bandit algorithms. Our workprovides a highprobability upper bound on the regret incurred by the proposedalgorithm in terms of covariate sampling probabilities showing that the regretdegrades due to missingness by at most zetamin where zetamin isthe minimum probability of observing covariates in the context vector. Weillustrate our algorithm for the practical application of experimental designfor collecting gene expression data by a sequential selection of classdiscriminating DNA probes.,4
On the instrumental variable estimation with many weak and invalid instruments We discuss the fundamental issue of identification in linear instrumentalvariable IV models with unknown IV validity. We revisit the popular majorityand plurality rules and show that no identification condition can be if andonly if in general. With the assumption of the sparsest rule which isequivalent to the plurality rule but becomes operational in computationalgorithms we investigate and prove the advantages of nonconvex penalizedapproaches over other IV estimators based on twostep selections in terms ofselection consistency and accommodation for individually weak IVs. Furthermorewe propose a surrogate sparsest penalty that aligns with the identificationcondition and provides oracle sparse structure simultaneously. Desirabletheoretical properties are derived for the proposed estimator with weaker IVstrength conditions compared to the previous literature. Finite sampleproperties are demonstrated using simulations and the selection and estimationmethod is applied to an empirical study concerning the effect of trade oneconomic growth.,4
On minimax density estimation via measure transport We study the convergence properties in Hellinger and related distances ofnonparametric density estimators based on measure transport. These estimatorsrepresent the measure of interest as the pushforward of a chosen referencedistribution under a transport map where the map is chosen via a maximumlikelihood objective equivalently minimizing an empirical KullbackLeiblerloss or a penalized version thereof. We establish concentration inequalitiesfor a general class of penalized measure transport estimators by combiningtechniques from Mestimation with analytical properties of the transportbaseddensity representation. We then demonstrate the implications of our theory forthe case of triangular KnotheRosenblatt KR transports on the ddimensionalunit cube and show that both penalized and unpenalized versions of suchestimators achieve minimax optimal convergence rates over Hlder classes ofdensities. Specifically we establish optimal rates for unpenalizednonparametric maximum likelihood estimation over bounded Hldertype ballsand then for certain Sobolevpenalized estimators and sieved waveletestimators.,4
The Mean Dimension of Neural Networks  What causes the interaction effects Owen and Hoyt recently showed that the effective dimension offers keystructural information about the inputoutput mapping underlying an artificialneural network. Along this line of research this work proposes an estimationprocedure that allows the calculation of the mean dimension from a givendataset without resampling from external distributions. The design yieldstotal indices when features are independent and a variant of total indices whenfeatures are correlated. We show that this variant possesses the zeroindependence property. With synthetic datasets we analyse how the meandimension evolves layer by layer and how the activation function impacts themagnitude of interactions. We then use the mean dimension to study some of themost widely employed convolutional architectures for image recognition LeNetResNet DenseNet. To account for pixel correlations we propose calculatingthe mean dimension after the addition of an inverse PCA layer that allows oneto work on uncorrelated PCAtransformed features without the need to retrainthe neural network. We use the generalized total indices to produce heatmapsfor posthoc explanations and we employ the mean dimension on thePCAtransformed features for cross comparisons of the artificial neuralnetworks structures. Results provide several insights on the difference inmagnitude of interactions across the architectures as well as indications onhow the mean dimension evolves during training.,4
Subgraph Frequency Distribution Estimation using Graph Neural Networks Small subgraphs graphlets are important features to describe fundamentalunits of a large network. The calculation of the subgraph frequencydistributions has a wide application in multiple domains including biology andengineering. Unfortunately due to the inherent complexity of this task most ofthe existing methods are computationally intensive and inefficient. In thiswork we propose GNNS a novel representational learning framework thatutilizes graph neural networks to sample subgraphs efficiently for estimatingtheir frequency distribution. Our framework includes an inference model and agenerative model that learns hierarchical embeddings of nodes subgraphs andgraph types. With the learned model and embeddings subgraphs are sampled in ahighly scalable and parallel way and the frequency distribution estimation isthen performed based on these sampled subgraphs. Eventually our methodsachieve comparable accuracy and a significant speedup by three orders ofmagnitude compared to existing methods.,4
Finitetime Highprobability Bounds for PolyakRuppert Averaged Iterates of Linear Stochastic Approximation This paper provides a finitetime analysis of linear stochastic approximationLSA algorithms with fixed step size a core method in statistics and machinelearning. LSA is used to compute approximate solutions of a ddimensionallinear system barmathbfA theta  barmathbfb for whichbarmathbfA barmathbfb can only be estimated throughasymptotically unbiased observationsmathbfAZnmathbfbZnn in mathbbN. We consider herethe case where Znn in mathbbN is an i.i.d. sequence or auniformly geometrically ergodic Markov chain and derive pmoments inequalityand high probability bounds for the iterates defined by LSA and itsPolyakRuppert averaged version. More precisely we establish bounds of orderp alpha toperatornamemixdp on the pth moment of thelast iterate of LSA. In this formula alpha is the step size of the procedureand toperatornamemix is the mixing time of the underlying chaintoperatornamemix in the i.i.d. setting. We then prove finitetimeinstancedependent bounds on the PolyakRuppert averaged sequence of iterates.These results are sharp in the sense that the leading term we obtain matchesthe local asymptotic minimax limit including tight dependence on theparameters dtoperatornamemix in the higher order terms.,4
Gradients should stay on Path Better Estimators of the Reverse and Forward KL Divergence for Normalizing Flows We propose an algorithm to estimate the pathgradient of both the reverse andforward KullbackLeibler divergence for an arbitrary manifestly invertiblenormalizing flow. The resulting pathgradient estimators are straightforward toimplement have lower variance and lead not only to faster convergence oftraining but also to better overall approximation results compared to standardtotal gradient estimators. We also demonstrate that pathgradient training isless susceptible to modecollapse. In light of our results we expect thatpathgradient estimators will become the new standard method to trainnormalizing flows for variational inference.,4
A SublinearTime Quantum Algorithm for Approximating Partition Functions We present a novel quantum algorithm for estimating Gibbs partition functionsin sublinear time with respect to the logarithm of the size of the state space.This is the first speedup of this type to be obtained over the seminalnearlylinear time algorithm of tefankovi Vempala and Vigoda JACM. Our result also preserves the quadratic speedup in precision andspectral gap achieved in previous work by exploiting the properties of quantumMarkov chains. As an application we obtain new polynomial improvements overthe bestknown algorithms for computing the partition function of the Isingmodel and counting the number of kcolorings matchings or independent setsof a graph.,4
Fairnessaware Network Revenue Management with Demand Learning In addition to maximizing the total revenue decisionmakers in lots ofindustries would like to guarantee fair consumption across different resourcesand avoid saturating certain resources. Motivated by these practical needsthis paper studies the pricebased network revenue management problem with bothdemand learning and fairness concern about the consumption across differentresources. We introduce the regularized revenue i.e. the total revenue with afairness regularization as our objective to incorporate fairness into therevenue maximization goal. We propose a primaldualtype online policy with theUpperConfidenceBound UCB demand learning method to maximize the regularizedrevenue. We adopt several innovative techniques to make our algorithm a unifiedand computationally efficient framework for the continuous price set and a wideclass of fairness regularizers. Our algorithm achieves a worstcase regret oftilde ONsqrtT where N denotes the number of products and Tdenotes the number of time periods. Numerical experiments in a few NRM examplesdemonstrate the effectiveness of our algorithm for balancing revenue andfairness.,4
On the Superexponential Quantum Speedup of Equivariant Quantum Machine Learning Algorithms with SUd Symmetry We introduce a framework of the equivariant convolutional algorithms which istailored for a number of machinelearning tasks on physical systems witharbitrary SUd symmetries. It allows us to enhance a natural model ofquantum computationpermutational quantum computing PQC Quantum Inf.Comput.    and defines a more powerful model PQC. WhilePQC was shown to be effectively classically simulatable we exhibit a problemwhich can be efficiently solved on PQC machine whereas the best knownclassical algorithms runs in Onn time thus providing strong evidenceagainst PQC being classically simulatable. We further discuss practicalquantum machine learning algorithms which can be carried out in the paradigm ofPQC.,4
GoalConditioned Generators of Deep Policies Goalconditioned Reinforcement Learning RL aims at learning optimalpolicies given goals encoded in special command inputs. Here we studygoalconditioned neural nets NNs that learn to generate deep NN policies inform of contextspecific weight matrices similar to Fast Weight Programmersand other methods from the s. Using context commands of the form generatea policy that achieves a desired expected return our NN generators combinepowerful exploration of parameter space with generalization across commands toiteratively find better and better policies. A form of weightsharingHyperNetworks and policy embeddings scales our method to generate deep NNs.Experiments show how a single learned policy generator can produce policiesthat achieve any return seen during training. Finally we evaluate ouralgorithm on a set of continuous control tasks where it exhibits competitiveperformance. Our code is public.,4
Shrinkage Estimation of Higher Order Bochner Integrals We consider shrinkage estimation of higher order Hilbert space valued Bochnerintegrals in a nonparametric setting. We propose estimators that shrink theUstatistic estimator of the Bochner integral towards a prespecified targetelement in the Hilbert space. Depending on the degeneracy of the kernel of theUstatistic we construct consistent shrinkage estimators with fast rates ofconvergence and develop oracle inequalities comparing the risks of the theUstatistic estimator and its shrinkage version. Surprisingly we show thatthe shrinkage estimator designed by assuming complete degeneracy of the kernelof the Ustatistic is a consistent estimator even when the kernel is notcomplete degenerate. This work subsumes and improves upon Krikamol et al. JMLR and Zhou et al.  JMVA which only handle mean element andcovariance operator estimation in a reproducing kernel Hilbert space. We alsospecialize our results to normal mean estimation and show that for dge the proposed estimator strictly improves upon the sample mean in terms of themean squared error.,4
Uncertaintyaware Mixedvariable Machine Learning for Materials Design Datadriven design shows the promise of accelerating materials discovery butis challenging due to the prohibitive cost of searching the vast design spaceof chemistry structure and synthesis methods. Bayesian Optimization BOemploys uncertaintyaware machine learning models to select promising designsto evaluate hence reducing the cost. However BO with mixed numerical andcategorical variables which is of particular interest in materials design hasnot been well studied. In this work we survey frequentist and Bayesianapproaches to uncertainty quantification of machine learning with mixedvariables. We then conduct a systematic comparative study of their performancesin BO using a popular representative model from each group the randomforestbased Lolo model frequentist and the latent variable Gaussian processmodel Bayesian. We examine the efficacy of the two models in the optimizationof mathematical functions as well as properties of structural and functionalmaterials where we observe performance differences as related to problemdimensionality and complexity. By investigating the machine learning modelspredictive and uncertainty estimation capabilities we provide interpretationsof the observed performance differences. Our results provide practical guidanceon choosing between frequentist and Bayesian uncertaintyaware machine learningmodels for mixedvariable BO in materials design.,4
Uncertainty Calibration in Bayesian Neural Networks via DistanceAware Priors As we move away from the data the predictive uncertainty should increasesince a great variety of explanations are consistent with the little availableinformation. We introduce DistanceAware Prior DAP calibration a method tocorrect overconfidence of Bayesian deep learning models outside of the trainingdomain. We define DAPs as prior distributions over the model parameters thatdepend on the inputs through a measure of their distance from the training set.DAP calibration is agnostic to the posterior inference method and it can beperformed as a postprocessing step. We demonstrate its effectiveness againstseveral baselines in a variety of classification and regression problemsincluding benchmarks designed to test the quality of predictive distributionsaway from the data.,4
Variance estimation in graphs with the fused lasso We study the problem of variance estimation in general graphstructuredproblems. First we develop a linear time estimator for the homoscedastic casethat can consistently estimate the variance in general graphs. We show that ourestimator attains minimax rates for the chain and D grid graphs when the meansignal has a total variation with canonical scaling. Furthermore we providegeneral upper bounds on the mean squared error performance of the fused lassoestimator in general graphs under a moment condition and a bound on the tailbehavior of the errors. These upper bounds allow us to generalize for broaderclasses of distributions such as subExponential many existing results on thefused lasso that are only known to hold with the assumption that errors aresubGaussian random variables. Exploiting our upper bounds we then study asimple total variation regularization estimator for estimating the signal ofvariances in the heteroscedastic case. Our results show that the varianceestimator attains minimax rates for estimating signals of bounded variation ingrid graphs Knearest neighbor graphs with very mild assumptions and it isconsistent for estimating the variances in any connected graph. In additionextensive numerical results show that our proposed estimators performreasonably well in a variety of graphstructured models.,4
MetaLearning a RealTime Tabular AutoML Method For Small Data We present TabPFN an AutoML method that is competitive with the state of theart on small tabular datasets while being over times faster. Our methodis very simple it is fully entailed in the weights of a single neural networkand a single forward pass directly yields predictions for a new dataset. OurAutoML method is metalearned using the Transformerbased PriorData FittedNetwork PFN architecture and approximates Bayesian inference with a priorthat is based on assumptions of simplicity and causal structures. The priorcontains a large space of structural causal models and Bayesian neural networkswith a bias for small architectures and thus low complexity. Furthermore weextend the PFN approach to differentiably calibrate the priors hyperparameterson real data. By doing so we separate our abstract prior assumptions fromtheir heuristic calibration on real data. Afterwards the calibratedhyperparameters are fixed and TabPFN can be applied to any new tabular datasetat the push of a button. Finally on  datasets from the OpenMLCC suite weshow that our method outperforms boosted trees and performs on par with complexstateoftheart AutoML systems with predictions produced in less than asecond. We provide all our code and our final trained TabPFN in thesupplementary materials.,4
Contextual Bandits with Smooth Regret Efficient Learning in Continuous Action Spaces Designing efficient generalpurpose contextual bandit algorithms that workwith large  or even continuous  action spaces would facilitate applicationto important scenarios such as information retrieval recommendation systemsand continuous control. While obtaining standard regret guarantees can behopeless alternative regret notions have been proposed to tackle the largeaction setting. We propose a smooth regret notion for contextual bandits whichdominates previously proposed alternatives. We design a statistically andcomputationally efficient algorithm  for the proposed smooth regret  thatworks with general function approximation under standard supervised oracles. Wealso present an adaptive algorithm that automatically adapts to any smoothnesslevel. Our algorithms can be used to recover the previous minimaxParetooptimal guarantees under the standard regret e.g. in bandit problems withmultiple best arms and LipschitzHlder bandits. We conduct largescaleempirical evaluations demonstrating the efficacy of our proposed algorithms.,4
Fast computation of rankings from pairwise comparisons We study the ranking of individuals teams or objects on the basis ofpairwise comparisons using the BradleyTerry model. Maximumlikelihoodestimates of rankings within this model are commonly made using a simpleiterative algorithm first introduced by Zermelo almost a century ago. Here wedescribe an alternative and similarly simple iteration that solves the sameproblem much faster  over a hundred times faster in some cases. Wedemonstrate this algorithm with applications to a range of example data setsand derive some results regarding its convergence.,4
Discrimination in machine learning algorithms Machine learning algorithms are routinely used for business decisions thatmay directly affect individuals for example because a credit scoringalgorithm refuses them a loan. It is then relevant from an ethical and legalpoint of view to ensure that these algorithms do not discriminate based onsensitive attributes like sex or race which may occur unwittingly andunknowingly by the operator and the management. Statistical tools and methodsare then required to detect and eliminate such potential biases.,4
Private Convex Optimization in General Norms We propose a new framework for differentially private optimization of convexfunctions which are Lipschitz in an arbitrary norm normxcdot. Ouralgorithms are based on a regularized exponential mechanism which samples fromthe density propto expkFmu r where F is the empirical loss and ris a regularizer which is strongly convex with respect to normxcdotgeneralizing a recent work of citeGLL to nonEuclidean settings. We showthat this mechanism satisfies Gaussian differential privacy and solves bothDPERM empirical risk minimization and DPSCO stochastic convexoptimization by using localization tools from convex geometry. Our frameworkis the first to apply to private convex optimization in general normed spacesand directly recovers nonprivate SCO rates achieved by mirror descent as theprivacy parameter eps to infty. As applications for Lipschitzoptimization in ellp norms for all p in   we obtain the firstoptimal privacyutility tradeoffs for p   we improve tradeoffs obtainedby the recent works citeAsiFKT BassilyGN by at least a logarithmicfactor. Our ellp norm and Schattenp norm optimization frameworks arecomplemented with polynomialtime samplers whose query complexity we explicitlybound.,4
PRoA A Probabilistic Robustness Assessment against Functional Perturbations In safetycritical deep learning applications robustness measurement is avital predeployment phase. However existing robustness verification methodsare not sufficiently practical for deploying machine learning systems in thereal world. On the one hand these methods attempt to claim that noperturbations can fool deep neural networks DNNs which may be toostringent in practice. On the other hand existing works rigorously considerLp bounded additive perturbations on the pixel space althoughperturbations such as colour shifting and geometric transformations are morepractically and frequently occurring in the real world. Thus from thepractical standpoint we present a novel and general it probabilisticrobustness assessment method PRoA based on the adaptive concentration andit can measure the robustness of deep learning models against functionalperturbations. PRoA can provide statistical guarantees on the probabilisticrobustness of a model textiti.e. the probability of failure encountered bythe trained model after deployment. Our experiments demonstrate theeffectiveness and flexibility of PRoA in terms of evaluating the probabilisticrobustness against a broad range of functional perturbations and PRoA canscale well to various largescale deep neural networks compared to existingstateoftheart baselines. For the purpose of reproducibility we release ourtool on GitHub url,4
MultiModel Federated Learning with Provable Guarantees Federated Learning FL is a variant of distributed learning where edgedevices collaborate to learn a model without sharing their data with thecentral server or each other. We refer to the process of training multipleindependent models simultaneously in a federated setting using a common pool ofclients as multimodel FL. In this work we propose two variants of the popularFedAvg algorithm for multimodel FL with provable convergence guarantees. Wefurther show that for the same amount of computation multimodel FL can havebetter performance than training each model separately. We supplement ourtheoretical results with experiments in strongly convex convex and nonconvexsettings.,4
Video Coding Using Learned Latent GAN Compression We propose in this paper a new paradigm for facial video compression. Weleverage the generative capacity of GANs such as StyleGAN to represent andcompress a video including intra and inter compression. Each frame is invertedin the latent space of StyleGAN from which the optimal compression is learned.To do so a diffeomorphic latent representation is learned using a normalizingflows model where an entropy model can be optimized for image coding. Inaddition we propose a new perceptual loss that is more efficient than othercounterparts. Finally an entropy model for video inter coding with residual isalso learned in the previously constructed latent representation. Our methodSGANC is simple faster to train and achieves better results for image andvideo coding compared to stateoftheart codecs such as VTM AV and recentdeep learning techniques. In particular it drastically minimizes perceptualdistortion at low bit rates.,4
Towards understanding how momentum improves generalization in deep learning Stochastic gradient descent SGD with momentum is widely used for trainingmodern deep learning architectures. While it is wellunderstood that usingmomentum can lead to faster convergence rate in various settings it has alsobeen observed that momentum yields higher generalization. Prior work argue thatmomentum stabilizes the SGD noise during training and this leads to highergeneralization. In this paper we adopt another perspective and firstempirically show that gradient descent with momentum GDM significantlyimproves generalization compared to gradient descent GD in some deep learningproblems. From this observation we formally study how momentum improvesgeneralization. We devise a binary classification setting where a onehiddenlayer overparameterized convolutional neural network trained with GDMprovably generalizes better than the same network trained with GD when bothalgorithms are similarly initialized. The key insight in our analysis is thatmomentum is beneficial in datasets where the examples share some feature butdiffer in their margin. Contrary to GD that memorizes the small margin dataGDM still learns the feature in these data thanks to its historical gradients.Lastly we empirically validate our theoretical findings.,4
Guaranteed Discovery of Controllable Latent States with MultiStep Inverse Models A person walking along a city street who tries to model all aspects of theworld would quickly be overwhelmed by a multitude of shops cars and peoplemoving in and out of view following their own complex and inscrutabledynamics. Exploration and navigation in such an environment is an everydaytask requiring no vast exertion of mental resources. Is it possible to turnthis fire hose of sensory information into a minimal latent state which isnecessary and sufficient for an agent to successfully act in the world Weformulate this question concretely and propose the AgentControllable StateDiscovery algorithm ACState which has theoretical guarantees and ispractically demonstrated to discover the textitminimal controllable latentstate which contains all of the information necessary for controlling theagent while fully discarding all irrelevant information. This algorithmconsists of a multistep inverse model predicting actions from distantobservations with an information bottleneck. ACState enables localizationexploration and navigation without reward or demonstrations. We demonstratethe discovery of controllable latent state in three domains localizing a robotarm with distractions e.g. changing lighting conditions and backgroundexploring in a maze alongside other agents and navigating in the Matterporthouse simulator.,4
Energy Trees Regression and Classification With Structured and MixedType Covariates The continuous growth of data complexity requires methods and models thatadequately account for nontrivial structures as any simplification may induceloss of information. Many analytical tools have been introduced to work withcomplex data objects in their original form but such tools can typically dealwith singletype variables only. In this work we propose Energy Trees as amodel for regression and classification tasks where covariates are potentiallyboth structured and of different types. Energy Trees incorporate EnergyStatistics to generalize Conditional Trees from which they inheritstatistically sound foundations interpretability scale invariance and lackof distributional assumptions. We focus on functions and graphs as structuredcovariates and we show how the model can be easily adapted to work with almostany other type of variable. Through an extensive simulation study we highlightthe good performance of our proposal in terms of variable selection androbustness to overfitting. Finally we validate the models predictive abilitythrough two empirical analyses with human biological data.,4
MultiStudy Boosting Theoretical Considerations for Merging vs. Ensembling Crossstudy replicability is a powerful model evaluation criterion thatemphasizes generalizability of predictions. When training crossstudyreplicable prediction models it is critical to decide between merging andtreating the studies separately. We study boosting algorithms in the presenceof potential heterogeneity in predictoroutcome relationships across studiesand compare two multistudy learning strategies  merging all the studies andtraining a single model and  multistudy ensembling which involves traininga separate model on each study and ensembling the resulting predictions. In theregression setting we provide theoretical guidelines based on an analyticaltransition point to determine whether it is more beneficial to merge or toensemble for boosting with linear learners. In addition we characterize abiasvariance decomposition of estimation error for boosting withcomponentwise linear learners. We verify the theoretical transition pointresult in simulation and illustrate how it can guide the decision on mergingvs. ensembling in an application to breast cancer gene expression data.,4
Mathematical Foundations of GraphBased Bayesian SemiSupervised Learning In recent decades science and engineering have been revolutionized by amomentous growth in the amount of available data. However despite theunprecedented ease with which data are now collected and stored labeling databy supplementing each feature with an informative tag remains to bechallenging. Illustrative tasks where the labeling process requires expertknowledge or is tedious and timeconsuming include labeling Xrays with adiagnosis protein sequences with a protein type texts by their topic tweetsby their sentiment or videos by their genre. In these and numerous otherexamples only a few features may be manually labeled due to cost and timeconstraints. How can we best propagate label information from a small number ofexpensive labeled features to a vast number of unlabeled ones This is thequestion addressed by semisupervised learning SSL.,4
Rewiring Networks for Graph Neural Network Training Using Discrete Geometry Information oversquashing is a phenomenon of inefficient informationpropagation between distant nodes on networks. It is an important problem thatis known to significantly impact the training of graph neural networks GNNsas the receptive field of a node grows exponentially. To mitigate this problema preprocessing procedure known as rewiring is often applied to the inputnetwork. In this paper we investigate the use of discrete analogues ofclassical geometric notions of curvature to model information flow on networksand rewire them. We show that these classical notions achieve stateoftheartperformance in GNN training accuracy on a variety of realworld networkdatasets. Moreover compared to the current stateoftheart these classicalnotions exhibit a clear advantage in computational runtime by several orders ofmagnitude.,4
Single Model Uncertainty Estimation via Stochastic Data Centering We are interested in estimating the uncertainties of deep neural networkswhich play an important role in many scientific and engineering problems. Inthis paper we present a striking new finding that an ensemble of neuralnetworks with the same weight initialization trained on datasets that areshifted by a constant bias gives rise to slightly inconsistent trained modelswhere the differences in predictions are a strong indicator of epistemicuncertainties. Using the neural tangent kernel NTK we demonstrate that thisphenomena occurs in part because the NTK is not shiftinvariant. Since this isachieved via a trivial input transformation we show that it can therefore beapproximated using just a single neural network  using a technique that wecall DeltaUQ  that estimates uncertainty around prediction bymarginalizing out the effect of the biases. We show that DeltaUQsuncertainty estimates are superior to many of the current methods on a varietyof benchmarks  outlier rejection calibration under distribution shift andsequential design optimization of black box functions.,4
Can Populationbased Engagement Improve Personalisation A Novel Dataset and Experiments This work explores how populationbased engagement prediction can addresscoldstart at scale in large learning resource collections. The paperintroduces i VLE a novel dataset that consists of content and video basedfeatures extracted from publicly available scientific video lectures coupledwith implicit and explicit signals related to learner engagement ii twostandard tasks related to predicting and ranking contextagnostic engagement invideo lectures with preliminary baselines and iii a set of experiments thatvalidate the usefulness of the proposed dataset. Our experimental resultsindicate that the newly proposed VLE dataset leads to building contextagnosticengagement prediction models that are significantly performant than ones basedon previous datasets mainly attributing to the increase of training examples.VLE datasets suitability in building models towards Computer ScienceArtificial Intelligence education focused on elearning MOOC usecases is alsoevidenced. Further experiments in combining the built model with apersonalising algorithm show promising improvements in addressing thecoldstart problem encountered in educational recommenders. This is the largestand most diverse publicly available dataset to our knowledge that deals withlearner engagement prediction tasks. The dataset helper tools descriptivestatistics and example code snippets are available publicly.,4
Generalized Identifiability Bounds for Mixture Models with Grouped Samples Recent work has shown that finite mixture models with m components areidentifiable while making no assumptions on the mixture components so long asone has access to groups of samples of size m which are known to come fromthe same mixture component. In this work we generalize that result and showthat if every subset of k mixture components of a mixture model are linearlyindependent then that mixture model is identifiable with only mksamples per group. We further show that this value cannot be improved. We provean analogous result for a stronger form of identifiability known asdeterminedness along with a corresponding lower bound. This independenceassumption almost surely holds if mixture components are chosen randomly from akdimensional space. We describe some implications of our results formultinomial mixture models and topic modeling.,4
Grounding Aleatoric Uncertainty in Unsupervised Environment Design Adaptive curricula in reinforcement learning RL have proven effective forproducing policies robust to discrepancies between the train and testenvironment. Recently the Unsupervised Environment Design UED frameworkgeneralized RL curricula to generating sequences of entire environmentsleading to new methods with robust minimax regret properties. Problematicallyin partiallyobservable or stochastic settings optimal policies may depend onthe groundtruth distribution over aleatoric parameters of the environment inthe intended deployment setting while curriculum learning necessarily shiftsthe training distribution. We formalize this phenomenon as curriculuminducedcovariate shift CICS and describe how its occurrence in aleatoric parameterscan lead to suboptimal policies. Directly sampling these parameters from thegroundtruth distribution avoids the issue but thwarts curriculum learning. Wepropose SAMPLR a minimax regret UED method that optimizes the groundtruthutility function even when the underlying training data is biased due to CICS.We prove and validate on challenging domains that our approach preservesoptimality under the groundtruth distribution while promoting robustnessacross the full range of environment settings.,4
A clinically motivated selfsupervised approach for contentbased image retrieval of CT liver images Deep learningbased approaches for contentbased image retrieval CBIR of CTliver images is an active field of research but suffers from some criticallimitations. First they are heavily reliant on labeled data which can bechallenging and costly to acquire. Second they lack transparency andexplainability which limits the trustworthiness of deep CBIR systems. Weaddress these limitations by  proposing a selfsupervised learning frameworkthat incorporates domainknowledge into the training procedure and providing the first representation learning explainability analysis in thecontext of CBIR of CT liver images. Results demonstrate improved performancecompared to the standard selfsupervised approach across several metrics aswell as improved generalisation across datasets. Further we conduct the firstrepresentation learning explainability analysis in the context of CBIR whichreveals new insights into the feature extraction process. Lastly we perform acase study with crossexamination CBIR that demonstrates the usability of ourproposed framework. We believe that our proposed framework could play a vitalrole in creating trustworthy deep CBIR systems that can successfully takeadvantage of unlabeled data.,4
TCT Convexifying Federated Learning using Bootstrapped Neural Tangent Kernels Stateoftheart federated learning methods can perform far worse than theircentralized counterparts when clients have dissimilar data distributions. Forneural networks even when centralized SGD easily finds a solution that issimultaneously performant for all clients current federated optimizationmethods fail to converge to a comparable solution. We show that thisperformance disparity can largely be attributed to optimization challengespresented by nonconvexity. Specifically we find that the early layers of thenetwork do learn useful features but the final layers fail to make use ofthem. That is federated optimization applied to this nonconvex problemdistorts the learning of the final layers. Leveraging this observation wepropose a TrainConvexifyTrain TCT procedure to sidestep this issue firstlearn features using offtheshelf methods e.g. FedAvg then optimize aconvexified problem obtained from the networks empirical neural tangent kernelapproximation. Our technique yields accuracy improvements of up to  onFMNIST and  on CIFAR when clients have dissimilar data.,4
The Poisson binomial mechanism for secure and private federated learning We introduce the Poisson Binomial mechanism PBM a discrete differentialprivacy mechanism for distributed mean estimation DME with applications tofederated learning and analytics. We provide a tight analysis of its privacyguarantees showing that it achieves the same privacyaccuracy tradeoffs asthe continuous Gaussian mechanism. Our analysis is based on a novel bound onthe Rnyi divergence of two Poisson binomial distributions that may be ofindependent interest.,4
Fuzzy Clustering by Hyperbolic Smoothing We propose a novel method for building fuzzy clusters of large data setsusing a smoothing numerical approach. The usual sumofsquares criterion isrelaxed so the search for good fuzzy partitions is made on a continuous spacerather than a combinatorial space as in classical methods citeHartigan. Thesmoothing allows a conversion from a strongly nondifferentiable problem intodifferentiable subproblems of optimization without constraints of lowdimension by using a differentiable function of infinite class. For theimplementation of the algorithm we used the statistical software R and theresults obtained were compared to the traditional fuzzy Cmeans methodproposed by Bezdek.,4
Recommendation Systems with DistributionFree Reliability Guarantees When building recommendation systems we seek to output a helpful set ofitems to the user. Under the hood a ranking model predicts which of twocandidate items is better and we must distill these pairwise comparisons intothe userfacing output. However a learned ranking model is never perfect sotaking its predictions at face value gives no guarantee that the userfacingoutput is reliable. Building from a pretrained ranking model we show how toreturn a set of items that is rigorously guaranteed to contain mostly gooditems. Our procedure endows any ranking model with rigorous finitesamplecontrol of the false discovery rate FDR regardless of the unknown datadistribution. Moreover our calibration algorithm enables the easy andprincipled integration of multiple objectives in recommender systems. As anexample we show how to optimize for recommendation diversity subject to auserspecified level of FDR control circumventing the need to specify ad hocweights of a diversity loss against an accuracy loss. Throughout we focus onthe problem of learning to rank a set of possible recommendations evaluatingour methods on the Yahoo Learning to Rank and MSMarco datasets.,4
Causal Graphs Underlying Generative Models Path to Learning with Limited Data Training generative models that capture rich semantics of the data andinterpreting the latent representations encoded by such models are veryimportant problems in unsupervised learning. In this work we provide a simplealgorithm that relies on perturbation experiments on latent codes of apretrained generative autoencoder to uncover a causal graph that is implied bythe generative model. We leverage pretrained attribute classifiers and performperturbation experiments to check for influence of a given latent variable on asubset of attributes. Given this we show that one can fit an effective causalgraph that models a structural equation model between latent codes taken asexogenous variables and attributes taken as observed variables. One interestingaspect is that a single latent variable controls multiple overlapping subsetsof attributes unlike conventional approach that tries to impose fullindependence. Using a pretrained RNNbased generative autoencoder trained on adataset of peptide sequences we demonstrate that the learnt causal graph fromour algorithm between various attributes and latent codes can be used topredict a specific property for sequences which are unseen. We compareprediction models trained on either all available attributes or only the onesin the Markov blanket and empirically show that in both the unsupervised andsupervised regimes typically using the predictor that relies on Markovblanket attributes generalizes better for outofdistribution sequences.,4
VTrackIt A Synthetic SelfDriving Dataset with Infrastructure and Pooled Vehicle Information Artificial intelligence solutions for Autonomous Vehicles AVs have beendeveloped using publicly available datasets such as Argoverse ApolloScapeLevel and NuScenes. One major limitation of these datasets is the absence ofinfrastructure andor pooled vehicle information like lane line type vehiclespeed traffic signs and intersections. Such information is necessary and notcomplementary to eliminating highrisk edge cases. The rapid advancements inVehicletoInfrastructure and VehicletoVehicle technologies show promise thatinfrastructure and pooled vehicle information will soon be accessible in nearrealtime. Taking a leap in the future we introduce the first comprehensivesynthetic dataset with intelligent infrastructure and pooled vehicleinformation for advancing the next generation of AVs named VTrackIt. We alsointroduce the first deep learning model InfraGAN for trajectory predictionsthat considers such information. Our experiments with InfraGAN show that thecomprehensive information offered by VTrackIt reduces the number of highriskedge cases. The VTrackIt dataset is available upon request under the CreativeCommons CC BYNCSA . license at httpvtrackit.irda.club.,4
Recommendation Systems with DistributionFree Reliability Guarantees When building recommendation systems we seek to output a helpful set ofitems to the user. Under the hood a ranking model predicts which of twocandidate items is better and we must distill these pairwise comparisons intothe userfacing output. However a learned ranking model is never perfect sotaking its predictions at face value gives no guarantee that the userfacingoutput is reliable. Building from a pretrained ranking model we show how toreturn a set of items that is rigorously guaranteed to contain mostly gooditems. Our procedure endows any ranking model with rigorous finitesamplecontrol of the false discovery rate FDR regardless of the unknown datadistribution. Moreover our calibration algorithm enables the easy andprincipled integration of multiple objectives in recommender systems. As anexample we show how to optimize for recommendation diversity subject to auserspecified level of FDR control circumventing the need to specify ad hocweights of a diversity loss against an accuracy loss. Throughout we focus onthe problem of learning to rank a set of possible recommendations evaluatingour methods on the Yahoo Learning to Rank and MSMarco datasets.,4
Multiscale Causal Structure Learning The inference of causal structures from observed data plays a key role inunveiling the underlying dynamics of the system. This paper exposes a novelmethod named MultiscaleCausal Structure Learning MSCASTLE to estimate thestructure of linear causal relationships occurring at different time scales.Differently from existing approaches MSCASTLE takes explicitly into accountinstantaneous and lagged interrelations between multiple time seriesrepresented at different scales hinging on stationary wavelet transform andnonconvex optimization. MSCASTLE incorporates as a special case asinglescale version named SSCASTLE which compares favorably in terms ofcomputational efficiency performance and robustness with respect to the stateof the art onto synthetic data. We used MSCASTLE to study the multiscalecausal structure of the risk of  global equity markets during covidpandemic illustrating how MSCASTLE can extract meaningful information thanksto its multiscale analysis outperforming SSCASTLE. We found that the mostpersistent and strongest interactions occur at midterm time resolutions.Moreover we identified the stock markets that drive the risk during theconsidered period Brazil Canada and Italy. The proposed approach can beexploited by financial investors who depending to their investment horizoncan manage the risk within equity portfolios from a causal perspective.,4
DeeplyLearned Generalized Linear Models with Missing Data Deep Learning DL methods have dramatically increased in popularity inrecent years with significant growth in their application to supervisedlearning problems in the biomedical sciences. However the greater prevalenceand complexity of missing data in modern biomedical datasets presentsignificant challenges for DL methods. Here we provide a formal treatment ofmissing data in the context of deeply learned generalized linear models asupervised DL architecture for regression and classification problems. Wepropose a new architecture textitdlglm that is one of the first to be ableto flexibly account for both ignorable and nonignorable patterns ofmissingness in input features and response at training time. We demonstratethrough statistical simulation that our method outperforms existing approachesfor supervised learning tasks in the presence of missing not at random MNARmissingness. We conclude with a case study of a Bank Marketing dataset from theUCI Machine Learning Repository in which we predict whether clients subscribedto a product based on phone survey data.,4
