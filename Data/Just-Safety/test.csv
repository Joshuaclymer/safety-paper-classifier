text,label
"Active Exploration for Inverse Reinforcement Learning Inverse Reinforcement Learning (IRL) is a powerful paradigm for inferring areward function from expert demonstrations. Many IRL algorithms require a knowntransition model and sometimes even a known expert policy, or they at leastrequire access to a generative model. However, these assumptions are too strongfor many real-world applications, where the environment can be accessed onlythrough sequential interaction. We propose a novel IRL algorithm: Activeexploration for Inverse Reinforcement Learning (AceIRL), which activelyexplores an unknown environment and expert policy to quickly learn the expert'sreward function and identify a good policy. AceIRL uses previous observationsto construct confidence intervals that capture plausible reward functions andfind exploration policies that focus on the most informative regions of theenvironment. AceIRL is the first approach to active IRL with sample-complexitybounds that does not require a generative model of the environment. AceIRLmatches the sample complexity of active IRL with a generative model in theworst case. Additionally, we establish a problem-dependent bound that relatesthe sample complexity of AceIRL to the suboptimality gap of a given IRLproblem. We empirically evaluate AceIRL in simulations and find that itsignificantly outperforms more naive exploration strategies.",0
"Learning to summarize from human feedback As language models become more powerful, training and evaluation areincreasingly bottlenecked by the data and metrics used for a particular task.For example, summarization models are often trained to predict human referencesummaries and evaluated using ROUGE, but both of these metrics are roughproxies for what we really care about -- summary quality. In this work, we showthat it is possible to significantly improve summary quality by training amodel to optimize for human preferences. We collect a large, high-qualitydataset of human comparisons between summaries, train a model to predict thehuman-preferred summary, and use that model as a reward function to fine-tune asummarization policy using reinforcement learning. We apply our method to aversion of the TL;DR dataset of Reddit posts and find that our modelssignificantly outperform both human reference summaries and much larger modelsfine-tuned with supervised learning alone. Our models also transfer to CNN/DMnews articles, producing summaries nearly as good as the human referencewithout any news-specific fine-tuning. We conduct extensive analyses tounderstand our human feedback dataset and fine-tuned models We establish thatour reward model generalizes to new datasets, and that optimizing our rewardmodel results in better summaries than optimizing ROUGE according to humans. Wehope the evidence from our paper motivates machine learning researchers to paycloser attention to how their training loss affects the model behavior theyactually want.",0
"Parametrically Retargetable Decision-Makers Tend To Seek Power If capable AI agents are generally incentivized to seek power in service ofthe objectives we specify for them, then these systems will pose enormousrisks, in addition to enormous benefits. In fully observable environments, mostreward functions have an optimal policy which seeks power by keeping optionsopen and staying alive. However, the real world is neither fully observable,nor will agents be perfectly optimal. We consider a range of models of AIdecision-making, from optimal, to random, to choices informed by learning andinteracting with an environment. We discover that many decision-makingfunctions are retargetable, and that retargetability is sufficient to causepower-seeking tendencies. Our functional criterion is simple and broad. We showthat a range of qualitatively dissimilar decision-making procedures incentivizeagents to seek power. We demonstrate the flexibility of our results byreasoning about learned policy incentives in Montezuma's Revenge. These resultssuggest a safety risk: Eventually, highly retargetable training procedures maytrain real-world agents which seek power over humans.",0
"Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets In this paper we propose to study generalization of neural networks on smallalgorithmically generated datasets. In this setting, questions about dataefficiency, memorization, generalization, and speed of learning can be studiedin great detail. In some situations we show that neural networks learn througha process of grokking a pattern in the data, improving generalizationperformance from random chance level to perfect generalization, and that thisimprovement in generalization can happen well past the point of overfitting. Wealso study generalization as a function of dataset size and find that smallerdatasets require increasing amounts of optimization for generalization. Weargue that these datasets provide a fertile ground for studying a poorlyunderstood aspect of deep learning: generalization of overparametrized neuralnetworks beyond memorization of the finite training dataset.",0
"WeShort: Out-of-distribution Detection With Weak Shortcut structure Neural networks have achieved impressive performance for data in thedistribution which is the same as the training set but can produce anoverconfident incorrect result for the data these networks have never seen.Therefore, it is essential to detect whether inputs come fromout-of-distribution(OOD) in order to guarantee the safety of neural networksdeployed in the real world. In this paper, we propose a simple and effectivepost-hoc technique, WeShort, to reduce the overconfidence of neural networks onOOD data. Our method is inspired by the observation of the internal residualstructure, which shows the separation of the OOD and in-distribution (ID) datain the shortcut layer. Our method is compatible with different OOD detectionscores and can generalize well to different architectures of networks. Wedemonstrate our method on various OOD datasets to show its competitiveperformances and provide reasonable hypotheses to explain why our method works.On the ImageNet benchmark, Weshort achieves state-of-the-art performance on thefalse positive rate (FPR95) and the area under the receiver operatingcharacteristic (AUROC) on the family of post-hoc methods.",0
"The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models Reward hacking -- where RL agents exploit gaps in misspecified rewardfunctions -- has been widely observed, but not yet systematically studied. Tounderstand how reward hacking arises, we construct four RL environments withmisspecified rewards. We investigate reward hacking as a function of agentcapabilities: model capacity, action space resolution, observation space noise,and training time. More capable agents often exploit reward misspecifications,achieving higher proxy reward and lower true reward than less capable agents.Moreover, we find instances of phase transitions: capability thresholds atwhich the agent's behavior qualitatively shifts, leading to a sharp decrease inthe true reward. Such phase transitions pose challenges to monitoring thesafety of ML systems. To address this, we propose an anomaly detection task foraberrant policies and offer several baseline detectors.",0
"Missingness Bias in Model Debugging Missingness, or the absence of features from an input, is a conceptfundamental to many model debugging tools. However, in computer vision, pixelscannot simply be removed from an image. One thus tends to resort to heuristicssuch as blacking out pixels, which may in turn introduce bias into thedebugging process. We study such biases and, in particular, show howtransformer-based architectures can enable a more natural implementation ofmissingness, which side-steps these issues and improves the reliability ofmodel debugging in practice. Our code is available at",0
"Acquisition of Chess Knowledge in AlphaZero What is learned by sophisticated neural network agents such as AlphaZero?This question is of both scientific and practical interest. If therepresentations of strong neural networks bear no resemblance to humanconcepts, our ability to understand faithful explanations of their decisionswill be restricted, ultimately limiting what we can achieve with neural networkinterpretability. In this work we provide evidence that human knowledge isacquired by the AlphaZero neural network as it trains on the game of chess. Byprobing for a broad range of human chess concepts we show when and where theseconcepts are represented in the AlphaZero network. We also provide abehavioural analysis focusing on opening play, including qualitative analysisfrom chess Grandmaster Vladimir Kramnik. Finally, we carry out a preliminaryinvestigation looking at the low-level details of AlphaZero's representations,and make the resulting behavioural and representational analyses availableonline.",0
"Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks The field of defense strategies against adversarial attacks has significantlygrown over the last years, but progress is hampered as the evaluation ofadversarial defenses is often insufficient and thus gives a wrong impression ofrobustness. Many promising defenses could be broken later on, making itdifficult to identify the state-of-the-art. Frequent pitfalls in the evaluationare improper tuning of hyperparameters of the attacks, gradient obfuscation ormasking. In this paper we first propose two extensions of the PGD-attackovercoming failures due to suboptimal step size and problems of the objectivefunction. We then combine our novel attacks with two complementary existingones to form a parameter-free, computationally affordable and user-independentensemble of attacks to test adversarial robustness. We apply our ensemble toover 50 models from papers published at recent top machine learning andcomputer vision venues. In all except one of the cases we achieve lower robusttest accuracy than reported in these papers, often by more than $10\%$,identifying several broken defenses.",0
"WILDS: A Benchmark of in-the-Wild Distribution Shifts Distribution shifts -- where the training distribution differs from the testdistribution -- can substantially degrade the accuracy of machine learning (ML)systems deployed in the wild. Despite their ubiquity in the real-worlddeployments, these distribution shifts are under-represented in the datasetswidely used in the ML community today. To address this gap, we present WILDS, acurated benchmark of 10 datasets reflecting a diverse range of distributionshifts that naturally arise in real-world applications, such as shifts acrosshospitals for tumor identification; across camera traps for wildlifemonitoring; and across time and location in satellite imaging and povertymapping. On each dataset, we show that standard training yields substantiallylower out-of-distribution than in-distribution performance. This gap remainseven with models trained by existing methods for tackling distribution shifts,underscoring the need for new methods for training models that are more robustto the types of distribution shifts that arise in practice. To facilitatemethod development, we provide an open-source package that automates datasetloading, contains default model architectures and hyperparameters, andstandardizes evaluations. Code and leaderboards are available at",0
"Robustness of Epinets against Distributional Shifts Recent work introduced the epinet as a new approach to uncertainty modelingin deep learning. An epinet is a small neural network added to traditionalneural networks, which, together, can produce predictive distributions. Inparticular, using an epinet can greatly improve the quality of jointpredictions across multiple inputs, a measure of how well a neural networkknows what it does not know. In this paper, we examine whether epinets canoffer similar advantages under distributional shifts. We find that, acrossImageNet-A/O/C, epinets generally improve robustness metrics. Moreover, theseimprovements are more significant than those afforded by even very largeensembles at orders of magnitude lower computational costs. However, theseimprovements are relatively small compared to the outstanding issues indistributionally-robust deep learning. Epinets may be a useful tool in thetoolbox, but they are far from the complete solution.",0
"Adversarial NLI: A New Benchmark for Natural Language Understanding We introduce a new large-scale NLI benchmark dataset, collected via aniterative, adversarial human-and-model-in-the-loop procedure. We show thattraining models on this new dataset leads to state-of-the-art performance on avariety of popular NLI benchmarks, while posing a more difficult challenge withits new test set. Our analysis sheds light on the shortcomings of currentstate-of-the-art models, and shows that non-expert annotators are successful atfinding their weaknesses. The data collection method can be applied in anever-ending learning scenario, becoming a moving target for NLU, rather than astatic benchmark that will quickly saturate.",0
"The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization We introduce four new real-world distribution shift datasets consisting ofchanges in image style, image blurriness, geographic location, cameraoperation, and more. With our new datasets, we take stock of previouslyproposed methods for improving out-of-distribution robustness and put them tothe test. We find that using larger models and artificial data augmentationscan improve robustness on real-world distribution shifts, contrary to claims inprior work. We find improvements in artificial robustness benchmarks cantransfer to real-world distribution shifts, contrary to claims in prior work.Motivated by our observation that data augmentations can help with real-worlddistribution shifts, we also introduce a new data augmentation method whichadvances the state-of-the-art and outperforms models pretrained with 1000 timesmore labeled data. Overall we find that some methods consistently help withdistribution shifts in texture and local image statistics, but these methods donot help with some other distribution shifts like geographic changes. Ourresults show that future research must study multiple distribution shiftssimultaneously, as we demonstrate that no evaluated method consistentlyimproves robustness.",0
"HierarchicalForecast: A Reference Framework for Hierarchical Forecasting in Python Large collections of time series data are commonly organized intocross-sectional structures with different levels of aggregation; examplesinclude product and geographical groupings. A necessary condition for coherentdecision-making and planning, with such datasets, is for the dis-aggregatedseries' forecasts to add up exactly to the aggregated series forecasts, whichmotivates the creation of novel hierarchical forecasting algorithms. Thegrowing interest of the Machine Learning community in cross-sectionalhierarchical forecasting systems states that we are in a propitious moment toensure that scientific endeavors are grounded on sound baselines. For thisreason, we put forward the HierarchicalForecast library, which containspreprocessed publicly available datasets, evaluation metrics, and a compiledset of statistical baseline models. Our Python-based framework aims to bridgethe gap between statistical, econometric modeling, and Machine Learningforecasting research. Code and documentation are available in",0
"On Single Point Forecasts for Fat-Tailed Variables We discuss common errors and fallacies when using naive evidence basedempiricism and point forecasts for fat-tailed variables, as well as theinsufficiency of using naive first-order scientific methods for tail riskmanagement. We use the COVID-19 pandemic as the background for the discussionand as an example of a phenomenon characterized by a multiplicative nature, andwhat mitigating policies must result from the statistical properties andassociated risks. In doing so, we also respond to the points raised byIoannidis et al. (2020).",0
"BR-SNIS: Bias Reduced Self-Normalized Importance Sampling Importance Sampling (IS) is a method for approximating expectations under atarget distribution using independent samples from a proposal distribution andthe associated importance weights. In many applications, the targetdistribution is known only up to a normalization constant, in which caseself-normalized IS (SNIS) can be used. While the use of self-normalization canhave a positive effect on the dispersion of the estimator, it introduces bias.In this work, we propose a new method, BR-SNIS, whose complexity is essentiallythe same as that of SNIS and which significantly reduces bias withoutincreasing the variance. This method is a wrapper in the sense that it uses thesame proposal samples and importance weights as SNIS, but makes clever use ofiterated sampling--importance resampling (ISIR) to form a bias-reduced versionof the estimator. We furnish the proposed algorithm with rigorous theoreticalresults, including new bias, variance and high-probability bounds, and theseare illustrated by numerical examples.",1
"Is a Caption Worth a Thousand Images? A Controlled Study for Representation Learning The development of CLIP [Radford et al., 2021] has sparked a debate onwhether language supervision can result in vision models with more transferablerepresentations than traditional image-only methods. Our work studies thisquestion through a carefully controlled comparison of two approaches in termsof their ability to learn representations that generalize to downstreamclassification tasks. We find that when the pre-training dataset meets certaincriteria -- it is sufficiently large and contains descriptive captions with lowvariability -- image-only methods do not match CLIP's transfer performance,even when they are trained with more image data. However, contrary to what onemight expect, there are practical settings in which these criteria are not met,wherein added supervision through captions is actually detrimental. Motivatedby our findings, we devise simple prescriptions to enable CLIP to betterleverage the language information present in existing pre-training datasets.",1
"Goal-Conditioned Generators of Deep Policies Goal-conditioned Reinforcement Learning (RL) aims at learning optimalpolicies, given goals encoded in special command inputs. Here we studygoal-conditioned neural nets (NNs) that learn to generate deep NN policies inform of context-specific weight matrices, similar to Fast Weight Programmersand other methods from the 1990s. Using context commands of the form generatea policy that achieves a desired expected return, our NN generators combinepowerful exploration of parameter space with generalization across commands toiteratively find better and better policies. A form of weight-sharingHyperNetworks and policy embeddings scales our method to generate deep NNs.Experiments show how a single learned policy generator can produce policiesthat achieve any return seen during training. Finally, we evaluate ouralgorithm on a set of continuous control tasks where it exhibits competitiveperformance. Our code is public.",1
"Online Active Regression Active regression considers a linear regression problem where the learnerreceives a large number of data points but can only observe a small number oflabels. Since online algorithms can deal with incremental training data andtake advantage of low computational cost, we consider an online extension ofthe active regression problem: the learner receives data points one by one andimmediately decides whether it should collect the corresponding labels. Thegoal is to efficiently maintain the regression of received data points with asmall budget of label queries. We propose novel algorithms for this problemunder $\ell_p$ loss where $p\in[1,2]$. To achieve a $(1+\epsilon)$-approximatesolution, our proposed algorithms only require$\tilde{\mathcal{O}}(\epsilon^{-2} d \log(n\kappa))$ queries of labels, where$n$ is the number of data points and $\kappa$ is a quantity, called thecondition number, of the data points. The numerical results verify ourtheoretical results and show that our methods have comparable performance withoffline active regression algorithms.",1
"The role of the geometric mean in case-control studies Historically used in settings where the outcome is rare or data collection isexpensive, outcome-dependent sampling is relevant to many modern settings wheredata is readily available for a biased sample of the target population, such aspublic administrative data. Under outcome-dependent sampling, common effectmeasures such as the average risk difference and the average risk ratio are notidentified, but the conditional odds ratio is. Aggregation of the conditionalodds ratio is challenging since summary measures are generally not identified.Furthermore, the marginal odds ratio can be larger (or smaller) than allconditional odds ratios. This so-called non-collapsibility of the odds ratio isavoidable if we use an alternative aggregation to the standard arithmetic mean.We provide a new definition of collapsibility that makes this choice ofaggregation method explicit, and we demonstrate that the odds ratio iscollapsible under geometric aggregation. We describe how to partially identify,estimate, and do inference on the geometric odds ratio under outcome-dependentsampling. Our proposed estimator is based on the efficient influence functionand therefore has doubly robust-style properties.",1
"A State Transition Model for Mobile Notifications via Survival Analysis Mobile notifications have become a major communication channel for socialnetworking services to keep users informed and engaged. As more mobileapplications push notifications to users, they constantly face decisions onwhat to send, when and how. A lack of research and methodology commonly leadsto heuristic decision making. Many notifications arrive at an inappropriatemoment or introduce too many interruptions, failing to provide value to usersand spurring users' complaints. In this paper we explore unique features ofinteractions between mobile notifications and user engagement. We propose astate transition framework to quantitatively evaluate the effectiveness ofnotifications. Within this framework, we develop a survival model for badgingnotifications assuming a log-linear structure and a Weibull distribution. Ourresults show that this model achieves more flexibility for applications andsuperior prediction accuracy than a logistic regression model. In particular,we provide an online use case on notification delivery time optimization toshow how we make better decisions, drive more user engagement, and provide morevalue to users.",1
"Package for Fast ABC-Boost This report presents the open-source package which implements the series ofour boosting works in the past years. In particular, the package includesmainly three lines of techniques, among which the following two are already thestandard implementations in popular boosted tree platforms:",1
"Minimax Rates for Robust Community Detection In this work, we study the problem of community detection in the stochasticblock model with adversarial node corruptions. Our main result is an efficientalgorithm that can tolerate an $\epsilon$-fraction of corruptions and achieveserror $O(\epsilon) + e^{-\frac{C}{2} (1 \pm o(1))}$ where $C = (\sqrt{a} -\sqrt{b})^2$ is the signal-to-noise ratio and $a/n$ and $b/n$ are theinter-community and intra-community connection probabilities respectively.These bounds essentially match the minimax rates for the SBM withoutcorruptions. We also give robust algorithms for $\mathbb{Z}_2$-synchronization.At the heart of our algorithm is a new semidefinite program that uses globalinformation to robustly boost the accuracy of a rough clustering. Moreover, weshow that our algorithms are doubly-robust in the sense that they work in aneven more challenging noise model that mixes adversarial corruptions withunbounded monotone changes, from the semi-random model.",1
"Estimating Classification Confidence Using Kernel Densities This paper investigates the post-hoc calibration of confidence forexploratory machine learning classification problems. The difficulty in theseproblems stems from the continuing desire to push the boundaries of whichcategories have enough examples to generalize from when curating datasets, andconfusion regarding the validity of those categories. We argue that for suchproblems the one-versus-all approach (top-label calibration) must be usedrather than the calibrate-the-full-response-matrix approach advocatedelsewhere in the literature. We introduce and test four new algorithms designedto handle the idiosyncrasies of category-specific confidence estimation. Chiefamong these methods is the use of kernel density ratios for confidencecalibration including a novel, bulletproof algorithm for choosing thebandwidth. We test our claims and explore the limits of calibration on abioinformatics application (PhANNs) as well as the classic MNIST benchmark.Finally, our analysis argues that post-hoc calibration should always beperformed, should be based only on the test dataset, and should besanity-checked visually.",1
"On uniform-in-time diffusion approximation for stochastic gradient descent The diffusion approximation of stochastic gradient descent (SGD) in currentliterature is only valid on a finite time interval. In this paper, we establishthe uniform-in-time diffusion approximation of SGD, by only assuming that theexpected loss is strongly convex and some other mild conditions, withoutassuming the convexity of each random loss function. The main technique is toestablish the exponential decay rates of the derivatives of the solution to thebackward Kolmogorov equation. The uniform-in-time approximation allows us tostudy asymptotic behaviors of SGD via the continuous stochastic differentialequation (SDE) even when the random objective function $f(\cdot;\xi)$ is notstrongly convex.",1
"Kullback-Leibler and Renyi divergences in reproducing kernel Hilbert space and Gaussian process settings In this work, we present formulations for regularized Kullback-Leibler andRényi divergences via the Alpha Log-Determinant (Log-Det) divergences betweenpositive Hilbert-Schmidt operators on Hilbert spaces in two different settings,namely (i) covariance operators and Gaussian measures defined on reproducingkernel Hilbert spaces (RKHS); and (ii) Gaussian processes with squaredintegrable sample paths. For characteristic kernels, the first setting leads todivergences between arbitrary Borel probability measures on a complete,separable metric space. We show that the Alpha Log-Det divergences arecontinuous in the Hilbert-Schmidt norm, which enables us to apply laws of largenumbers for Hilbert space-valued random variables. As a consequence of this, weshow that, in both settings, the infinite-dimensional divergences can beconsistently and efficiently estimated from their finite-dimensional versions,using finite-dimensional Gram matrices/Gaussian measures and finite sampledata, with {\it dimension-independent} sample complexities in all cases. RKHSmethodology plays a central role in the theoretical analysis in both settings.The mathematical formulation is illustrated by numerical experiments.",1
"An Asymmetric Contrastive Loss for Handling Imbalanced Datasets Contrastive learning is a representation learning method performed bycontrasting a sample to other similar samples so that they are brought closelytogether, forming clusters in the feature space. The learning process istypically conducted using a two-stage training architecture, and it utilizesthe contrastive loss (CL) for its feature learning. Contrastive learning hasbeen shown to be quite successful in handling imbalanced datasets, in whichsome classes are overrepresented while some others are underrepresented.However, previous studies have not specifically modified CL for imbalanceddatasets. In this work, we introduce an asymmetric version of CL, referred toas ACL, in order to directly address the problem of class imbalance. Inaddition, we propose the asymmetric focal contrastive loss (AFCL) as a furthergeneralization of both ACL and focal contrastive loss (FCL). Results on theFMNIST and ISIC 2018 imbalanced datasets show that AFCL is capable ofoutperforming CL and FCL in terms of both weighted and unweightedclassification accuracies. In the appendix, we provide a full axiomatictreatment on entropy, along with complete proofs.",1
"Probing the Robustness of Independent Mechanism Analysis for Representation Learning One aim of representation learning is to recover the original latent codethat generated the data, a task which requires additional information orinductive biases. A recently proposed approach termed Independent MechanismAnalysis (IMA) postulates that each latent source should influence the observedmixtures independently, complementing standard nonlinear independent componentanalysis, and taking inspiration from the principle of independent causalmechanisms. While it was shown in theory and experiments that IMA helpsrecovering the true latents, the method's performance was so far onlycharacterized when the modeling assumptions are exactly satisfied. Here, wetest the method's robustness to violations of the underlying assumptions. Wefind that the benefits of IMA-based regularization for recovering the truesources extend to mixing functions with various degrees of violation of the IMAprinciple, while standard regularizers do not provide the same merits.Moreover, we show that unregularized maximum likelihood recovers mixingfunctions which systematically deviate from the IMA principle, and provide anargument elucidating the benefits of IMA-based regularization.",1
"The d-separation criterion in Categorical Probability The d-separation criterion detects the compatibility of a joint probabilitydistribution with a directed acyclic graph through certain conditionalindependences. In this work, we study this problem in the context ofcategorical probability theory by introducing a categorical definition ofcausal models, a categorical notion of d-separation, and proving an abstractversion of the d-separation criterion. This approach has two main benefits.First, categorical d-separation is a very intuitive criterion based ontopological connectedness. Second, our results apply in measure-theoreticprobability (with standard Borel spaces), and therefore provide a clean proofof the equivalence of local and global Markov properties with causalcompatibility for continuous and mixed variables.",1
"Matching Normalizing Flows and Probability Paths on Manifolds Continuous Normalizing Flows (CNFs) are a class of generative models thattransform a prior distribution to a model distribution by solving an ordinarydifferential equation (ODE). We propose to train CNFs on manifolds byminimizing probability path divergence (PPD), a novel family of divergencesbetween the probability density path generated by the CNF and a targetprobability density path. PPD is formulated using a logarithmic massconservation formula which is a linear first order partial differentialequation relating the log target probabilities and the CNF's defining vectorfield. PPD has several key benefits over existing methods: it sidesteps theneed to solve an ODE per iteration, readily applies to manifold data, scales tohigh dimensions, and is compatible with a large family of target pathsinterpolating pure noise and data in finite time. Theoretically, PPD is shownto bound classical probability divergences. Empirically, we show that CNFslearned by minimizing PPD achieve state-of-the-art results in likelihoods andsample quality on existing low-dimensional manifold benchmarks, and is thefirst example of a generative model to scale to moderately high dimensionalmanifolds.",1
"Variational Inference for Additive Main and Multiplicative Interaction Effects Models In plant breeding the presence of a genotype by environment (GxE) interactionhas a strong impact on cultivation decision making and the introduction of newcrop cultivars. The combination of linear and bilinear terms has been shown tobe very useful in modelling this type of data. A widely-used approach toidentify GxE is the Additive Main Effects and Multiplicative InteractionEffects (AMMI) model. However, as data frequently can be high-dimensional,Markov chain Monte Carlo (MCMC) approaches can be computationally infeasible.In this article, we consider a variational inference approach for such a model.We derive variational approximations for estimating the parameters and wecompare the approximations to MCMC using both simulated and real data. The newinferential framework we propose is on average two times faster whilstmaintaining the same predictive performance as MCMC.",1
"Exploration in Linear Bandits with Rich Action Sets and its Implications for Inference We present a non-asymptotic lower bound on the eigenspectrum of the designmatrix generated by any linear bandit algorithm with sub-linear regret when theaction set has well-behaved curvature. Specifically, we show that the minimumeigenvalue of the expected design matrix grows as $\Omega(\sqrt{n})$ wheneverthe expected cumulative regret of the algorithm is $O(\sqrt{n})$, where $n$ isthe learning horizon, and the action-space has a constant Hessian around theoptimal arm. This shows that such action-spaces force a polynomial lower boundrather than a logarithmic lower bound, as shown by \cite{lattimore2017end}, indiscrete (i.e., well-separated) action spaces. Furthermore, while the previousresult is shown to hold only in the asymptotic regime (as $n \to \infty$), ourresult for these ``locally rich action spaces is any-time. Additionally, undera mild technical assumption, we obtain a similar lower bound on the minimumeigen value holding with high probability.",1
"The derivatives of Sinkhorn-Knopp converge We show that the derivatives of the Sinkhorn-Knopp algorithm, or iterativeproportional fitting procedure, converge towards the derivatives of theentropic regularization of the optimal transport problem with a locally uniformlinear convergence rate.",1
"Grounding Aleatoric Uncertainty in Unsupervised Environment Design Adaptive curricula in reinforcement learning (RL) have proven effective forproducing policies robust to discrepancies between the train and testenvironment. Recently, the Unsupervised Environment Design (UED) frameworkgeneralized RL curricula to generating sequences of entire environments,leading to new methods with robust minimax regret properties. Problematically,in partially-observable or stochastic settings, optimal policies may depend onthe ground-truth distribution over aleatoric parameters of the environment inthe intended deployment setting, while curriculum learning necessarily shiftsthe training distribution. We formalize this phenomenon as curriculum-inducedcovariate shift (CICS), and describe how its occurrence in aleatoric parameterscan lead to suboptimal policies. Directly sampling these parameters from theground-truth distribution avoids the issue, but thwarts curriculum learning. Wepropose SAMPLR, a minimax regret UED method that optimizes the ground-truthutility function, even when the underlying training data is biased due to CICS.We prove, and validate on challenging domains, that our approach preservesoptimality under the ground-truth distribution, while promoting robustnessacross the full range of environment settings.",1
"Learning Mutual Fund Categorization using Natural Language Processing Categorization of mutual funds or Exchange-Traded-funds (ETFs) have longserved the financial analysts to perform peer analysis for various purposesstarting from competitor analysis, to quantifying portfolio diversification.The categorization methodology usually relies on fund composition data in thestructured format extracted from the Form N-1A. Here, we initiate a study tolearn the categorization system directly from the unstructured data as depictedin the forms using natural language processing (NLP). Positing as a multi-classclassification problem with the input data being only the investment strategydescription as reported in the form and the target variable being the LipperGlobal categories, and using various NLP models, we show that thecategorization system can indeed be learned with high accuracy. We discussimplications and applications of our findings as well as limitations ofexisting pre-trained architectures in applying them to learn fundcategorization.",1
"Representing Random Utility Choice Models with Neural Networks Motivated by the successes of deep learning, we propose a class of neuralnetwork-based discrete choice models, called RUMnets, which is inspired by therandom utility maximization (RUM) framework. This model formulates the agents'random utility function using the sample average approximation (SAA) method. Weshow that RUMnets sharply approximate the class of RUM discrete choice models:any model derived from random utility maximization has choice probabilitiesthat can be approximated arbitrarily closely by a RUMnet. Reciprocally, anyRUMnet is consistent with the RUM principle. We derive an upper bound on thegeneralization error of RUMnets fitted on choice data, and gain theoreticalinsights on their ability to predict choices on new, unseen data depending oncritical parameters of the dataset and architecture. By leveraging open-sourcelibraries for neural networks, we find that RUMnets outperform otherstate-of-the-art choice modeling and machine learning methods by a significantmargin on two real-world datasets.",1
"Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning We propose a new auto-regressive model for the statistical analysis ofmultivariate distributional time series. The data of interest consist of acollection of multiple series of probability measures supported over a boundedinterval of the real line, and that are indexed by distinct time instants. Theprobability measures are modelled as random objects in the Wasserstein space.We establish the auto-regressive model in the tangent space at the Lebesguemeasure by first centering all the raw measures so that their Fréchet meansturn to be the Lebesgue measure. Using the theory of iterated random functionsystems, results on the existence, uniqueness and stationarity of the solutionof such a model are provided. We also propose a consistent estimator for themodel coefficient. In addition to the analysis of simulated data, the proposedmodel is illustrated with two real data sets made of observations from agedistribution in different countries and bike sharing network in Paris. Finally,due to the positive and boundedness constraints that we impose on the modelcoefficients, the proposed estimator that is learned under these constraints,naturally has a sparse structure. The sparsity allows furthermore theapplication of the proposed model in learning a graph of temporal dependencyfrom the multivariate distributional time series.",1
Learning structures of the French clinical language:development and validation of word embedding models using 21 million clinical reports from electronic health records Background,1
